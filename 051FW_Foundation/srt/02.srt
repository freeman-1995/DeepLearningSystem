1
00:00:00,000 --> 00:00:04,687
字幕校对:米哈游天下第一

2
00:00:04,687 --> 00:00:10,000
哈喽,大家好,我是那个没什么人在观看,但是我依然在坚持的ZOMI

3
00:00:10,000 --> 00:00:16,000
今天我主要是想给大家一起去探讨一下AI框架到底有什么用

4
00:00:16,000 --> 00:00:21,000
这个灵魂问题,领导经常会挑战这些工程师

5
00:00:21,000 --> 00:00:25,000
你捣鼓,你搞这个AI框架到底有什么用

6
00:00:25,000 --> 00:00:29,000
你要是做开源的话,怎么给带来商业上的变现呢?

7
00:00:29,000 --> 00:00:31,000
过来啊!

8
00:00:31,000 --> 00:00:33,000
经常受到这样的挑战

9
00:00:33,000 --> 00:00:38,000
所以这一节我也是想简单的尝试的去回答这个问题

10
00:00:38,000 --> 00:00:41,000
如果下次领导或者有其他人在挑战

11
00:00:41,000 --> 00:00:44,000
可以把这些相关的内容搬出来

12
00:00:44,000 --> 00:00:48,000
给他们看看,到底做这个东西有没有用

13
00:00:51,000 --> 00:00:54,000
那在这里面可以看到

14
00:00:54,000 --> 00:00:59,000
左上角的之前的那两个logo其实已经去掉了

15
00:00:59,000 --> 00:01:03,000
这里面就不再出现昇腾和Mindspore的一个大大的logo

16
00:01:03,000 --> 00:01:06,000
那个非常不和谐,也不再挂广告了

17
00:01:06,000 --> 00:01:10,000
在这一节里面来看看今天要讲的内容

18
00:01:10,000 --> 00:01:13,000
第一个就是深度学习的一个基础

19
00:01:13,000 --> 00:01:16,000
不知道那条线为啥这样飞出去了

20
00:01:16,000 --> 00:01:19,000
第二个就是AI框架的一个具体的作用

21
00:01:19,000 --> 00:01:22,000
第三个就是做AI框架的一个目的

22
00:01:22,000 --> 00:01:25,000
或者AI框架有什么帮助对

23
00:01:25,000 --> 00:01:29,000
正式开始之前首先要来回顾一下

24
00:01:29,000 --> 00:01:32,000
深度学习的一个基础的概念

25
00:01:32,000 --> 00:01:37,000
因为整个AI框架主要是为深度学习而去服务的

26
00:01:37,000 --> 00:01:40,000
搞深度学习很重要的第一个

27
00:01:40,000 --> 00:01:43,000
首先要定义一个神经网络

28
00:01:43,000 --> 00:01:48,000
这里面以马东梅作为例子去做一个预测

29
00:01:48,000 --> 00:01:52,000
它到底是一个马什么梅呢?还是什么东梅呢?

30
00:01:59,000 --> 00:02:02,000
就需要去定义一个神经网络

31
00:02:02,000 --> 00:02:06,000
中间的这一个就是神经网络层

32
00:02:06,000 --> 00:02:09,000
每一层有大量的连接线

33
00:02:09,000 --> 00:02:11,000
这些连接线就构成权重

34
00:02:11,000 --> 00:02:15,000
W1,W2,W3各种各样的权重

35
00:02:15,000 --> 00:02:18,000
网络模型越多权重参数就越大

36
00:02:20,000 --> 00:02:22,000
第二个有了神经网络定义之后

37
00:02:22,000 --> 00:02:25,000
需要定义优化的目标

38
00:02:25,000 --> 00:02:28,000
就是告诉程序或者告诉深度学习

39
00:02:28,000 --> 00:02:32,000
我需要预测这个人到底是个什么东西

40
00:02:32,000 --> 00:02:34,000
或者他到底是个什么梅

41
00:02:38,000 --> 00:02:42,000
接着定义了损失函数和优化器之后

42
00:02:42,000 --> 00:02:46,000
第三步就是计算梯度并更新权重了

43
00:02:46,000 --> 00:02:49,000
计算梯度就跟上一节课去讲

44
00:02:49,000 --> 00:02:51,000
自动微分的原理有点像

45
00:02:51,000 --> 00:02:55,000
但是这里面不完全是实现那套方式

46
00:02:55,000 --> 00:02:59,000
而是通过反向传播对梯度进行累积

47
00:02:59,000 --> 00:03:03,000
单门讲反向传播算法的时候会去介绍的

48
00:03:03,000 --> 00:03:05,000
先简单粗俗的去理解一下

49
00:03:05,000 --> 00:03:08,000
计算梯度并更新权重参数

50
00:03:08,000 --> 00:03:11,000
就是计算每一个权重

51
00:03:11,000 --> 00:03:15,000
W1到W2到Wn的一个权重参数

52
00:03:15,000 --> 00:03:18,000
然后从而不断的形成一个循环

53
00:03:18,000 --> 00:03:21,000
去更新权重参数

54
00:03:21,000 --> 00:03:24,000
使得损失值越小越好

55
00:03:24,000 --> 00:03:28,000
就有了AI框架的基础之后

56
00:03:28,000 --> 00:03:30,000
下面来看看

57
00:03:30,000 --> 00:03:34,000
实现一个简单的神经网络里面的一个算子

58
00:03:34,000 --> 00:03:35,000
是怎么实现的

59
00:03:36,000 --> 00:03:39,000
可以看到实现一个卷积的算子

60
00:03:39,000 --> 00:03:42,000
卷积简单的就是一个滤波的操作

61
00:03:42,000 --> 00:03:46,000
从原始的图像也就o_n到o_c里面

62
00:03:46,000 --> 00:03:50,000
你要不断的去迭代每一个batch的数据

63
00:03:50,000 --> 00:03:52,000
然后在这个窗口里面

64
00:03:52,000 --> 00:03:56,000
不断的去滑动卷积核

65
00:03:56,000 --> 00:04:01,000
然后去计算卷积核跟原始模板的一个数

66
00:04:01,000 --> 00:04:03,000
然后得到这个数进行累积

67
00:04:03,000 --> 00:04:06,000
最终了就得到整一个

68
00:04:06,000 --> 00:04:09,000
得到整个卷积核的数值

69
00:04:09,000 --> 00:04:11,000
看上去很复杂

70
00:04:11,000 --> 00:04:13,000
可能你完全听不懂

71
00:04:13,000 --> 00:04:17,000
这里面嵌套了1234567

72
00:04:17,000 --> 00:04:19,000
7个for具体有什么用

73
00:04:19,000 --> 00:04:20,000
没关系

74
00:04:20,000 --> 00:04:22,000
只是讲了一个简单的例子

75
00:04:22,000 --> 00:04:25,000
告诉大家实现一个神经网络非常复杂

76
00:04:25,000 --> 00:04:29,000
要是在CPU里面执行这么复杂的for循环操作

77
00:04:29,000 --> 00:04:31,000
其实是很耗时的

78
00:04:31,000 --> 00:04:33,000
所以就提出了一个概念

79
00:04:33,000 --> 00:04:36,000
怎么样去实现多线程的算子加速呢

80
00:04:36,000 --> 00:04:39,000
就是我实现一个算子是非常冗余的

81
00:04:39,000 --> 00:04:42,000
我需要进行多线程的加速

82
00:04:42,000 --> 00:04:45,000
那第二个以maxpool这个算子为例

83
00:04:45,000 --> 00:04:48,000
maxpool要实现这个算子

84
00:04:48,000 --> 00:04:51,000
其实同样非常复杂

85
00:04:51,000 --> 00:04:53,000
里面嵌套了很多个for

86
00:04:53,000 --> 00:04:55,000
for里面又有for

87
00:04:55,000 --> 00:04:58,000
那这个时候就有个问题

88
00:04:58,000 --> 00:05:01,000
如何把这些大量的并行的操作

89
00:05:01,000 --> 00:05:06,000
跑在GPU NPU一些通用或者AI加速芯片上面呢

90
00:05:06,000 --> 00:05:08,000
这是第二个难题

91
00:05:08,000 --> 00:05:12,000
假设现在对每个算子都已经实现了

92
00:05:12,000 --> 00:05:14,000
一个具体的操作

93
00:05:14,000 --> 00:05:16,000
例如卷积我已经实现出来了

94
00:05:16,000 --> 00:05:17,000
对应relu

95
00:05:17,000 --> 00:05:20,000
然后我也实现了一个relu出来

96
00:05:20,000 --> 00:05:21,000
同样maxpool

97
00:05:21,000 --> 00:05:24,000
全连接网络softmax我都实现了

98
00:05:24,000 --> 00:05:28,000
我如何去把这些算子串起来呢

99
00:05:28,000 --> 00:05:30,000
如果假设只是简单的

100
00:05:30,000 --> 00:05:32,000
人工的去写一个函数

101
00:05:32,000 --> 00:05:34,000
把这些算子串起来

102
00:05:34,000 --> 00:05:37,000
那如何去做一些反向的操作呢

103
00:05:37,000 --> 00:05:40,000
也就是后向的算子怎么去实现呢

104
00:05:40,000 --> 00:05:43,000
只是实现了一个正向的网络堆叠

105
00:05:43,000 --> 00:05:47,000
后向的根本没有去实现

106
00:05:47,000 --> 00:05:51,000
这些神经网络的算子都是我自己去实现的

107
00:05:51,000 --> 00:05:54,000
怎么样去封装好这些算子

108
00:05:54,000 --> 00:05:56,000
然后暴露给其他用户呢

109
00:05:57,000 --> 00:06:01,000
第三个可以看到这些代码都非常冗余

110
00:06:01,000 --> 00:06:04,000
如何优化这一份代码

111
00:06:04,000 --> 00:06:06,000
是个很复杂的工程问题

112
00:06:09,000 --> 00:06:11,000
所以面向很多问题

113
00:06:11,000 --> 00:06:12,000
现在来看看了

114
00:06:12,000 --> 00:06:16,000
AI框架整个框架面对不同层

115
00:06:16,000 --> 00:06:19,000
或者不同层级的时候有哪些问题

116
00:06:19,000 --> 00:06:21,000
第一个就是前端

117
00:06:21,000 --> 00:06:24,000
前端用来看看是面向用户的

118
00:06:24,000 --> 00:06:28,000
这个时候如何灵活的表达一个深度学习模型

119
00:06:28,000 --> 00:06:32,000
也就是怎么把刚才的左边的这个模型

120
00:06:32,000 --> 00:06:34,000
很好的表示出来

121
00:06:34,000 --> 00:06:36,000
这个是面向前端用户的

122
00:06:36,000 --> 00:06:38,000
第二个就是算子

123
00:06:38,000 --> 00:06:40,000
刚才讲到的卷积算子

124
00:06:40,000 --> 00:06:42,000
怎么样才能保证

125
00:06:42,000 --> 00:06:44,000
每个算子的执行效率非常高

126
00:06:44,000 --> 00:06:46,000
它的泛化性非常好

127
00:06:46,000 --> 00:06:49,000
也就是每个算子的执行都是正确的

128
00:06:49,000 --> 00:06:51,000
无论我输的是大的图片

129
00:06:51,000 --> 00:06:52,000
小的图片

130
00:06:52,000 --> 00:06:54,000
非常多的batch少的batch

131
00:06:54,000 --> 00:06:57,000
它的计算结果都应该能够是正确的

132
00:06:57,000 --> 00:07:00,000
而且算子的泛化性也做得很好

133
00:07:00,000 --> 00:07:01,000
不同的入参

134
00:07:01,000 --> 00:07:02,000
它都能够处理

135
00:07:04,000 --> 00:07:06,000
这个第三步就是求导

136
00:07:06,000 --> 00:07:11,000
如何更加有效的去对网络模型求导

137
00:07:11,000 --> 00:07:13,000
然后通过系统进行表示出来

138
00:07:13,000 --> 00:07:15,000
这是第三个难题

139
00:07:15,000 --> 00:07:19,000
第四个就是后端跟系统相关的

140
00:07:19,000 --> 00:07:21,000
可能用户看不到

141
00:07:21,000 --> 00:07:23,000
但是如果我拿了另外一个

142
00:07:23,000 --> 00:07:25,000
不同的设备上面去跑

143
00:07:25,000 --> 00:07:27,000
我这个神经网络还能跑得通吗

144
00:07:27,000 --> 00:07:31,000
最后一点就是如何自动的优化和调度

145
00:07:31,000 --> 00:07:33,000
网络模型进行计算

146
00:07:33,000 --> 00:07:37,000
简单的来说就是程序员写了一堆代码

147
00:07:37,000 --> 00:07:40,000
这些都是一些程序式的代码

148
00:07:40,000 --> 00:07:43,000
如何对这份代码进行优化

149
00:07:43,000 --> 00:07:46,000
其实是一个很大的系统工程问题

150
00:07:49,000 --> 00:07:53,000
为了粗暴的去解决刚才的一些问题

151
00:07:53,000 --> 00:07:55,000
这里面举两个极端的例子

152
00:07:55,000 --> 00:07:58,000
第一个就是用高级语言

153
00:07:58,000 --> 00:08:01,000
从头去实现一个网络模型的计算

154
00:08:01,000 --> 00:08:04,000
右边的这一个就是简单的一个计算

155
00:08:04,000 --> 00:08:06,000
然后通过计算得到C之后

156
00:08:06,000 --> 00:08:07,000
然后去求它的梯度

157
00:08:07,000 --> 00:08:10,000
这个时候可能会用一些高级语言

158
00:08:10,000 --> 00:08:13,000
自己去实现了右边的这个计算公式

159
00:08:13,000 --> 00:08:14,000
先乘然后再加

160
00:08:14,000 --> 00:08:16,000
然后再求一个和

161
00:08:16,000 --> 00:08:18,000
那我要做反向的时候

162
00:08:18,000 --> 00:08:21,000
可能就需要手工的去做一个反向的操作

163
00:08:21,000 --> 00:08:24,000
人工的去把一些需要反向的东西记录下来

164
00:08:26,000 --> 00:08:29,000
这种方式就是Python like的方式

165
00:08:29,000 --> 00:08:31,000
这种方式的好处

166
00:08:31,000 --> 00:08:34,000
就是跟Python的原生代码非常像

167
00:08:34,000 --> 00:08:36,000
然后易用性非常高

168
00:08:36,000 --> 00:08:38,000
但是它所谓的易用性高

169
00:08:38,000 --> 00:08:41,000
并不是真正理解的易用性高

170
00:08:41,000 --> 00:08:45,000
这个时候还停留在非常初始的阶段

171
00:08:45,000 --> 00:08:46,000
那第二种呢

172
00:08:46,000 --> 00:08:48,000
就是另外一种极端的方式

173
00:08:48,000 --> 00:08:53,000
下面是华为的昇腾系列的一个服务器板卡

174
00:08:53,000 --> 00:08:55,000
这是我从网上粘下来的图

175
00:08:55,000 --> 00:08:56,000
所以不要care

176
00:08:56,000 --> 00:08:59,000
这到底是一个GPU还是NPU

177
00:08:59,000 --> 00:09:02,000
那可能会为一些常用的模型

178
00:09:02,000 --> 00:09:05,000
在NPU加速上面去做了一个简单的实现

179
00:09:05,000 --> 00:09:07,000
就是import什么什么library进去

180
00:09:07,000 --> 00:09:08,000
然后呢

181
00:09:08,000 --> 00:09:12,000
把这个library里面的resnet50或者resnet101

182
00:09:12,000 --> 00:09:14,000
这些直接写死了

183
00:09:14,000 --> 00:09:17,000
用户直接调用我这个模型就可以了

184
00:09:17,000 --> 00:09:20,000
我帮你已经做好了高度的封装和优化

185
00:09:20,000 --> 00:09:21,000
那这个呢

186
00:09:21,000 --> 00:09:24,000
就是另外一个AI框架的极端

187
00:09:24,000 --> 00:09:28,000
也就是非常注重效率基于库的实现方式

188
00:09:30,000 --> 00:09:31,000
刚才那两种方式呢

189
00:09:31,000 --> 00:09:33,000
都是非常极端的

190
00:09:33,000 --> 00:09:34,000
实际上呢

191
00:09:34,000 --> 00:09:38,000
为了解决很多刚才提到的一些问题

192
00:09:38,000 --> 00:09:41,000
并不会去真正使用刚才那两种方式

193
00:09:41,000 --> 00:09:43,000
那看看这个图呢

194
00:09:43,000 --> 00:09:45,000
下面是芯片使能啊

195
00:09:45,000 --> 00:09:47,000
假设芯片有昇腾的芯片

196
00:09:47,000 --> 00:09:48,000
有CPU的芯片

197
00:09:48,000 --> 00:09:50,000
还有CUDA的芯片是吧

198
00:09:50,000 --> 00:09:53,000
还有一些其他杂七杂八的芯片

199
00:09:53,000 --> 00:09:54,000
例如苹果的呀

200
00:09:54,000 --> 00:09:55,000
高通的呀

201
00:09:55,000 --> 00:09:56,000
马力的GPU啊

202
00:09:56,000 --> 00:09:58,000
这些一系列的芯片

203
00:09:58,000 --> 00:09:59,000
AI框架呢

204
00:09:59,000 --> 00:10:02,000
在核心层就是中间这个框

205
00:10:02,000 --> 00:10:04,000
它会做一些数据处理啊

206
00:10:04,000 --> 00:10:05,000
开发接口啊

207
00:10:05,000 --> 00:10:06,000
调试调优

208
00:10:06,000 --> 00:10:07,000
编译和执行

209
00:10:07,000 --> 00:10:09,000
还有推理部署相关的组件

210
00:10:10,000 --> 00:10:12,000
向下主要是对接一些芯片

211
00:10:12,000 --> 00:10:13,000
向上呢

212
00:10:13,000 --> 00:10:15,000
主要是对接一些算法

213
00:10:15,000 --> 00:10:17,000
就是承载算法

214
00:10:17,000 --> 00:10:20,000
所以AI框架起到了两个作用

215
00:10:20,000 --> 00:10:22,000
第一个对下的芯片使能

216
00:10:22,000 --> 00:10:24,000
对上的承载算法应用

217
00:10:24,000 --> 00:10:26,000
算法应用不可能直接到芯片的

218
00:10:26,000 --> 00:10:29,000
它需要一个框架或者一个库去承载

219
00:10:29,000 --> 00:10:32,000
这个时候AI框架就变得非常核心了

220
00:10:32,000 --> 00:10:34,000
因为现在找工作都知道

221
00:10:35,000 --> 00:10:36,000
不懂点算法

222
00:10:36,000 --> 00:10:38,000
可能工作都不好找了

223
00:10:40,000 --> 00:10:41,000
下面呢

224
00:10:41,000 --> 00:10:43,000
看看AI框架真正的目的

225
00:10:43,000 --> 00:10:44,000
或者来

226
00:10:45,000 --> 00:10:47,000
语言化一点去表示

227
00:10:48,000 --> 00:10:49,000
下面这个呢

228
00:10:49,000 --> 00:10:51,000
是我所总结的一些字眼

229
00:10:52,000 --> 00:10:53,000
大家看看就好了

230
00:10:53,000 --> 00:10:56,000
其实更多时候是凭借用户的感觉

231
00:10:56,000 --> 00:10:58,000
或者自己的第一个反应

232
00:10:58,000 --> 00:11:00,000
我觉得这个才是最核心的

233
00:11:00,000 --> 00:11:02,000
或者你觉得AI框架有什么用

234
00:11:02,000 --> 00:11:05,000
它真的就是能帮你解决实际的问题的

235
00:11:05,000 --> 00:11:07,000
那作为AI框架的开发人

236
00:11:07,000 --> 00:11:09,000
或者开发者来说呢

237
00:11:09,000 --> 00:11:11,000
希望AI框架呢

238
00:11:11,000 --> 00:11:13,000
对用户提供一个非常灵活的

239
00:11:13,000 --> 00:11:15,000
编程模型和编程接口

240
00:11:15,000 --> 00:11:17,000
就是对用户来说有用的

241
00:11:17,000 --> 00:11:19,000
可以帮助用户去做一些

242
00:11:19,000 --> 00:11:21,000
自动的计算图的推导

243
00:11:21,000 --> 00:11:25,000
还有比较好的跟现有的AI生态进行融合

244
00:11:25,000 --> 00:11:27,000
另外的话可能还会提供一些

245
00:11:27,000 --> 00:11:29,000
非常直观的模型构建的方式

246
00:11:29,000 --> 00:11:31,000
例如现在MNLab

247
00:11:31,000 --> 00:11:33,000
Huggingface推出很多套件

248
00:11:33,000 --> 00:11:36,000
他们就提供了很多基于Pytorch之上

249
00:11:36,000 --> 00:11:38,000
构建的模型的构建方式

250
00:11:38,000 --> 00:11:41,000
还有Pytorch提供非常简洁的

251
00:11:41,000 --> 00:11:44,000
神经网络的编程语言接口

252
00:11:44,000 --> 00:11:45,000
这个呢就是对上

253
00:11:45,000 --> 00:11:48,000
希望能够为用户解决的一些问题

254
00:11:48,000 --> 00:11:49,000
对下呢

255
00:11:49,000 --> 00:11:51,000
其实更希望提供一些

256
00:11:51,000 --> 00:11:53,000
计算能力的解决

257
00:11:53,000 --> 00:11:55,000
或者提升效率

258
00:11:55,000 --> 00:11:57,000
那这个呢可能就是学计算机

259
00:11:57,000 --> 00:11:59,000
或者学软件的人更加关注的

260
00:11:59,000 --> 00:12:02,000
提供一个高效可以扩展的计算能力

261
00:12:02,000 --> 00:12:06,000
例如做一些自动编译的优化算法

262
00:12:06,000 --> 00:12:08,000
例如在编译器里面

263
00:12:08,000 --> 00:12:10,000
会做一些子表达式的消除

264
00:12:10,000 --> 00:12:11,000
内核的融合

265
00:12:11,000 --> 00:12:13,000
还有内存的优化

266
00:12:13,000 --> 00:12:15,000
让计算图

267
00:12:15,000 --> 00:12:18,000
或者神经网络跑得更快

268
00:12:18,000 --> 00:12:19,000
那第二个呢

269
00:12:19,000 --> 00:12:21,000
就是根据不同的硬件体系结构

270
00:12:21,000 --> 00:12:22,000
和硬件设备

271
00:12:22,000 --> 00:12:24,000
做一些自动化的并行

272
00:12:24,000 --> 00:12:26,000
自动化的加速

273
00:12:26,000 --> 00:12:28,000
这个就是底下的能力

274
00:12:30,000 --> 00:12:32,000
讲完这节课之后呢

275
00:12:32,000 --> 00:12:35,000
回顾了深度学习的基本流程

276
00:12:35,000 --> 00:12:36,000
有三步

277
00:12:36,000 --> 00:12:37,000
第一网络模型

278
00:12:37,000 --> 00:12:38,000
定义损失函数

279
00:12:38,000 --> 00:12:40,000
然后求偏导微分

280
00:12:40,000 --> 00:12:41,000
那第二个呢

281
00:12:41,000 --> 00:12:43,000
就是了解了AI框架的具体作用

282
00:12:43,000 --> 00:12:45,000
向上呢是承接算法

283
00:12:45,000 --> 00:12:47,000
向下呢是芯片使能

284
00:12:47,000 --> 00:12:48,000
第三点呢

285
00:12:48,000 --> 00:12:50,000
就是知道了AI框架

286
00:12:50,000 --> 00:12:52,000
具体希望能够给用户

287
00:12:52,000 --> 00:12:54,000
对上提供一个编程接口

288
00:12:54,000 --> 00:12:57,000
对下呢提供更好的算力的目的

289
00:12:57,000 --> 00:12:58,000
好了

290
00:12:58,000 --> 00:12:59,000
谢谢各位

291
00:12:59,000 --> 00:13:00,000
拜了个拜

292
00:13:01,500 --> 00:13:03,500
卷的不行了卷的不行了

293
00:13:03,500 --> 00:13:05,291
记得一键三连加关注哦

294
00:13:05,291 --> 00:13:05,500
所有的内容都会开源在下面这条链接里面

295
00:13:05,500 --> 00:13:08,481
所有的内容都会开源在下面这条链接里面

296
00:13:08,481 --> 00:13:09,788
拜了个拜

