1
00:00:00,000 --> 00:00:05,275
字幕校对:米哈游天下第一

2
00:00:05,275 --> 00:00:07,800
哈喽大家好,我是ZOMI

3
00:00:07,800 --> 00:00:11,600
今天还是在AI芯片的基础

4
00:00:11,600 --> 00:00:15,400
不过来到了AI芯片里面基础的最后一个内容

5
00:00:15,400 --> 00:00:18,400
计算体系架构的黄金十年

6
00:00:18,400 --> 00:00:21,400
其实从CPU到GPU到NPU

7
00:00:21,400 --> 00:00:24,000
可能DPU不在范围内

8
00:00:24,000 --> 00:00:27,200
随着这么多不同的架构的芯片组合在一起

9
00:00:27,200 --> 00:00:30,400
其实真正的来到了整个计算体系架构的

10
00:00:30,400 --> 00:00:32,600
真正的革命和演变的时代

11
00:00:32,600 --> 00:00:34,400
而为什么我会这么说呢?

12
00:00:34,400 --> 00:00:36,000
这个结论不是我说的

13
00:00:36,000 --> 00:00:38,600
而是图灵的得奖者David

14
00:00:38,600 --> 00:00:42,200
在计算机架构的黄金十年里面

15
00:00:42,200 --> 00:00:44,000
去讲到的一个概念

16
00:00:44,000 --> 00:00:45,600
而一年之后

17
00:00:45,600 --> 00:00:48,800
LLVM之父也同样的去发表了一篇报告

18
00:00:48,800 --> 00:00:51,200
叫做编译器的黄金十年

19
00:00:51,200 --> 00:00:53,800
非常欢迎大家去看看这两个视频

20
00:00:53,800 --> 00:00:58,000
这两个视频在YouTube上面都可以去看的

21
00:00:58,000 --> 00:01:00,000
接下来回到今天的重点

22
00:01:00,000 --> 00:01:02,600
AI芯片的发展

23
00:01:02,600 --> 00:01:05,600
其实AI芯片经历过三个阶段

24
00:01:05,600 --> 00:01:07,800
简单的去过一过

25
00:01:07,800 --> 00:01:10,200
第一个阶段就是AI芯片算力不足

26
00:01:10,200 --> 00:01:13,000
神级网络没有很好的被受到重视

27
00:01:13,000 --> 00:01:16,000
那个时候应该是1970年到1980年

28
00:01:16,000 --> 00:01:18,600
CPU还没有正式的获得出现

29
00:01:18,600 --> 00:01:23,400
而在第二个阶段就是CPU的算力大幅的提升

30
00:01:23,400 --> 00:01:25,000
应该在千禧年左右

31
00:01:25,000 --> 00:01:29,200
但是那个时候已经开始慢慢出现了一些AI的框架

32
00:01:29,200 --> 00:01:32,600
例如PyTorch的前身Torch

33
00:01:32,600 --> 00:01:34,600
在第二个阶段最大的问题就是

34
00:01:34,600 --> 00:01:36,800
CPU的算力虽然大幅的提升了

35
00:01:36,800 --> 00:01:39,000
但是没有办法去满足神经网络

36
00:01:39,000 --> 00:01:41,400
或者深度学习算力的增长需求

37
00:01:41,400 --> 00:01:42,800
到第三个阶段

38
00:01:42,800 --> 00:01:46,200
就是现在来到的一个AI产业的阶段

39
00:01:46,200 --> 00:01:48,200
GPU和AI的芯片

40
00:01:48,200 --> 00:01:50,400
整体的新的架构体系的出现

41
00:01:50,400 --> 00:01:53,600
推动了整个人工智能的快速落地

42
00:01:53,600 --> 00:01:56,000
现在算力越来越多

43
00:01:56,000 --> 00:01:58,800
能够从小模型演变到大模型

44
00:01:58,800 --> 00:02:01,600
到现在的基础模型了

45
00:02:01,600 --> 00:02:03,000
模型参数量

46
00:02:03,000 --> 00:02:05,600
动辄就已经上百亿千亿万亿了

47
00:02:05,600 --> 00:02:09,000
这种规模也是非常的惊人和夸张的

48
00:02:09,000 --> 00:02:11,400
接着讲完一些基础的内容

49
00:02:11,400 --> 00:02:13,600
来看看什么叫做异构

50
00:02:13,600 --> 00:02:16,000
今天的主角就是异构场景

51
00:02:16,000 --> 00:02:17,600
和具体的异构芯片

52
00:02:17,600 --> 00:02:19,200
下面以一个具体的例子

53
00:02:19,200 --> 00:02:21,000
来去看看这个问题

54
00:02:21,000 --> 00:02:24,000
以特斯拉这款芯片作为例子

55
00:02:24,000 --> 00:02:26,000
特斯拉可以看到一款车

56
00:02:26,000 --> 00:02:28,400
我在车里面要做很多相关的工作

57
00:02:28,400 --> 00:02:29,400
我要感知雷达

58
00:02:29,400 --> 00:02:30,200
我要做GPS

59
00:02:30,200 --> 00:02:31,600
我要做地图的建模

60
00:02:31,600 --> 00:02:34,200
我可能还会对IMU的数据进行处理

61
00:02:34,200 --> 00:02:37,200
所以说它的功能是非常多样化的

62
00:02:37,200 --> 00:02:38,400
面对这些功能

63
00:02:38,400 --> 00:02:42,200
特斯拉HW3 FSD芯片就推出了

64
00:02:42,200 --> 00:02:45,400
它不仅有自己的CPU、GPU还有NPU

65
00:02:45,400 --> 00:02:48,800
可能里面还会有ISP和Secure Processing Unit

66
00:02:48,800 --> 00:02:52,600
里面的功能单元非常非常的多

67
00:02:52,600 --> 00:02:56,600
下面这个图就是NPU的一个Data Flow的架构

68
00:02:56,600 --> 00:03:00,200
在一款芯片里面拥有这么多不同的IP

69
00:03:00,200 --> 00:03:04,200
叫这款IP或者这款芯片叫做异构的SoC

70
00:03:04,200 --> 00:03:08,400
这款芯片有非常多不同的IP进行组合

71
00:03:08,400 --> 00:03:11,600
进行配合才能够正常的工作起来

72
00:03:11,600 --> 00:03:15,000
这种情况叫做异构

73
00:03:15,000 --> 00:03:16,400
整个计算的体系

74
00:03:16,400 --> 00:03:18,400
因为应用场景越来越丰富

75
00:03:18,400 --> 00:03:20,200
因为计算的需求越来越多

76
00:03:20,200 --> 00:03:23,600
于是现在迎来了整个异构的体系

77
00:03:23,600 --> 00:03:25,600
异构的时代

78
00:03:25,600 --> 00:03:28,600
来看一下整个异构芯片的出现

79
00:03:28,600 --> 00:03:31,000
其实现在大部分的CPU

80
00:03:31,000 --> 00:03:33,000
都是采用冯诺依曼的架构

81
00:03:33,000 --> 00:03:34,000
冯诺依曼的架构

82
00:03:34,000 --> 00:03:37,200
基本上就是我按指令顺序的去执行

83
00:03:37,200 --> 00:03:39,600
虽然这种方式确实有点低效

84
00:03:39,600 --> 00:03:41,600
于是就出现了多核的处理器

85
00:03:41,600 --> 00:03:43,600
或者变成了一个集群的计算

86
00:03:43,600 --> 00:03:47,200
慢慢的去引入了并行计算这个概念

87
00:03:47,200 --> 00:03:48,400
并行计算这个概念

88
00:03:48,400 --> 00:03:51,400
其实一开始是出现在GPU

89
00:03:51,400 --> 00:03:54,800
但是GPU它其实自己是没有办法单独的工作的

90
00:03:54,800 --> 00:03:57,400
而是要跟CPU进行一个配合

91
00:03:57,400 --> 00:04:00,800
既然两种不同的架构在一起配合工作

92
00:04:00,800 --> 00:04:03,000
于是就迎来了第一种

93
00:04:03,000 --> 00:04:05,600
异构的芯片异构的工作流程

94
00:04:05,600 --> 00:04:07,000
下面来打开看一下

95
00:04:07,000 --> 00:04:09,000
它整体的GPU跟CPU的异构

96
00:04:09,000 --> 00:04:11,800
是怎么去互相配合的

97
00:04:11,800 --> 00:04:14,800
首先CPU要处理一些工作的时候

98
00:04:14,800 --> 00:04:17,375
它会把一些数据存在里面的DRAM

99
00:04:17,375 --> 00:04:17,400
在第一步就会把DRAM的数据搬运到HBM

100
00:04:17,400 --> 00:04:21,175
在第一步就会把DRAM的数据搬运到HBM

101
00:04:21,200 --> 00:04:25,600
也就是显存GPU的显示内存里面

102
00:04:25,600 --> 00:04:27,800
接着在第二步的时候

103
00:04:27,800 --> 00:04:31,400
CPU就会发射一些相对应的指令

104
00:04:31,400 --> 00:04:32,800
给到GPU的CUDA Core

105
00:04:32,800 --> 00:04:36,400
或者GPU的线程真正的去执行计算

106
00:04:36,400 --> 00:04:37,400
计算完之后

107
00:04:37,400 --> 00:04:39,400
GPU就会把相关的结果

108
00:04:39,400 --> 00:04:41,800
返回存储到HBM里面

109
00:04:41,800 --> 00:04:43,400
最后一步就是step4

110
00:04:43,400 --> 00:04:45,800
step4会把一些GPU计算完的结果

111
00:04:45,800 --> 00:04:47,800
返回给CPU

112
00:04:47,800 --> 00:04:51,400
这个时候GPU计算的是一些特殊的加速

113
00:04:51,400 --> 00:04:54,800
或者特殊的需要进行并行的一些计算的功能

114
00:04:54,800 --> 00:04:57,600
这个时候CPU跟GPU之间的异构

115
00:04:57,600 --> 00:04:59,600
就非常之明显了

116
00:04:59,600 --> 00:05:04,400
CPU主要是用来处理一些通用的应用逻辑程序

117
00:05:04,400 --> 00:05:06,800
而GPU在一开始出现的时候

118
00:05:06,800 --> 00:05:09,600
主要是来处理一些图形图像

119
00:05:09,600 --> 00:05:12,400
渲染的一些工作

120
00:05:12,400 --> 00:05:13,800
最近这五年

121
00:05:13,800 --> 00:05:15,600
又有非常多的芯片

122
00:05:15,600 --> 00:05:17,000
例如ASIC的芯片

123
00:05:17,000 --> 00:05:20,800
就迎来了一个真正能够帮助AI应用做加速的

124
00:05:20,800 --> 00:05:22,000
像谷歌的TPU

125
00:05:22,000 --> 00:05:24,000
就从第一代V1 V2 V3 V4

126
00:05:24,000 --> 00:05:25,400
到现在的V4

127
00:05:25,400 --> 00:05:30,000
有了非常多专门为AI应用做加速的芯片

128
00:05:30,000 --> 00:05:32,600
而这些芯片除了通用的IO之外

129
00:05:32,600 --> 00:05:34,200
它最重要的一个核心模块

130
00:05:34,200 --> 00:05:39,600
就是针对AI的一个专用处理引擎

131
00:05:39,600 --> 00:05:41,800
了解完什么是异构之后

132
00:05:41,800 --> 00:05:43,400
现在来看看

133
00:05:43,400 --> 00:05:45,400
何为超异构

134
00:05:45,400 --> 00:05:47,400
里面有一个最重要的字眼

135
00:05:47,400 --> 00:05:49,200
就是一个超字了

136
00:05:49,200 --> 00:05:50,200
那下面这个图

137
00:05:50,200 --> 00:05:53,600
可以看到超异构的整体的一个关系

138
00:05:53,600 --> 00:05:55,000
除了有CPU

139
00:05:55,000 --> 00:05:56,200
有协处理器

140
00:05:56,200 --> 00:05:57,400
后来有了GPU

141
00:05:57,400 --> 00:05:58,800
到现在的NPU

142
00:05:58,800 --> 00:06:00,400
但是后面还有一些DPU

143
00:06:00,400 --> 00:06:02,000
越来越多的芯片

144
00:06:02,000 --> 00:06:04,200
而越来越多的特殊的芯片

145
00:06:04,200 --> 00:06:06,800
主要是提供一些特殊的性能加速

146
00:06:06,800 --> 00:06:10,200
还有特殊的硬件的专用的处理

147
00:06:10,200 --> 00:06:12,200
针对某些应用场景

148
00:06:12,200 --> 00:06:13,600
越往右边走了

149
00:06:13,600 --> 00:06:17,400
这些芯片基本上就会越会针对某些应用

150
00:06:17,400 --> 00:06:18,800
或者某些计算场景

151
00:06:18,800 --> 00:06:21,200
做一些专用的硬件的提供

152
00:06:21,200 --> 00:06:24,400
它的性能也会更加的比一些通用的要高

153
00:06:24,400 --> 00:06:27,200
这个时候就迎来了一个最大的问题

154
00:06:27,200 --> 00:06:29,000
处理器的架构越来越多

155
00:06:29,000 --> 00:06:30,000
架构多了

156
00:06:30,000 --> 00:06:31,800
整个碎片化程度就会多

157
00:06:31,800 --> 00:06:35,000
构建整个生态的难度也会越来越大

158
00:06:37,000 --> 00:06:39,800
回顾一下异构计算的发展历史

159
00:06:39,800 --> 00:06:42,000
从CPU简单的IO

160
00:06:42,000 --> 00:06:44,000
这种叫做同构

161
00:06:44,000 --> 00:06:46,600
或者直接说是串行计算就行了

162
00:06:46,600 --> 00:06:48,200
它连构都不是

163
00:06:48,200 --> 00:06:52,200
接着迎来了GPU跟CPU协同合作

164
00:06:52,200 --> 00:06:55,200
这种慢慢的迎来了异构

165
00:06:55,200 --> 00:07:00,600
当然现在更多的是CPU跟NPU进行协作的

166
00:07:00,600 --> 00:07:02,400
这种也是属于异构

167
00:07:02,400 --> 00:07:06,200
CPU同时也可以跟GPU进行一个协作处理

168
00:07:06,200 --> 00:07:09,400
这种方式其实也属于一个异构的场景

169
00:07:09,400 --> 00:07:12,400
到未来或者未来接近的现在

170
00:07:12,400 --> 00:07:14,200
出现了超异构的架构

171
00:07:14,200 --> 00:07:16,600
中间连接的可能就已经不是CPU

172
00:07:16,600 --> 00:07:19,200
而是DPU数据处理单元

173
00:07:19,200 --> 00:07:21,000
数据处理单元可以跟GPU

174
00:07:21,000 --> 00:07:22,400
NPU还有IO

175
00:07:22,400 --> 00:07:25,000
CPU之间互相的协作

176
00:07:25,000 --> 00:07:28,200
而CPU又可以跟GPU进行互相的协作

177
00:07:28,200 --> 00:07:30,600
当然可能CPU会跟NPU

178
00:07:30,600 --> 00:07:33,400
或者NPU跟GPU进行互相的协作

179
00:07:33,400 --> 00:07:35,400
举一个非常简单的例子

180
00:07:35,400 --> 00:07:37,000
现在我有一个场景

181
00:07:37,000 --> 00:07:39,000
例如三维的场景

182
00:07:39,000 --> 00:07:39,800
NERV

183
00:07:39,800 --> 00:07:43,600
NERF现在可以用NPU进行三维的加速

184
00:07:43,600 --> 00:07:44,600
加速完之后

185
00:07:44,600 --> 00:07:48,000
我要显示的时候交给GPU进行处理

186
00:07:48,000 --> 00:07:49,800
GPU处理完之后

187
00:07:49,800 --> 00:07:52,200
最终返回给用户显示的应用

188
00:07:52,200 --> 00:07:55,000
由CPU进行调度

189
00:07:55,000 --> 00:07:58,000
这种场景就是超异构架构

190
00:07:58,000 --> 00:08:01,000
所会使用到的

191
00:08:01,000 --> 00:08:03,000
因此从刚才那个图

192
00:08:03,000 --> 00:08:04,200
可以看到计算

193
00:08:04,200 --> 00:08:08,200
从异构并行走向了超异构并行

194
00:08:08,200 --> 00:08:10,000
从简单的两层

195
00:08:10,000 --> 00:08:12,400
CPU加GPU或者CPU加NPU

196
00:08:12,400 --> 00:08:13,800
到现在的三层

197
00:08:13,800 --> 00:08:15,200
甚至更高层的

198
00:08:15,200 --> 00:08:17,800
CPU加GPU同时加上XPU

199
00:08:17,800 --> 00:08:20,000
就NPU TPU或者DPU

200
00:08:20,000 --> 00:08:22,000
同时协同的工作

201
00:08:22,000 --> 00:08:23,400
这个时候就真正的

202
00:08:23,400 --> 00:08:26,200
迈进了超异构并行架构里面了

203
00:08:26,200 --> 00:08:28,000
在整体的超异构计算里面

204
00:08:28,000 --> 00:08:31,600
其实这里面并不是简单的对一些芯片

205
00:08:31,600 --> 00:08:34,400
或者整个系统进行简单的集成

206
00:08:34,400 --> 00:08:37,600
而是把更多的异构计算重整起来

207
00:08:37,800 --> 00:08:40,200
变成一个新的架构体系

208
00:08:40,200 --> 00:08:41,600
各种各样的处理器

209
00:08:41,600 --> 00:08:43,800
非常之良好的配合的工作

210
00:08:43,800 --> 00:08:46,400
形成了整一个超异构计算的体系

211
00:08:46,400 --> 00:08:48,600
为什么要去强调计算体系呢

212
00:08:48,600 --> 00:08:51,200
因为它是一个整体的解决方案

213
00:08:51,200 --> 00:08:55,200
而不仅是把不同的芯片架构服务器堆叠起来

214
00:08:56,800 --> 00:08:58,000
在上面的内容里面

215
00:08:58,000 --> 00:08:59,800
其实讲了很多不同的概念

216
00:08:59,800 --> 00:09:02,400
这里面简单的做一个汇总

217
00:09:02,400 --> 00:09:03,600
那在第一个阶段

218
00:09:03,600 --> 00:09:05,200
就是由单引擎

219
00:09:05,200 --> 00:09:07,400
串行的单核的CPU

220
00:09:07,400 --> 00:09:08,800
到在第二个阶段

221
00:09:08,800 --> 00:09:10,600
就是同构并行

222
00:09:10,600 --> 00:09:13,200
所谓的同构可能就是多核的CPU

223
00:09:13,200 --> 00:09:15,800
或者多核的GPU独立的工作

224
00:09:15,800 --> 00:09:17,000
到第三个阶段

225
00:09:17,000 --> 00:09:19,800
也就是现在所处的阶段

226
00:09:19,800 --> 00:09:23,000
主要是两层的两种的类型的并行

227
00:09:23,000 --> 00:09:24,600
例如CPU加GPU

228
00:09:24,600 --> 00:09:27,200
或者CPU加NPU这种方式

229
00:09:28,200 --> 00:09:29,800
在未来或者现在

230
00:09:29,800 --> 00:09:32,000
正在处于的一个变革时代

231
00:09:32,000 --> 00:09:35,400
就是三种以上的三层以上的类型

232
00:09:35,400 --> 00:09:36,400
不同的处理器

233
00:09:36,400 --> 00:09:38,400
叫做超异构并行

234
00:09:38,400 --> 00:09:39,600
从CPU加GPU

235
00:09:39,600 --> 00:09:41,200
再NPU再DPU

236
00:09:41,200 --> 00:09:42,800
互相的配合工作

237
00:09:42,800 --> 00:09:44,800
就变成了超异构并行的架构

238
00:09:46,600 --> 00:09:48,400
这种超异构并行的架构

239
00:09:48,400 --> 00:09:49,800
有两个重要的特点

240
00:09:49,800 --> 00:09:53,400
第一个特点就是超大规模的计算集群

241
00:09:54,200 --> 00:09:57,800
第二个特点就是计算系统非常的复杂

242
00:09:57,800 --> 00:10:00,400
分块分层去组成的

243
00:10:00,400 --> 00:10:02,600
可能应用层会使用CPU

244
00:10:02,600 --> 00:10:03,600
特殊的应用加速

245
00:10:03,600 --> 00:10:05,200
会使用GPU ASIC

246
00:10:05,200 --> 00:10:06,400
还有DPU或者NPU

247
00:10:06,400 --> 00:10:07,400
各种各样的

248
00:10:07,400 --> 00:10:09,200
而基础的网络设施

249
00:10:09,400 --> 00:10:12,000
又会有独特的特殊的

250
00:10:12,000 --> 00:10:14,000
一些PU进行给处理

251
00:10:14,000 --> 00:10:16,600
所以它形成了一个超大规模的集群

252
00:10:19,000 --> 00:10:21,800
既然来到了一个超异构的并行架构了

253
00:10:21,800 --> 00:10:24,000
确实也遇到很多问题

254
00:10:24,000 --> 00:10:25,000
最大的一个问题

255
00:10:25,000 --> 00:10:27,000
钟敏觉得就是单处理器

256
00:10:27,000 --> 00:10:29,800
现在有很多不同形态的架构

257
00:10:29,800 --> 00:10:31,600
这些架构之间怎么去兼容

258
00:10:31,600 --> 00:10:32,800
怎么去配合

259
00:10:32,800 --> 00:10:34,600
怎么去灵活的使用

260
00:10:34,600 --> 00:10:36,400
这是一个最大的问题

261
00:10:37,600 --> 00:10:40,600
于是就引入了最后一个内容

262
00:10:40,600 --> 00:10:42,800
超异构架构的挑战

263
00:10:42,800 --> 00:10:45,200
和关于超异构架构的思考

264
00:10:46,000 --> 00:10:47,600
一个很直观的问题就是

265
00:10:47,600 --> 00:10:50,600
面对如此复杂的超异构的架构

266
00:10:50,600 --> 00:10:53,200
应该如何很好的去驾驭

267
00:10:53,800 --> 00:10:57,200
这里面ZOMI结合了非常多的idea

268
00:10:57,200 --> 00:10:59,400
然后做了一个总结

269
00:10:59,400 --> 00:11:01,200
首先看看软件层

270
00:11:01,200 --> 00:11:03,800
软件层肯定是跨平台的

271
00:11:03,800 --> 00:11:04,600
跨不同处理器

272
00:11:04,600 --> 00:11:05,400
跨厂商

273
00:11:05,400 --> 00:11:06,200
跨不同位置

274
00:11:06,200 --> 00:11:07,600
跨不同的设备

275
00:11:07,600 --> 00:11:10,000
所以软件架构的复杂性

276
00:11:10,000 --> 00:11:11,600
会急剧的增长

277
00:11:11,600 --> 00:11:13,600
成为一个最大的挑战

278
00:11:13,600 --> 00:11:14,800
也就是软件

279
00:11:14,800 --> 00:11:17,000
面对这些软件的挑战

280
00:11:17,000 --> 00:11:20,400
应该更多的是开放整个生态

281
00:11:20,400 --> 00:11:21,800
介入整个社区

282
00:11:21,800 --> 00:11:23,400
这里面像英伟达的CUDA

283
00:11:23,400 --> 00:11:25,600
就做得非常非常的好

284
00:11:25,600 --> 00:11:28,800
它开放了自己的整个编程的体系

285
00:11:28,800 --> 00:11:32,000
虽然CUDA它这个语言是没有去开源的

286
00:11:32,000 --> 00:11:33,600
里面的编译层也没有开源

287
00:11:33,600 --> 00:11:36,400
但是它整套编译体系是开放出来了

288
00:11:36,400 --> 00:11:38,000
让更多的人去介入

289
00:11:38,000 --> 00:11:41,600
也形成了现在GPU的一个非常之良好的生态

290
00:11:41,600 --> 00:11:44,800
第二种就是软件需要兼容

291
00:11:44,800 --> 00:11:46,200
像现在的AI芯片

292
00:11:46,200 --> 00:11:48,800
我觉得很多厂商也在做

293
00:11:48,800 --> 00:11:50,400
但是在软件兼容方面

294
00:11:50,400 --> 00:11:51,800
确实也挺困难的

295
00:11:51,800 --> 00:11:53,800
很多厂商在软件兼容方面

296
00:11:53,800 --> 00:11:56,200
是做得非常之头痛的

297
00:11:56,200 --> 00:11:57,800
像未来的Pytorch 2.0

298
00:11:57,800 --> 00:11:59,000
确实有这种趋势

299
00:11:59,000 --> 00:12:02,400
慢慢的去做一些软件的南向的兼容

300
00:12:02,400 --> 00:12:04,200
第三层就是开放接口

301
00:12:04,200 --> 00:12:05,600
或者开放架构

302
00:12:05,600 --> 00:12:07,200
还有开放的生态

303
00:12:07,200 --> 00:12:09,200
形成整体的标准

304
00:12:09,200 --> 00:12:11,400
开放这个事情很重要

305
00:12:11,400 --> 00:12:14,400
那是上面硬件体系能够做的

306
00:12:14,400 --> 00:12:18,600
再往下就是开放整体的硬件的架构

307
00:12:18,600 --> 00:12:21,600
像RISC-V就是一个非常之开放的硬件架构

308
00:12:23,200 --> 00:12:24,600
第二个问题就是

309
00:12:24,600 --> 00:12:26,600
到底是硬件定义软件

310
00:12:26,600 --> 00:12:28,600
还是软件定义硬件

311
00:12:28,600 --> 00:12:31,000
在这么一个超异构架构平台里面

312
00:12:31,000 --> 00:12:34,200
我到底应该怎么去定义产品

313
00:12:34,200 --> 00:12:36,400
怎么定义解决方案呢

314
00:12:36,400 --> 00:12:37,800
那这个时候看一下

315
00:12:37,800 --> 00:12:39,400
所谓的软件定义硬件

316
00:12:39,400 --> 00:12:41,800
和硬件定义软件到底有什么区别

317
00:12:41,800 --> 00:12:43,200
那硬件定义软件

318
00:12:43,200 --> 00:12:44,600
这种其实是很明确的

319
00:12:44,600 --> 00:12:48,200
像CPU或者GPU就很明确

320
00:12:48,200 --> 00:12:49,400
硬件架构

321
00:12:49,400 --> 00:12:51,600
硬件的体系就这么定了

322
00:12:51,600 --> 00:12:52,600
你的软件

323
00:12:52,600 --> 00:12:54,800
你必须要去适配我的硬件

324
00:12:54,800 --> 00:12:57,800
你必须要去学CUDA是怎么写的

325
00:12:57,800 --> 00:13:00,400
你必须要学C++是怎么写的

326
00:13:00,600 --> 00:13:02,600
开发者才能够把他们的软件

327
00:13:02,600 --> 00:13:04,400
跑在具体的硬件上面

328
00:13:04,400 --> 00:13:06,000
而软件定义硬件

329
00:13:06,000 --> 00:13:08,000
其实这个也很好理解

330
00:13:08,000 --> 00:13:09,200
现在的AI应用

331
00:13:09,200 --> 00:13:10,400
大部分开发者

332
00:13:10,400 --> 00:13:12,400
都是基于PyTorch或者Python

333
00:13:12,400 --> 00:13:14,400
来去写他们的一些语言

334
00:13:14,400 --> 00:13:16,800
而这个时候他们并不是很关心

335
00:13:16,800 --> 00:13:18,200
我写完的Python

336
00:13:18,200 --> 00:13:19,800
到底是执行在GPU

337
00:13:19,800 --> 00:13:21,800
NPU还是TPU里面

338
00:13:21,800 --> 00:13:23,000
里面只要是要改了

339
00:13:23,000 --> 00:13:25,000
Torch.NPUTorch.Devices

340
00:13:25,000 --> 00:13:27,200
就可以执行在不同的硬件上面

341
00:13:27,200 --> 00:13:29,800
那这种就是软件定义硬件的

342
00:13:29,800 --> 00:13:31,000
一些Demo

343
00:13:31,000 --> 00:13:32,600
或者一个例子

344
00:13:32,600 --> 00:13:35,400
最后一种就是软硬件协同定义

345
00:13:35,400 --> 00:13:37,000
那这种其实现在来看

346
00:13:37,000 --> 00:13:39,000
没有太多相关的内容

347
00:13:39,000 --> 00:13:40,000
或者太多的Demo

348
00:13:40,000 --> 00:13:42,200
这也是在不断的演进当中

349
00:13:42,200 --> 00:13:47,000
确实衍生了越来越多的新的方式

350
00:13:47,000 --> 00:13:49,200
不管是硬件定义软件也好

351
00:13:49,200 --> 00:13:50,600
还是软件定义也好

352
00:13:50,600 --> 00:13:52,200
其实这个是跟

353
00:13:52,200 --> 00:13:54,600
整体系统复杂度是相关的

354
00:13:54,600 --> 00:13:58,000
CPU和GPU它有非常大的区别

355
00:13:58,200 --> 00:14:00,800
CPU就是我大部分都是比较擅长于

356
00:14:00,800 --> 00:14:01,600
逻辑控制

357
00:14:01,600 --> 00:14:03,600
还有一些操作系统的承载

358
00:14:03,600 --> 00:14:05,800
而GPU更多的是对图形图像

359
00:14:05,800 --> 00:14:08,800
或者并行计算的进行一些加速

360
00:14:08,800 --> 00:14:10,200
那其实整体来说

361
00:14:10,200 --> 00:14:11,400
不管是软件定义硬件

362
00:14:11,400 --> 00:14:13,200
还是硬件定义软件

363
00:14:13,200 --> 00:14:15,400
本质问题就是这个系统

364
00:14:15,400 --> 00:14:17,200
应该怎么去定义

365
00:14:17,200 --> 00:14:19,600
其实这个问题非常非常的抽象

366
00:14:19,600 --> 00:14:21,600
也非常非常的难回答

367
00:14:21,600 --> 00:14:22,800
而现在回顾一下

368
00:14:22,800 --> 00:14:25,800
整个计算的体系和编译的体系

369
00:14:25,800 --> 00:14:27,200
虽然计算系统

370
00:14:27,200 --> 00:14:29,200
或者超异构系统很难定义

371
00:14:29,200 --> 00:14:31,000
但很多时候更多的是

372
00:14:31,000 --> 00:14:33,600
依靠于编译体系去承载的

373
00:14:33,600 --> 00:14:37,400
具体的计算是由编译去决定的

374
00:14:37,400 --> 00:14:39,200
很多时候各类各样的应用

375
00:14:39,200 --> 00:14:42,200
大部分怎么跑在不同的芯片上面

376
00:14:42,200 --> 00:14:44,000
靠的就是编译体系

377
00:14:44,000 --> 00:14:45,000
而计算体系

378
00:14:45,000 --> 00:14:46,400
其实基本上都是定型的

379
00:14:46,400 --> 00:14:49,400
根据计算的原则来去定义

380
00:14:49,400 --> 00:14:51,200
有了这些计算的原则之后

381
00:14:51,200 --> 00:14:53,400
就需要去定义编译体系

382
00:14:53,400 --> 00:14:56,000
就需要反向的去对编译体系

383
00:14:56,000 --> 00:14:58,000
提出各种各样的需求

384
00:14:58,000 --> 00:14:59,800
最后来到最后一个内容

385
00:14:59,800 --> 00:15:02,400
就是在整体整个系统来看

386
00:15:02,400 --> 00:15:05,000
很重要的一个点就是计算的资源

387
00:15:05,000 --> 00:15:06,600
必须要中心化

388
00:15:06,600 --> 00:15:08,600
把不同的计算的孤岛连接起来

389
00:15:08,600 --> 00:15:09,600
把GPU连接起来

390
00:15:09,600 --> 00:15:11,000
把CPU连接起来

391
00:15:11,000 --> 00:15:12,400
把NPU连接起来

392
00:15:12,400 --> 00:15:14,600
实现整个资源的池化

393
00:15:14,600 --> 00:15:16,400
特别是计算资源的词化

394
00:15:16,400 --> 00:15:19,200
提升整体系统的算力利用率

395
00:15:19,200 --> 00:15:22,200
而不是单块芯片的算力利用率

396
00:15:22,200 --> 00:15:25,600
是整个系统的算力利用率

397
00:15:25,600 --> 00:15:27,800
那这个时候回顾一下

398
00:15:27,800 --> 00:15:30,400
刚才所讲的两个内容

399
00:15:30,400 --> 00:15:33,800
第一个就是跨平台统一整个计算架构

400
00:15:33,800 --> 00:15:38,000
把一些孤岛的计算资源连接起来

401
00:15:38,000 --> 00:15:40,000
第二点就是超异构时代

402
00:15:40,000 --> 00:15:42,800
要形成一个整体的开放的程序

403
00:15:42,800 --> 00:15:43,800
开放的生态

404
00:15:43,800 --> 00:15:45,400
让更多的计算资源

405
00:15:45,400 --> 00:15:48,000
连接到整个中心里面

406
00:15:48,000 --> 00:15:52,200
满足对更多的计算的渴求

407
00:15:52,200 --> 00:15:53,600
有了上面两个点之后

408
00:15:53,800 --> 00:15:55,600
就来到了软硬件

409
00:15:55,600 --> 00:15:57,000
需要共同的去定义

410
00:15:57,000 --> 00:15:58,200
而不像以前

411
00:15:58,200 --> 00:16:00,000
可能某个软件定硬件

412
00:16:00,000 --> 00:16:01,600
或者有硬件定义软件

413
00:16:01,600 --> 00:16:03,400
而是相互组成

414
00:16:03,400 --> 00:16:05,200
整个超异构生态开放

415
00:16:05,200 --> 00:16:08,200
去迎接未来新的应用场景

416
00:16:09,800 --> 00:16:13,000
针对未来计算体系的黄金十年

417
00:16:13,000 --> 00:16:15,000
总结了三个内容

418
00:16:15,000 --> 00:16:17,000
第一条就是超异构的计算架构

419
00:16:17,000 --> 00:16:19,800
确实已经开始慢慢到来了

420
00:16:19,800 --> 00:16:21,600
从CPU GPU FPGA到DSA

421
00:16:21,600 --> 00:16:24,400
到各种PU的融合

422
00:16:24,400 --> 00:16:26,200
第二个就是需要平台化

423
00:16:26,200 --> 00:16:27,600
可编程化

424
00:16:27,600 --> 00:16:29,000
第三个就是需要建立

425
00:16:29,000 --> 00:16:30,400
整个标准的体系

426
00:16:30,400 --> 00:16:32,200
还要开放整个生态的接口

427
00:16:32,200 --> 00:16:33,400
才能够让

428
00:16:33,400 --> 00:16:35,200
整个超异构的计算架构

429
00:16:35,200 --> 00:16:38,000
更好的发挥它的计算的算力

430
00:16:38,000 --> 00:16:41,000
更好的利用好每一个算力程序

431
00:16:41,000 --> 00:16:43,400
今天的内容就到这个为止

432
00:16:43,400 --> 00:16:45,000
虽然讲的有点虚

433
00:16:45,000 --> 00:16:45,800
谢谢各位

434
00:16:45,800 --> 00:16:46,400
拜了个拜

435
00:16:46,400 --> 00:16:48,400
卷的不行了卷的不行了

436
00:16:48,400 --> 00:16:50,400
记得一键三连加关注哦

437
00:16:50,400 --> 00:16:52,100
所有的内容都会开源在

438
00:16:52,100 --> 00:16:53,800
在下面这条链接里面

439
00:16:53,800 --> 00:16:54,600
拜了个拜

