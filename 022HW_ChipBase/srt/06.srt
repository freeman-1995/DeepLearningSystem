1
00:00:00,000 --> 00:00:04,440
字幕校对:米哈游天下第一

2
00:00:05,560 --> 00:00:09,120
哈喽大家好,我是那个又秃头来又发胖

3
00:00:09,120 --> 00:00:11,920
开头还得正能量的ZOMI

4
00:00:12,400 --> 00:00:16,680
每一节课呢,我都要能量满满的给大家去录课

5
00:00:16,680 --> 00:00:18,680
不然呢,大家会听得很无聊

6
00:00:19,120 --> 00:00:21,040
ZOMI发现录了100多期课呢

7
00:00:21,040 --> 00:00:22,560
我现在在B站上面呢

8
00:00:22,560 --> 00:00:25,720
赚的钱还没有达到提现的额度

9
00:00:26,040 --> 00:00:27,800
如果我有机会提现呢

10
00:00:27,800 --> 00:00:31,360
我会把这些钱呢,都捐给到中国儿童基金会

11
00:00:32,400 --> 00:00:35,960
今天的内容还是在AI芯片基础

12
00:00:35,960 --> 00:00:41,560
不过呢,之前其实讲了很多跟AI芯片没有相关的内容

13
00:00:41,560 --> 00:00:43,400
例如,通用处理器CPU呢

14
00:00:43,400 --> 00:00:47,840
怎么从数据去看CPU的计算的时延和内存的带宽

15
00:00:47,840 --> 00:00:52,200
接着呢,去了解了一下图形图像处理器GPU

16
00:00:52,200 --> 00:00:55,840
今天才正式的来到AI专用处理器

17
00:00:55,840 --> 00:00:58,120
叫做NPU也好,TPU也好

18
00:00:58,120 --> 00:01:00,440
都是一些专用的AI处理器

19
00:01:00,440 --> 00:01:05,800
那今天呢,简单的讲一讲AI专用处理器的一些基本的概念

20
00:01:05,800 --> 00:01:10,320
在后面的,应该是在下一节我会深入的去剖析GPU

21
00:01:10,320 --> 00:01:13,800
在下一下节呢,会深入的去讲讲NPU

22
00:01:14,240 --> 00:01:16,040
这里面呢,很有意思的就是

23
00:01:16,040 --> 00:01:18,200
ZOMI会用一些最近啊

24
00:01:18,200 --> 00:01:20,760
有重要性的代表的AI专用处理器

25
00:01:20,760 --> 00:01:22,160
华为昇腾的NPU呢

26
00:01:22,160 --> 00:01:23,280
谷歌的TPU呢

27
00:01:23,280 --> 00:01:25,080
还有特斯拉的DOJO呢

28
00:01:25,240 --> 00:01:27,840
包括一些国内外的其他的AI芯片

29
00:01:27,840 --> 00:01:29,840
去看看它们的一些整体的架构

30
00:01:29,840 --> 00:01:32,480
然后看一下它里面处理器有什么不一样

31
00:01:32,480 --> 00:01:36,880
从而去结束整个AI专用处理器里面的核心内容

32
00:01:36,880 --> 00:01:39,440
今天回到AI专用处理器呢

33
00:01:39,440 --> 00:01:41,040
主要有几个方面

34
00:01:41,040 --> 00:01:44,720
首先呢,看一下了解一下什么是AI芯片

35
00:01:44,720 --> 00:01:47,320
接着呢,去看看AI芯片的任务

36
00:01:47,320 --> 00:01:48,840
还有它的部署的情况

37
00:01:48,840 --> 00:01:51,200
也就是AI芯片用在哪里

38
00:01:51,200 --> 00:01:53,440
接着呢,去回顾

39
00:01:53,480 --> 00:01:57,920
去了解AI芯片的技术路线有几个选项

40
00:01:57,920 --> 00:02:00,520
最后就是AI芯片的应用场景了

41
00:02:00,520 --> 00:02:03,560
今天主要是分开这四部分给大家去汇报的

42
00:02:04,880 --> 00:02:06,960
首先看第一个内容

43
00:02:06,960 --> 00:02:09,200
什么是AI芯片呢

44
00:02:09,200 --> 00:02:10,360
AIchip

45
00:02:10,360 --> 00:02:12,760
NPU还有DPU

46
00:02:12,760 --> 00:02:14,000
首先AI芯片呢

47
00:02:14,000 --> 00:02:17,160
它属于一个特殊领域的一个体系结构

48
00:02:17,160 --> 00:02:19,960
叫Domain Specific Architecture

49
00:02:19,960 --> 00:02:21,000
在CPU上面呢

50
00:02:21,000 --> 00:02:24,440
可能会执行一些非常之通用的应用程序

51
00:02:24,440 --> 00:02:25,880
那某些应用程序呢

52
00:02:25,880 --> 00:02:30,440
可能会通过特殊的专用的芯片进行加速

53
00:02:30,440 --> 00:02:31,080
所以这个呢

54
00:02:31,080 --> 00:02:33,080
通常叫做DSA

55
00:02:33,080 --> 00:02:33,680
假设呢

56
00:02:33,680 --> 00:02:35,200
所有的内容呢

57
00:02:35,200 --> 00:02:36,880
都是围绕着应用来走的

58
00:02:36,880 --> 00:02:37,400
旁边呢

59
00:02:37,400 --> 00:02:41,440
就会出现非常多不同的特殊的芯片

60
00:02:41,440 --> 00:02:43,840
例如现在的解码的芯片呢

61
00:02:43,840 --> 00:02:45,640
还有FPGA的芯片呢

62
00:02:45,640 --> 00:02:47,920
都是属于一些专用领域的芯片

63
00:02:47,920 --> 00:02:49,120
叫做DSA

64
00:02:49,120 --> 00:02:50,080
那它的好处呢

65
00:02:50,080 --> 00:02:54,600
就是可以专门针对某一类型的应用作为加速的

66
00:02:54,600 --> 00:02:58,600
最开始的就有之前提到过的图形图像处理器

67
00:02:58,600 --> 00:02:59,520
GPU

68
00:02:59,520 --> 00:02:59,960
当然了

69
00:02:59,960 --> 00:03:01,720
它现在叫做GPGPU了

70
00:03:01,720 --> 00:03:05,240
就不仅仅能够处理一些图形图像的加速

71
00:03:05,240 --> 00:03:07,640
还能够处理很多并行的内容

72
00:03:07,640 --> 00:03:08,760
今天的主角呢

73
00:03:08,760 --> 00:03:10,640
主要是AI芯片

74
00:03:10,640 --> 00:03:11,880
叫做AI加速器

75
00:03:11,880 --> 00:03:13,120
AI计算卡多好

76
00:03:13,120 --> 00:03:16,680
它是专门用来处理AI应用

77
00:03:16,680 --> 00:03:17,960
神经网络

78
00:03:17,960 --> 00:03:19,800
深度学习

79
00:03:19,800 --> 00:03:23,000
专门对这一类的计算进行加速的

80
00:03:23,000 --> 00:03:25,320
叫做AI芯片

81
00:03:25,320 --> 00:03:27,280
往右边的这个图一看呢

82
00:03:27,280 --> 00:03:30,600
就是AI芯片里面的Dataflow的架构

83
00:03:30,600 --> 00:03:31,680
可以看到这里面呢

84
00:03:31,680 --> 00:03:33,560
有非常多的feature map

85
00:03:33,560 --> 00:03:35,200
还有那个Input Kernel

86
00:03:35,200 --> 00:03:36,120
这些内容呢

87
00:03:36,120 --> 00:03:37,760
都写在硬件上面

88
00:03:37,760 --> 00:03:38,920
都是以AI

89
00:03:38,920 --> 00:03:41,760
都是以神经网络的计算模式

90
00:03:41,760 --> 00:03:46,240
作为芯片的硬件的基础和设计的原则

91
00:03:46,240 --> 00:03:46,720
下面呢

92
00:03:46,720 --> 00:03:48,120
来看看AI芯片

93
00:03:48,160 --> 00:03:50,960
CPU跟GPU最大的架构的差异

94
00:03:50,960 --> 00:03:52,480
下面的这三个图呢

95
00:03:52,480 --> 00:03:54,840
就是最简单的一个架构图

96
00:03:54,840 --> 00:03:55,440
CPU呢

97
00:03:55,440 --> 00:03:57,320
可以看到大部分的工作呢

98
00:03:57,320 --> 00:03:59,240
都是在做一个控制

99
00:03:59,240 --> 00:03:59,760
里面呢

100
00:03:59,760 --> 00:04:03,440
就占了芯片电路面积的大部分

101
00:04:03,440 --> 00:04:05,640
而里面的计算单元呢

102
00:04:05,640 --> 00:04:07,120
其实并不多啊

103
00:04:07,120 --> 00:04:09,760
经常谈到的4核8核

104
00:04:09,760 --> 00:04:11,560
到现在的32核

105
00:04:11,560 --> 00:04:13,560
它的核数还是非常的少的

106
00:04:13,560 --> 00:04:15,000
而了解到GPU呢

107
00:04:15,000 --> 00:04:17,080
可以看到里面的SM数啊

108
00:04:17,080 --> 00:04:19,840
里面的计算单元就有3000个

109
00:04:19,840 --> 00:04:21,160
是非常的夸张

110
00:04:21,160 --> 00:04:25,200
而这里面GPU的控制单元反倒是很少

111
00:04:25,200 --> 00:04:26,680
但NPU呢

112
00:04:26,680 --> 00:04:29,040
更多的是以AI core

113
00:04:29,040 --> 00:04:31,200
Tensor core这种方式呢

114
00:04:31,200 --> 00:04:32,880
进行一个加速的

115
00:04:32,880 --> 00:04:33,880
那这个AI core呢

116
00:04:33,880 --> 00:04:37,960
就是专门用来加速神经网络里面的卷积啊

117
00:04:37,960 --> 00:04:38,720
Transformer啊

118
00:04:38,720 --> 00:04:40,320
MatMul这种计算

119
00:04:41,920 --> 00:04:42,520
下面呢

120
00:04:42,520 --> 00:04:44,320
看看第二个内容

121
00:04:44,320 --> 00:04:45,440
AI芯片的任务

122
00:04:45,440 --> 00:04:46,760
还有它的部署

123
00:04:46,800 --> 00:04:48,800
Text and Development

124
00:04:50,320 --> 00:04:53,240
在AI芯片里面的任务分为两种

125
00:04:53,240 --> 00:04:53,840
第一种呢

126
00:04:53,840 --> 00:04:55,000
就是训练

127
00:04:55,000 --> 00:04:55,600
第二种呢

128
00:04:55,600 --> 00:04:56,840
就是推理

129
00:04:56,840 --> 00:04:57,560
那训练呢

130
00:04:57,560 --> 00:04:58,600
大家都知道了

131
00:04:58,600 --> 00:04:59,960
我简单的去讲讲

132
00:04:59,960 --> 00:05:00,400
训练呢

133
00:05:00,400 --> 00:05:00,880
首先呢

134
00:05:00,880 --> 00:05:03,960
需要输入一系列的数据集

135
00:05:03,960 --> 00:05:04,600
那这里面呢

136
00:05:04,600 --> 00:05:05,560
可能以mini-batch

137
00:05:05,560 --> 00:05:06,120
micro-batch

138
00:05:06,120 --> 00:05:08,600
或者bit-batch的方式呢

139
00:05:08,600 --> 00:05:09,320
数据呢

140
00:05:09,320 --> 00:05:10,720
输进去神经网络里面呢

141
00:05:10,720 --> 00:05:11,920
进行前向的计算

142
00:05:11,920 --> 00:05:12,360
并且呢

143
00:05:12,360 --> 00:05:14,600
计算出具体的损失值

144
00:05:14,640 --> 00:05:15,200
然后呢

145
00:05:15,200 --> 00:05:16,800
通过反向传播

146
00:05:16,800 --> 00:05:18,520
就反向梯度的计算呢

147
00:05:18,520 --> 00:05:19,400
利用优化器呢

148
00:05:19,400 --> 00:05:22,080
来更新整个网络模型

149
00:05:22,080 --> 00:05:23,960
使得总体的损失

150
00:05:23,960 --> 00:05:25,640
lost最小

151
00:05:25,640 --> 00:05:26,080
这个呢

152
00:05:26,080 --> 00:05:29,160
就是计算的本质和计算的原理

153
00:05:29,160 --> 00:05:29,640
接着呢

154
00:05:29,640 --> 00:05:30,480
计算完之后呢

155
00:05:30,480 --> 00:05:31,920
就会导到推理

156
00:05:31,920 --> 00:05:33,640
真正的应用部署

157
00:05:33,640 --> 00:05:34,480
那推理的时候呢

158
00:05:34,480 --> 00:05:35,320
因为刚才呢

159
00:05:35,320 --> 00:05:37,400
已经把神经网络啊

160
00:05:37,400 --> 00:05:38,360
固化下来了

161
00:05:38,360 --> 00:05:39,480
权重参数啊

162
00:05:39,480 --> 00:05:40,920
都已经训练学习好了

163
00:05:40,920 --> 00:05:41,560
于是呢

164
00:05:41,560 --> 00:05:43,840
只需要拿出一小部分的数据

165
00:05:43,840 --> 00:05:44,880
真实的数据

166
00:05:44,880 --> 00:05:46,640
然后执行一个前向

167
00:05:46,640 --> 00:05:47,160
最终呢

168
00:05:47,160 --> 00:05:49,320
就得到分类预测检测

169
00:05:49,320 --> 00:05:51,560
生成不同的任务

170
00:05:51,560 --> 00:05:52,880
不同的结果

171
00:05:54,360 --> 00:05:55,720
AI芯片的部署方式呢

172
00:05:55,720 --> 00:05:57,040
有非常的多啊

173
00:05:57,040 --> 00:05:58,480
主要有端边云

174
00:05:58,480 --> 00:06:00,200
那现在来看看云测呢

175
00:06:00,200 --> 00:06:02,520
主要是部署一些训练的芯片

176
00:06:02,520 --> 00:06:03,280
训练的卡

177
00:06:03,280 --> 00:06:04,080
而边缘呢

178
00:06:04,080 --> 00:06:05,320
就是边缘设备啊

179
00:06:05,320 --> 00:06:06,320
手机啊耳机啊

180
00:06:06,320 --> 00:06:07,000
手环啊

181
00:06:07,000 --> 00:06:10,440
这些真正的去运行一些具体的应用

182
00:06:10,440 --> 00:06:11,040
那当然呢

183
00:06:11,040 --> 00:06:12,560
还有一些端侧的

184
00:06:12,560 --> 00:06:13,560
例如摄像头了

185
00:06:13,560 --> 00:06:14,960
小型基站了

186
00:06:14,960 --> 00:06:16,520
在不同的部署形态里面呢

187
00:06:16,520 --> 00:06:17,760
会部署不同的应用

188
00:06:17,760 --> 00:06:19,920
还有不同的芯片系列

189
00:06:21,240 --> 00:06:21,680
下面呢

190
00:06:21,680 --> 00:06:22,840
再继续展开一下

191
00:06:22,840 --> 00:06:24,360
其实在推理引擎里面呢

192
00:06:24,360 --> 00:06:26,960
我已经给大家去介绍过这一系列的内容

193
00:06:26,960 --> 00:06:28,320
下面简单的看看

194
00:06:28,320 --> 00:06:29,960
其实它有非常多的方式

195
00:06:29,960 --> 00:06:31,080
例如边缘的设备了

196
00:06:31,080 --> 00:06:32,920
主要是部署一些小模型

197
00:06:32,920 --> 00:06:33,360
然后呢

198
00:06:33,360 --> 00:06:36,160
边缘设备跟边缘服务器呢

199
00:06:36,160 --> 00:06:38,400
就是端边协同的时候呢

200
00:06:38,400 --> 00:06:40,880
可能就会由边缘进行决策

201
00:06:40,880 --> 00:06:42,120
然后较大的模型呢

202
00:06:42,120 --> 00:06:43,280
在边缘服务器

203
00:06:43,280 --> 00:06:44,760
在端侧进行学习

204
00:06:44,760 --> 00:06:45,520
那第三种呢

205
00:06:45,520 --> 00:06:49,360
就是边和云进行协同操作

206
00:06:49,360 --> 00:06:51,640
那第四种就是刚才讲到的三种

207
00:06:51,640 --> 00:06:53,920
端边云进行同时协同

208
00:06:53,920 --> 00:06:55,440
第五种其实也是端边云

209
00:06:55,440 --> 00:06:56,920
进行同时协同的方式

210
00:06:56,920 --> 00:06:58,960
所以说AI芯片的部署方式呢

211
00:06:58,960 --> 00:07:01,040
不仅仅能够完全部署在云端

212
00:07:01,040 --> 00:07:02,240
完全部署在边端

213
00:07:02,240 --> 00:07:04,200
或者完全部署在端侧

214
00:07:04,200 --> 00:07:06,840
端边云都有可能去部署的

215
00:07:06,840 --> 00:07:09,880
这个也是不知道是华为内部的一个概念

216
00:07:09,880 --> 00:07:11,600
还是大家业界通用的概念呢

217
00:07:11,640 --> 00:07:13,520
反正华为的设备非常的多嘛

218
00:07:14,720 --> 00:07:16,760
接下来呢来到第三个内容

219
00:07:16,760 --> 00:07:19,800
就是AI芯片的技术路线

220
00:07:19,800 --> 00:07:22,280
它的AI chip roadmap

221
00:07:22,280 --> 00:07:22,880
首先呢

222
00:07:22,880 --> 00:07:24,240
AI芯片的部署路线呢

223
00:07:24,240 --> 00:07:24,960
有三种

224
00:07:24,960 --> 00:07:25,440
第一种呢

225
00:07:25,440 --> 00:07:27,120
就是大家用的非常多

226
00:07:27,120 --> 00:07:30,200
上一节给大家去普及过的GPU

227
00:07:30,200 --> 00:07:30,720
第二种呢

228
00:07:30,720 --> 00:07:32,000
就是FPGA

229
00:07:32,000 --> 00:07:33,640
第三种就是ASIC

230
00:07:33,640 --> 00:07:34,720
可以看到呢

231
00:07:34,720 --> 00:07:35,960
像定制化程度呢

232
00:07:35,960 --> 00:07:38,120
GPU是做的最通用的

233
00:07:38,120 --> 00:07:38,680
而FPGA呢

234
00:07:38,680 --> 00:07:41,760
ASKA是不是说那么的通用

235
00:07:41,760 --> 00:07:43,360
而编程语言就很有意思了

236
00:07:43,360 --> 00:07:44,360
像GPU呢

237
00:07:44,360 --> 00:07:46,480
它有那个CUDA跟OpenCL

238
00:07:46,480 --> 00:07:47,360
那上一节呢

239
00:07:47,360 --> 00:07:48,600
我其实给大家讲过了

240
00:07:48,600 --> 00:07:49,960
CUDA是英伟达推出的

241
00:07:49,960 --> 00:07:50,680
OpenCL呢

242
00:07:50,680 --> 00:07:52,200
是苹果推出的

243
00:07:52,200 --> 00:07:53,120
而FPGA呢

244
00:07:53,120 --> 00:07:54,160
都有自己的硬件

245
00:07:54,160 --> 00:07:56,640
当然它也可以对接到那个OpenCL里面

246
00:07:56,640 --> 00:07:57,560
而ASKA里面呢

247
00:07:57,560 --> 00:07:58,200
其实现在呢

248
00:07:58,200 --> 00:08:01,160
没有太多对应的特殊的编程语言

249
00:08:01,160 --> 00:08:02,040
那你说TVM呢

250
00:08:02,040 --> 00:08:03,600
它可能是其中一种啊

251
00:08:03,600 --> 00:08:05,280
但不完全属于

252
00:08:05,280 --> 00:08:05,840
另外的话

253
00:08:05,840 --> 00:08:07,920
主要的那个优点

254
00:08:07,920 --> 00:08:11,960
就是GPU整体的产品的成熟度

255
00:08:11,960 --> 00:08:13,240
是非常的高

256
00:08:13,240 --> 00:08:14,000
峰值算力呢

257
00:08:14,000 --> 00:08:15,200
也是非常的高

258
00:08:15,200 --> 00:08:16,000
而ASIC呢

259
00:08:16,000 --> 00:08:17,720
是非常的专用

260
00:08:17,720 --> 00:08:19,080
整体功耗呢

261
00:08:19,080 --> 00:08:20,920
会降得非常非常的低

262
00:08:20,920 --> 00:08:22,040
包括现在啊

263
00:08:22,040 --> 00:08:23,480
我手机应该是华为手机

264
00:08:23,480 --> 00:08:24,480
麒麟手机里面

265
00:08:24,480 --> 00:08:27,520
就内置了自己的NPU

266
00:08:27,520 --> 00:08:27,880
下面呢

267
00:08:27,880 --> 00:08:30,800
逐个的去简单的给大家过一下

268
00:08:30,800 --> 00:08:33,000
后面会深入的去剖析的

269
00:08:33,000 --> 00:08:34,720
就在下一个专题里面

270
00:08:34,720 --> 00:08:35,320
GPU呢

271
00:08:35,320 --> 00:08:37,640
主要是由大量的计算核组成的

272
00:08:37,640 --> 00:08:39,120
大规模的并行的架构

273
00:08:39,120 --> 00:08:39,800
那以前呢

274
00:08:39,800 --> 00:08:42,680
一开始它是专门用来处理图形图像的

275
00:08:42,680 --> 00:08:45,000
就对像素点进行显示啊

276
00:08:45,000 --> 00:08:45,880
进行计算

277
00:08:45,880 --> 00:08:46,520
它的优点呢

278
00:08:46,520 --> 00:08:48,800
就是并行的计算度非常的高

279
00:08:48,800 --> 00:08:51,240
超过80%的电路面积啊

280
00:08:51,240 --> 00:08:53,600
都是运算单元

281
00:08:53,600 --> 00:08:54,360
左边这个呢

282
00:08:54,360 --> 00:08:55,960
就是GPU的架构简图

283
00:08:55,960 --> 00:08:56,680
右边的这个呢

284
00:08:56,680 --> 00:08:59,080
就是GPU的一个自己的内部的设计图

285
00:08:59,080 --> 00:09:02,080
那当然了是针对英伟达的硬件

286
00:09:02,080 --> 00:09:03,600
下面看一下AI芯片的

287
00:09:03,600 --> 00:09:06,360
第二个硬件的设计的方式就是FPGA

288
00:09:06,360 --> 00:09:07,160
FPGA呢

289
00:09:07,160 --> 00:09:11,000
它其实叫做Field-Programmable Gate Array

290
00:09:11,000 --> 00:09:13,280
现场可编程门阵列

291
00:09:13,280 --> 00:09:15,600
FPGA呢属于一种半定制的电路啊

292
00:09:15,600 --> 00:09:18,160
主要是可以由用户去定义这些门控电路

293
00:09:18,160 --> 00:09:19,760
和存储器之间的部署

294
00:09:19,760 --> 00:09:22,400
非常方便快速的整合整个方案

295
00:09:22,400 --> 00:09:23,440
我觉得FPGA呢

296
00:09:23,440 --> 00:09:26,200
比较适用于多指令单数据流的这种方式

297
00:09:26,200 --> 00:09:27,280
而FPGA呢

298
00:09:27,280 --> 00:09:29,720
主要适用于推理的阶段

299
00:09:29,720 --> 00:09:31,520
推理的场景用的非常的多

300
00:09:31,520 --> 00:09:32,160
但缺点呢

301
00:09:32,160 --> 00:09:35,520
就是价格不是说非常太具备优势

302
00:09:35,520 --> 00:09:37,120
针对硬件专用的芯片呢

303
00:09:37,120 --> 00:09:37,840
FPGA呢

304
00:09:37,840 --> 00:09:41,640
其实已经提供了一条比较完善成熟的链条

305
00:09:41,640 --> 00:09:44,040
供芯片开发工程师和软件开发工程师呢

306
00:09:44,040 --> 00:09:46,120
遵循这条链条呢去开发

307
00:09:46,120 --> 00:09:46,960
右边这个图呢

308
00:09:46,960 --> 00:09:51,040
就是FPGA针对DSA的一种架构图

309
00:09:51,040 --> 00:09:52,960
接下来看第三个内容

310
00:09:52,960 --> 00:09:53,920
ASIC

311
00:09:53,920 --> 00:09:54,520
ASIC呢

312
00:09:54,520 --> 00:09:56,360
就是专用的集成电路了

313
00:09:56,360 --> 00:09:59,400
Application Specific Integrated Circuit

314
00:09:59,400 --> 00:10:01,040
专用集成电路

315
00:10:01,040 --> 00:10:02,400
里面的专用集成电路呢

316
00:10:02,400 --> 00:10:05,600
就是真的针对某一类型的应用去设计的

317
00:10:05,600 --> 00:10:07,320
没有一套设计的规范

318
00:10:07,320 --> 00:10:07,760
但是呢

319
00:10:07,760 --> 00:10:09,120
这个专用的集成电路呢

320
00:10:09,120 --> 00:10:10,920
没有太多的冗余的架构

321
00:10:10,920 --> 00:10:14,800
主要是专门针对某一个类型的应用去设计的

322
00:10:14,800 --> 00:10:16,920
所以在大规模量产的时候呢

323
00:10:16,920 --> 00:10:18,120
具备性能更强

324
00:10:18,120 --> 00:10:18,640
体积更小

325
00:10:18,640 --> 00:10:19,280
功耗更高

326
00:10:19,280 --> 00:10:22,120
成本更低的一些优点

327
00:10:22,120 --> 00:10:23,160
ASIC卡呢

328
00:10:23,160 --> 00:10:24,920
跟GPU和FPGA不同的就是

329
00:10:24,920 --> 00:10:27,760
它不仅是一种技术路线的选型

330
00:10:27,800 --> 00:10:31,640
它还是一种实实在在的产品的形态

331
00:10:31,640 --> 00:10:32,840
每一款AI芯片呢

332
00:10:32,840 --> 00:10:34,600
假设采用的是ASIC啊

333
00:10:34,600 --> 00:10:37,000
里面的架构设计也是千奇百怪的

334
00:10:37,000 --> 00:10:37,720
而GPU呢

335
00:10:37,720 --> 00:10:38,320
FPGA呢

336
00:10:38,320 --> 00:10:40,760
它是有一定的规律可言

337
00:10:40,760 --> 00:10:41,760
既然谈到这个点呢

338
00:10:41,760 --> 00:10:44,400
我就简单的给大家去剧透一下

339
00:10:44,400 --> 00:10:45,040
下面这个呢

340
00:10:45,040 --> 00:10:47,760
就是TPU的整体的架构骨骼开发出来的

341
00:10:47,760 --> 00:10:49,240
左边这个它的数据流

342
00:10:49,240 --> 00:10:52,840
右边这个它的芯片的摆放的位置和芯片的架构

343
00:10:52,840 --> 00:10:54,800
那最后一个点呢

344
00:10:54,800 --> 00:10:57,640
就是AI芯片的应用场景

345
00:10:57,640 --> 00:11:00,200
Application AI芯片能用在哪些地方了

346
00:11:00,200 --> 00:11:02,360
其实AI芯片在用的越来越多了

347
00:11:02,360 --> 00:11:04,720
包括现在的计算中心

348
00:11:04,720 --> 00:11:07,120
大家玩手机玩抖音玩的这么开心

349
00:11:07,120 --> 00:11:09,480
各种变脸各种变装各种美颜

350
00:11:09,480 --> 00:11:10,680
这些后面呢

351
00:11:10,680 --> 00:11:13,280
其实不是你手机在实时的计算

352
00:11:13,280 --> 00:11:16,480
而是背后的AI计算中心在实时的计算

353
00:11:16,480 --> 00:11:18,080
那第二个就是自动驾驶

354
00:11:18,080 --> 00:11:20,040
其实我是深受其苦的

355
00:11:20,040 --> 00:11:23,640
经常开车的时候堵车堵得非常的严重

356
00:11:23,640 --> 00:11:24,600
很多时候堵车呢

357
00:11:24,600 --> 00:11:27,360
我为什么还要看着前面一台车走了没走

358
00:11:27,360 --> 00:11:29,480
现在有很多半自动驾驶的应用场景

359
00:11:29,480 --> 00:11:30,360
里面的车机呢

360
00:11:30,360 --> 00:11:32,280
就装了非常多AI芯片

361
00:11:32,280 --> 00:11:33,920
在里面实时的去计算

362
00:11:33,920 --> 00:11:34,800
其实很多时候

363
00:11:34,800 --> 00:11:36,440
现在整个安防系统

364
00:11:36,440 --> 00:11:37,760
已经做得非常的好

365
00:11:37,760 --> 00:11:38,640
摄像头里面呢

366
00:11:38,640 --> 00:11:40,080
就内嵌了一个AI芯片

367
00:11:40,080 --> 00:11:41,680
然后通过实时的去计算

368
00:11:41,680 --> 00:11:42,880
闯红灯的车牌号码

369
00:11:42,880 --> 00:11:44,400
还有计算那段录影呢

370
00:11:44,400 --> 00:11:46,000
回传到AI的计算中心

371
00:11:46,000 --> 00:11:47,040
给后台的人员呢

372
00:11:47,040 --> 00:11:48,040
进行审核

373
00:11:48,040 --> 00:11:50,000
大量的侦查检测识别的工作呢

374
00:11:50,000 --> 00:11:52,800
都交到AI芯片了

375
00:11:52,800 --> 00:11:54,400
到了IOT设备

376
00:11:54,400 --> 00:11:55,880
这个就是经常用到的

377
00:11:55,880 --> 00:11:58,320
手机里面的AI功能

378
00:11:58,320 --> 00:11:58,960
这里面呢

379
00:11:58,960 --> 00:12:00,720
是以应用场景去区分的

380
00:12:00,720 --> 00:12:02,600
而针对不同的应用场景呢

381
00:12:02,600 --> 00:12:05,240
就推出一系列不同的芯片

382
00:12:05,240 --> 00:12:06,440
像在计算中心呢

383
00:12:06,440 --> 00:12:08,520
可能用的芯片会非常的高端

384
00:12:08,520 --> 00:12:10,360
而且功耗呢也是非常的高

385
00:12:10,360 --> 00:12:10,760
当然了

386
00:12:10,760 --> 00:12:12,200
在一些embedded

387
00:12:12,200 --> 00:12:13,760
在一些IOT测试设备呢

388
00:12:13,760 --> 00:12:15,600
可能会采用不同的类型

389
00:12:15,600 --> 00:12:17,240
在一些自动驾驶呢

390
00:12:17,240 --> 00:12:20,200
里面也会采用不同类型的芯片

391
00:12:20,200 --> 00:12:21,880
所以说针对不同的应用场景

392
00:12:21,880 --> 00:12:24,080
都会推出不同的应用芯片

393
00:12:24,120 --> 00:12:26,200
它们的峰值算力是不一样的

394
00:12:26,200 --> 00:12:28,080
它们的消耗的网速

395
00:12:28,080 --> 00:12:30,160
它们的功耗也是不一样的

396
00:12:30,160 --> 00:12:30,960
所以这里面呢

397
00:12:30,960 --> 00:12:33,120
就有很多的讲究

398
00:12:33,120 --> 00:12:34,680
针对不同的应用场景

399
00:12:34,680 --> 00:12:36,920
要推出不同的AI芯片

400
00:12:36,920 --> 00:12:39,400
和不同的系列产品

401
00:12:39,400 --> 00:12:40,120
下面这个呢

402
00:12:40,120 --> 00:12:42,600
就是华为从2012年呢

403
00:12:42,600 --> 00:12:44,120
推出的一个Mate系列

404
00:12:44,120 --> 00:12:45,880
到19年的时候

405
00:12:45,880 --> 00:12:47,840
应该是我现在使用的手机了

406
00:12:47,840 --> 00:12:49,080
这一代系列里面呢

407
00:12:49,080 --> 00:12:52,160
其实我经常在里面会插播很多

408
00:12:52,160 --> 00:12:53,240
关于华为的产品啊

409
00:12:53,240 --> 00:12:54,840
或者大部分都会用昇腾

410
00:12:54,840 --> 00:12:57,120
是因为我现在是在菊厂里面工作

411
00:12:57,120 --> 00:12:59,040
作为里面其中的一个

412
00:12:59,040 --> 00:13:00,840
研发工程师或者专家也好

413
00:13:00,840 --> 00:13:02,240
很多人都会问我是不是学生

414
00:13:02,240 --> 00:13:03,680
我告诉你我不是学生

415
00:13:03,680 --> 00:13:05,360
我已经毕业很多年了

416
00:13:05,360 --> 00:13:07,160
也是从17年开始

417
00:13:07,160 --> 00:13:09,720
不管是苹果还是高通联发科啊

418
00:13:09,720 --> 00:13:12,800
很多的芯片厂商或者手机厂商呢

419
00:13:12,800 --> 00:13:15,920
都慢慢地加持了非常多的AI的应用

420
00:13:15,920 --> 00:13:17,880
也会把自己的一些AI的chip

421
00:13:17,880 --> 00:13:18,920
AI的IP呢

422
00:13:18,920 --> 00:13:21,080
融合到中高端产品里面

423
00:13:21,080 --> 00:13:23,080
当然包括手机手表

424
00:13:23,080 --> 00:13:25,600
手环这些其实也结合了非常多

425
00:13:25,600 --> 00:13:27,320
新的AI的功能

426
00:13:27,320 --> 00:13:29,320
而现在像麒麟9000里面

427
00:13:29,320 --> 00:13:31,040
还有麒麟9000E里面

428
00:13:31,040 --> 00:13:35,360
里面就有一个非常之有意思的NPU

429
00:13:35,360 --> 00:13:37,240
神经网络处理单元

430
00:13:37,240 --> 00:13:40,360
这么针对AI应用的加速进行计算

431
00:13:40,360 --> 00:13:41,120
那最后呢

432
00:13:41,120 --> 00:13:44,920
回到整体的AI芯片基础

433
00:13:44,920 --> 00:13:45,880
今天的内容呢

434
00:13:45,880 --> 00:13:46,600
其实并不多

435
00:13:46,600 --> 00:13:47,560
而且比较简单

436
00:13:47,560 --> 00:13:49,440
看了一下什么是AI芯片

437
00:13:49,440 --> 00:13:50,640
AI芯片有什么用

438
00:13:50,640 --> 00:13:51,880
然后AI的任务呢

439
00:13:51,880 --> 00:13:53,560
主要分开训练和推理

440
00:13:53,560 --> 00:13:55,760
当然了部署分为端边云

441
00:13:55,760 --> 00:13:57,280
三种部署形态

442
00:13:57,280 --> 00:13:57,720
接着呢

443
00:13:57,720 --> 00:14:00,080
看了一下AI芯片的技术路线

444
00:14:00,080 --> 00:14:01,960
有GPU FPGA ASIC

445
00:14:01,960 --> 00:14:02,680
在最后呢

446
00:14:02,680 --> 00:14:06,040
看一下AI芯片的四大应用场景

447
00:14:06,040 --> 00:14:09,120
从计算中心到手机IoT设备

448
00:14:09,120 --> 00:14:10,200
那今天的内容呢

449
00:14:10,200 --> 00:14:10,960
就这么多

450
00:14:10,960 --> 00:14:12,080
谢谢各位

451
00:14:12,080 --> 00:14:13,480
拜了拜拜

452
00:14:13,480 --> 00:14:14,280
卷的不行了

453
00:14:14,280 --> 00:14:15,160
卷的不行了

454
00:14:15,160 --> 00:14:16,960
记得一键三连加关注哦

455
00:14:16,960 --> 00:14:20,560
所有的内容都会开源在下面这条链接里面

456
00:14:20,560 --> 00:14:21,400
拜了个拜

