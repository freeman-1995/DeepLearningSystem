1
00:00:00,000 --> 00:00:05,760
字幕校对:米哈游天下第一

2
00:00:05,760 --> 00:00:07,760
哈喽大家好,我是ZOMI

3
00:00:07,760 --> 00:00:11,200
我发现环境真的会影响人类的身体健康的

4
00:00:11,200 --> 00:00:15,600
我在办公室的时候经常头疼、腰疼、屁股疼

5
00:00:15,600 --> 00:00:18,920
回到家之后我发现哪都不疼了

6
00:00:18,920 --> 00:00:22,800
今天还是在AI芯片基础这一个大系列里面

7
00:00:22,800 --> 00:00:26,240
今天我要给大家去分享的就是计算的时延

8
00:00:26,240 --> 00:00:27,760
Latency

9
00:00:27,760 --> 00:00:30,120
来看看计算时延有什么不一样

10
00:00:30,120 --> 00:00:36,400
今天主要还是在从数据看CPU计算这一个小内容里面

11
00:00:36,400 --> 00:00:41,400
假设在CPU里面数据的读取速度是200GB每second

12
00:00:41,400 --> 00:00:45,960
而CPU的FLOPS计算能力是2000GFLOPS

13
00:00:45,960 --> 00:00:48,040
对应的单位都是FP16

14
00:00:48,040 --> 00:00:52,240
这个时候计算的强度就等于FLOPS除以Data Rate

15
00:00:52,240 --> 00:00:55,800
就是数据的传输速率得到一个80的值

16
00:00:55,840 --> 00:01:01,480
那这个80的值就意味着对每一个数据都要进行80次操作

17
00:01:01,480 --> 00:01:05,800
才能够达到一种计算跟数据传输速率的平衡

18
00:01:05,800 --> 00:01:07,495
所以在前一节课里面

19
00:01:07,495 --> 00:01:07,520
ZOMI就给大家汇报了CPU里面实际上FLOPS不是说最重要的

20
00:01:07,520 --> 00:01:12,615
ZOMI就给大家汇报了CPU里面实际上FLOPS不是说最重要的

21
00:01:12,640 --> 00:01:15,080
更重要的是数据传输的速率

22
00:01:15,080 --> 00:01:17,520
数据应该怎么去算

23
00:01:19,000 --> 00:01:23,320
现在继续回到AX+B这个例子

24
00:01:23,320 --> 00:01:24,840
去看看整体的demo

25
00:01:24,840 --> 00:01:28,800
那下面就是AX+B的一个C++的代码

26
00:01:28,800 --> 00:01:31,120
里面就有两个运算

27
00:01:31,120 --> 00:01:32,640
那一个就是加法

28
00:01:32,640 --> 00:01:34,640
一个就是乘法

29
00:01:34,640 --> 00:01:37,360
而这里面有两个内存的读取

30
00:01:37,360 --> 00:01:39,920
内存的读取第一个就是X[i]

31
00:01:39,920 --> 00:01:41,280
第二个就是Y[i]

32
00:01:41,280 --> 00:01:43,120
都是逐个元素的去读取的

33
00:01:43,120 --> 00:01:48,640
这一条公式展开就变成Y=AX+B这种方式了

34
00:01:48,640 --> 00:01:51,680
而这里面有一个独特的操作

35
00:01:51,680 --> 00:01:54,840
就是可以用一个指令来去代替

36
00:01:54,840 --> 00:01:58,040
例如FMA FUSED MULTIPLY-ADD

37
00:01:58,040 --> 00:02:00,800
就是把乘法和加法融合成一个指令

38
00:02:00,800 --> 00:02:04,200
当然了在之前也讲过可以叫做MAC

39
00:02:04,200 --> 00:02:05,600
通过这么一个简单的例子

40
00:02:05,600 --> 00:02:09,280
去看看整体的时延是怎么产生的

41
00:02:09,280 --> 00:02:11,480
下面以这个图

42
00:02:11,480 --> 00:02:13,840
这个图就是指令的流水

43
00:02:13,840 --> 00:02:16,320
叫做INSTRUCTION PIPELINE

44
00:02:16,320 --> 00:02:18,160
整体的指令流水

45
00:02:18,160 --> 00:02:21,000
下面打开看看这个指令流水

46
00:02:21,000 --> 00:02:23,400
首先需要从内存里面

47
00:02:23,400 --> 00:02:26,360
去读取一个元素x[0]

48
00:02:26,360 --> 00:02:29,920
接着同时去读取另外一个元素y[0]

49
00:02:29,920 --> 00:02:32,480
因为x[0]和y[0]之间没有依赖关系

50
00:02:32,480 --> 00:02:36,200
所以可以同时的从DRAM里面去读取

51
00:02:36,200 --> 00:02:39,840
读取的过程当中就会产生一个MEMORY的LATENCY

52
00:02:39,840 --> 00:02:42,040
就是内存的时延

53
00:02:42,040 --> 00:02:44,360
这个就是今天所关注的内容

54
00:02:44,360 --> 00:02:46,960
读完之后我就可以READ FROM CACHE

55
00:02:46,960 --> 00:02:49,240
就是写到CACHE里面

56
00:02:49,280 --> 00:02:52,720
接着控制器就会从CACHE里面

57
00:02:52,720 --> 00:02:56,400
或者从寄存器里面去读取x[0]

58
00:02:56,400 --> 00:02:59,320
同时也可以去读取y[0]

59
00:02:59,320 --> 00:03:01,240
先去读取x[0]

60
00:03:01,240 --> 00:03:04,560
然后执行a*x的操作

61
00:03:04,560 --> 00:03:07,080
同样这个a也是一个元素

62
00:03:07,080 --> 00:03:09,200
内存里面CACHE里面的一个元素

63
00:03:09,200 --> 00:03:10,280
需要读取

64
00:03:10,280 --> 00:03:11,360
然后乘的操作

65
00:03:11,360 --> 00:03:14,040
其实FLOP计算的非常的快

66
00:03:14,040 --> 00:03:16,640
只占了中间的这么一小撮时间

67
00:03:16,640 --> 00:03:18,160
接着就写回结果

68
00:03:18,200 --> 00:03:19,440
写回结果之后

69
00:03:19,440 --> 00:03:20,560
我的y[0]得到了

70
00:03:20,560 --> 00:03:22,840
我的a*x的结果得到了

71
00:03:22,840 --> 00:03:25,480
接着做一个+y的操作

72
00:03:25,480 --> 00:03:29,280
然后加的操作同样也需要点时间

73
00:03:29,280 --> 00:03:31,800
最后计算完Ax+B之后

74
00:03:31,800 --> 00:03:33,480
就写回结果

75
00:03:33,480 --> 00:03:35,000
写回到CACHE里面

76
00:03:35,000 --> 00:03:36,440
至于后面要不要写回内存

77
00:03:36,440 --> 00:03:38,000
就是另外一个事情了

78
00:03:38,000 --> 00:03:40,600
可以看到在整体的计算过程

79
00:03:40,600 --> 00:03:42,560
在INSTRUCTION PIPELINE

80
00:03:42,560 --> 00:03:44,040
指令流水过程中

81
00:03:44,040 --> 00:03:47,240
最耗时的是MEMORY LATENCY

82
00:03:47,280 --> 00:03:49,040
内存的时延

83
00:03:50,480 --> 00:03:53,840
现在看几个物理上的一个意义和概念

84
00:03:53,840 --> 00:03:55,720
就是光和电的传播速度

85
00:03:56,760 --> 00:04:02,000
可以看到光的传播速度是30万公里每秒

86
00:04:02,000 --> 00:04:03,360
非常非常的快

87
00:04:03,360 --> 00:04:06,400
大家都知道光的传播速度是更快的

88
00:04:06,400 --> 00:04:08,560
另外有一个非常夸张的数据

89
00:04:08,560 --> 00:04:10,920
就是计算机的频率

90
00:04:10,920 --> 00:04:11,840
时钟周期

91
00:04:11,840 --> 00:04:12,800
计算机的频率

92
00:04:12,800 --> 00:04:15,160
30亿赫兹每秒

93
00:04:15,160 --> 00:04:17,040
所以在一个时钟周期内

94
00:04:17,200 --> 00:04:19,960
光的传播速度是10厘米

95
00:04:19,960 --> 00:04:21,680
也就是100毫秒

96
00:04:21,680 --> 00:04:23,680
接着看看第二个数据

97
00:04:23,680 --> 00:04:25,960
电流的传播速度

98
00:04:26,240 --> 00:04:29,880
电流主要是指在硅芯片里面的传播速度

99
00:04:29,880 --> 00:04:32,600
只是光的5分之1

100
00:04:32,600 --> 00:04:34,760
6万公里每秒

101
00:04:34,960 --> 00:04:38,360
这个时候就得出一个比较有意思的规律

102
00:04:38,360 --> 00:04:40,080
就是一个时钟周期内

103
00:04:40,080 --> 00:04:44,840
电流的传播速度是20毫米

104
00:04:45,160 --> 00:04:47,480
假设现在有一款芯片

105
00:04:47,480 --> 00:04:48,240
或者有一个系统

106
00:04:48,240 --> 00:04:49,840
有CPU还有DRAM

107
00:04:49,840 --> 00:04:53,560
电流只是简单的从CPU传到DRAM里面

108
00:04:53,560 --> 00:04:56,480
它的一个距离大概是5到10毫秒

109
00:04:56,480 --> 00:05:00,000
也就是使用了五六个时钟周期了

110
00:05:00,000 --> 00:05:01,320
五六个时钟周期

111
00:05:01,320 --> 00:05:03,640
这就是产生了时延

112
00:05:03,640 --> 00:05:05,800
而在CPU里面一个时钟周期

113
00:05:05,800 --> 00:05:09,240
ALU可以执行非常多个FLOP的计算

114
00:05:09,240 --> 00:05:12,400
就每秒执行几亿万次的时钟周期计算

115
00:05:12,800 --> 00:05:16,320
这就衍生了时延的问题了

116
00:05:16,760 --> 00:05:20,520
现在还是站在一个整体系统的角度去看待问题的

117
00:05:20,520 --> 00:05:22,800
如果放在处理器内部

118
00:05:22,800 --> 00:05:24,560
放在晶体管内部

119
00:05:24,560 --> 00:05:27,000
实际上数据之间的搬运

120
00:05:27,000 --> 00:05:29,280
就是把一个晶体管里面的数据

121
00:05:29,280 --> 00:05:31,960
传输到另外一组晶体管

122
00:05:31,960 --> 00:05:36,000
于是刚才就用了晶体管里面的数据的传输速率

123
00:05:36,000 --> 00:05:39,880
去反推计算系统里面跟数据之间的一个关系

124
00:05:39,880 --> 00:05:41,960
里面就引出了一个时延

125
00:05:42,040 --> 00:05:46,320
现在还是以AX+Y这个demo作为例子

126
00:05:46,320 --> 00:05:48,800
现在左边有一款芯片

127
00:05:48,800 --> 00:05:50,800
假设是英特尔的一款芯片

128
00:05:50,800 --> 00:05:53,400
里面有两个主要的指标单位

129
00:05:53,400 --> 00:05:55,520
第一个是内存带宽

130
00:05:55,520 --> 00:05:57,760
内存带宽有131GB

131
00:05:57,760 --> 00:05:59,960
每秒能够传输那么多数据

132
00:05:59,960 --> 00:06:02,760
第二个单位就是memory的latency

133
00:06:02,760 --> 00:06:06,120
内存的时延是89纳秒

134
00:06:06,120 --> 00:06:08,320
这就意味着在89纳秒以内

135
00:06:08,320 --> 00:06:13,320
能够传输11659个字节的内容

136
00:06:13,320 --> 00:06:15,320
这就意味着在89纳秒以内

137
00:06:15,320 --> 00:06:21,080
最多可以传输11659个字节

138
00:06:21,080 --> 00:06:24,400
而刚才的demo是AX+Y这个demo

139
00:06:24,400 --> 00:06:26,600
然后传输了16个字节

140
00:06:26,600 --> 00:06:31,080
也就是x[0]和y[0]在89纳秒以内

141
00:06:31,080 --> 00:06:35,960
这个时候16个字节对比1165个字节

142
00:06:36,000 --> 00:06:37,480
整个内存的利用率

143
00:06:37,480 --> 00:06:39,640
内存的效率只有0.14

144
00:06:39,640 --> 00:06:41,640
是非常非常的低的

145
00:06:41,640 --> 00:06:45,600
反观看一看有个最大的问题就是

146
00:06:45,600 --> 00:06:48,920
现在虽然在intel Xeon这块芯片里面

147
00:06:48,920 --> 00:06:50,400
传输两个数据

148
00:06:50,400 --> 00:06:54,240
但是0.14已经是整个AMD

149
00:06:54,240 --> 00:06:55,880
英特尔英伟达里面

150
00:06:55,880 --> 00:06:59,760
数据传输效率内存利用率最高的

151
00:06:59,760 --> 00:07:02,040
为什么会有这种情况发生呢

152
00:07:02,040 --> 00:07:03,720
为什么英伟达更低呢

153
00:07:03,720 --> 00:07:05,520
那这个时候就很有意思

154
00:07:05,520 --> 00:07:07,200
就涉及到计算

155
00:07:07,200 --> 00:07:10,480
计算刚才只是搬运了少量的数据

156
00:07:10,480 --> 00:07:13,040
而英伟达A100或者GPU

157
00:07:13,040 --> 00:07:16,760
大部分都是对大量的数据进行大量的计算

158
00:07:16,760 --> 00:07:19,480
同一组数据进行非常之夸张

159
00:07:19,480 --> 00:07:21,000
惊人的计算

160
00:07:21,000 --> 00:07:25,000
GPU就非常不擅长做一些小数据的计算

161
00:07:25,000 --> 00:07:27,480
而是对大数据进行大计算

162
00:07:28,800 --> 00:07:32,320
现在回到AX+B这个指令架构图里面

163
00:07:32,320 --> 00:07:34,040
可以看到大部分时间

164
00:07:34,200 --> 00:07:37,400
内存都是在等待的时间

165
00:07:37,400 --> 00:07:39,040
都是在传输的时间

166
00:07:39,040 --> 00:07:43,960
而内存的时延就严重的阻碍了计算时间

167
00:07:43,960 --> 00:07:46,640
现在的内存利用率都这么的低

168
00:07:46,640 --> 00:07:49,000
更不用说计算的利用率了

169
00:07:49,000 --> 00:07:50,720
可以看到整个计算里面了

170
00:07:50,720 --> 00:07:52,240
这整个时间周期里面

171
00:07:52,240 --> 00:07:54,440
整个程序的周期计算

172
00:07:54,440 --> 00:07:56,760
只有中间这两个点

173
00:07:56,760 --> 00:07:58,480
就是乘和加

174
00:07:58,480 --> 00:08:02,360
只占了可能里面非常少的一个时间

175
00:08:03,360 --> 00:08:05,120
最后总结一下

176
00:08:05,120 --> 00:08:09,440
就是CPU的架构真的是主要是擅长逻辑控制

177
00:08:09,440 --> 00:08:12,600
而计算的利用率其实并不高

178
00:08:12,600 --> 00:08:14,200
如果要提CPU

179
00:08:14,200 --> 00:08:16,280
提它的Flop数非常高

180
00:08:16,280 --> 00:08:17,720
其实这是不合理的

181
00:08:17,720 --> 00:08:20,160
提它的内存带宽的利用率很高

182
00:08:20,160 --> 00:08:21,320
也是不合理的

183
00:08:21,320 --> 00:08:23,760
更多的想要提高计算的利用率

184
00:08:23,760 --> 00:08:25,960
可能不仅仅是依托于CPU

185
00:08:25,960 --> 00:08:28,160
而是依托于超异构架构

186
00:08:28,160 --> 00:08:30,880
CPU加GPU加NPU组合起来

187
00:08:33,360 --> 00:08:35,120
最后总结一下

188
00:08:35,120 --> 00:08:37,360
从数据看CPU

189
00:08:37,360 --> 00:08:40,840
在上一节里面给大家汇报了一个计算的强度

190
00:08:40,840 --> 00:08:41,720
在这一节里面

191
00:08:41,720 --> 00:08:44,880
数据的传输衍生了内存

192
00:08:44,880 --> 00:08:46,400
传输的一个时延

193
00:08:46,400 --> 00:08:48,200
最后因为有了时延

194
00:08:48,200 --> 00:08:49,720
有了跟计算相关的

195
00:08:49,720 --> 00:08:51,240
于是就出现了下一节

196
00:08:51,240 --> 00:08:54,760
会去深入的介绍的通用图形处理器GPU

197
00:08:54,760 --> 00:08:57,000
还有AI专用处理器NPU

198
00:08:57,000 --> 00:09:00,040
最后再到超异构架构的未来

199
00:09:00,040 --> 00:09:02,840
或者现在正处于的黄金十年

200
00:09:02,840 --> 00:09:04,520
今天的内容就到这里为止

201
00:09:04,520 --> 00:09:05,520
谢谢各位

202
00:09:05,520 --> 00:09:06,520
拜了个拜

203
00:09:06,520 --> 00:09:08,520
卷的不行了卷的不行了

204
00:09:08,520 --> 00:09:10,520
记得一键三连加关注哦

205
00:09:10,520 --> 00:09:13,203
所有的内容都会开源在下面这条链接里面

206
00:09:13,203 --> 00:09:15,203
拜了个拜

