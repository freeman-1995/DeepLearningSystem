1
00:00:00,925 --> 00:00:03,625
字幕生成：慎独    校对：游吟外星人

2
00:00:05,961 --> 00:00:06,950
Hello,大家好

3
00:00:06,950 --> 00:00:11,450
我是你们头又秃腰又肥的ZOMI

4
00:00:11,450 --> 00:00:14,025
今天来到一个新的系列里面

5
00:00:14,025 --> 00:00:16,500
主要是GPU的详解

6
00:00:16,876 --> 00:00:20,603
今天要分享给大家或者给大家汇报的内容

7
00:00:20,603 --> 00:00:22,996
就是GPU的工作原理

8
00:00:25,375 --> 00:00:28,896
其实在之前已经讲了AI的计算体系

9
00:00:28,896 --> 00:00:30,908
还有AI芯片的整体的基础

10
00:00:30,908 --> 00:00:33,403
而在这里面埋了一个雷

11
00:00:33,403 --> 00:00:36,600
就是通用图形处理器GPU

12
00:00:36,600 --> 00:00:39,800
简单的去讲了一些它的主要的概念

13
00:00:39,800 --> 00:00:44,344
今天会详细的去打开GPU里面的更多的内容

14
00:00:44,344 --> 00:00:47,381
那可能会分两个章节来聊

15
00:00:47,381 --> 00:00:49,550
第一个就是硬件的基础

16
00:00:49,550 --> 00:00:50,453
GPU的工作原理

17
00:00:50,453 --> 00:00:52,417
还有它的编程本质

18
00:00:52,417 --> 00:00:54,809
第二个就是英伟达的GPU的架构

19
00:00:54,809 --> 00:00:56,664
英伟达其实发展的非常久了

20
00:00:56,664 --> 00:00:59,544
它整体架构也演变了非常多代

21
00:00:59,544 --> 00:01:03,705
那从female到hopper架构它也引进了非常多

22
00:01:03,705 --> 00:01:07,125
其中我觉得跟AI特别相关的就有Tensor Core

23
00:01:07,125 --> 00:01:09,472
还有NVLink两个内容

24
00:01:09,472 --> 00:01:12,352
那在最后可能会单独分一节出来

25
00:01:12,352 --> 00:01:15,241
去聊一聊GPU的图形图像处理

26
00:01:15,241 --> 00:01:17,052
它最原始的一些内容

27
00:01:17,052 --> 00:01:21,033
今天来到重点就是GPU的工作原理

28
00:01:21,033 --> 00:01:21,058
GPU的Working Principle

29
00:01:21,058 --> 00:01:23,450
GPU的Working Principle

30
00:01:23,475 --> 00:01:25,395
在GPU的工作原理里面

31
00:01:25,395 --> 00:01:29,153
主要今天会给大家汇报几个内容

32
00:01:29,153 --> 00:01:31,341
第一个以AX加Y这个例子

33
00:01:31,341 --> 00:01:33,989
去看看GPU是怎么做并行的

34
00:01:33,989 --> 00:01:37,000
而谈到并行有两个概念要澄清的

35
00:01:37,000 --> 00:01:39,856
就是并发跟并行两个概念是不一样的

36
00:01:39,856 --> 00:01:41,776
而并发更多的是CPU

37
00:01:41,776 --> 00:01:45,108
并行更多的是GPU里面所处的

38
00:01:45,108 --> 00:01:46,945
或者所处理的一些任务

39
00:01:46,945 --> 00:01:49,377
然后看看GPU的缓存机制

40
00:01:49,377 --> 00:01:52,972
它的Cache跟线程是分不开的

41
00:01:52,972 --> 00:01:55,023
因为GPU它是一个SIMT

42
00:01:55,023 --> 00:01:57,335
T就是线程的意思

43
00:01:57,335 --> 00:02:00,000
所以今天会分开四个内容给大家去汇报

44
00:02:01,475 --> 00:02:03,970
现在还没有进入第一个内容的时候

45
00:02:03,970 --> 00:02:05,826
看看什么是GPU

46
00:02:05,826 --> 00:02:07,939
为什么GPU这么独特

47
00:02:07,939 --> 00:02:10,604
GPU的全称叫做

48
00:02:10,604 --> 00:02:13,182
Graphic Processing Unit

49
00:02:13,182 --> 00:02:16,930
它一开始是用来处理一些图形图像

50
00:02:16,930 --> 00:02:20,042
视频编解码的一些相关的工作

51
00:02:20,042 --> 00:02:24,903
第二个问题就是GPU跟CPU最大的不同的点在哪

52
00:02:24,903 --> 00:02:27,029
在上一个内容里面

53
00:02:27,029 --> 00:02:28,600
特别是AI芯片技术里面

54
00:02:28,600 --> 00:02:30,480
其实已经给大家汇报过了

55
00:02:30,480 --> 00:02:34,875
GPU的设计目标是最大化它的吞吐 Fullput

56
00:02:34,875 --> 00:02:37,625
主要关心的的是并行度

57
00:02:37,625 --> 00:02:39,787
就是同一时间可以执行多少任务

58
00:02:39,787 --> 00:02:42,186
而CPU更关心的是延迟

59
00:02:42,186 --> 00:02:44,088
还有并发两个内容

60
00:02:44,088 --> 00:02:47,613
它们所关心的内容或者聚焦的重点是不一样的

61
00:02:49,050 --> 00:02:51,034
现在来到第一个内容

62
00:02:51,059 --> 00:02:54,082
看一下AX加Y这一个Demo

63
00:02:54,082 --> 00:02:56,831
然后去了解一下GPU的工作原理

64
00:02:56,831 --> 00:02:58,324
其实在上一节里面

65
00:02:58,324 --> 00:03:00,198
以这个AX加Y作为例子

66
00:03:00,198 --> 00:03:01,452
给大家讲过了

67
00:03:01,452 --> 00:03:03,570
像这么简单的一个数据

68
00:03:03,570 --> 00:03:05,334
Demo就是AX加Y

69
00:03:05,334 --> 00:03:07,807
然后AX加Y这一个公式

70
00:03:07,807 --> 00:03:10,200
这里面就有两个Fullput操作

71
00:03:10,200 --> 00:03:11,372
一个就是乘法

72
00:03:11,372 --> 00:03:13,041
一个就是加法

73
00:03:13,481 --> 00:03:14,558
对于每一次操作

74
00:03:14,558 --> 00:03:16,760
需要在内存里面读取两个数据

75
00:03:16,944 --> 00:03:18,021
一个是XI

76
00:03:18,021 --> 00:03:19,386
一个是YI

77
00:03:19,790 --> 00:03:21,932
最后执行一个线性的操作

78
00:03:21,932 --> 00:03:23,835
存回YI这个里面

79
00:03:23,835 --> 00:03:27,283
在这里面就可以有一个融合的操作

80
00:03:27,283 --> 00:03:29,740
叫做FMA Fused Multiply and Add

81
00:03:29,740 --> 00:03:32,172
就是把乘法和加法融合在一起

82
00:03:32,172 --> 00:03:34,301
然后不管N有多少次

83
00:03:34,301 --> 00:03:35,301
就迭代多少次

84
00:03:35,301 --> 00:03:36,710
所以在CPU里面

85
00:03:36,710 --> 00:03:40,166
它是一个串行的按指令顺序去执行的一段程序

86
00:03:40,706 --> 00:03:43,559
假设在英特尔8280这款芯片里面

87
00:03:43,559 --> 00:03:47,460
内存带宽是113GB每秒

88
00:03:47,460 --> 00:03:50,062
而内存的延时是89纳秒

89
00:03:50,062 --> 00:03:54,424
这个时候就可以有11659个byte

90
00:03:54,424 --> 00:03:57,989
每一次也就是在89纳秒里面去执行

91
00:03:57,989 --> 00:04:01,936
当然，11659个byte在89纳秒里面去执行

92
00:04:01,936 --> 00:04:03,920
它只是一个峰值的算力

93
00:04:04,220 --> 00:04:05,090
在89纳秒

94
00:04:05,090 --> 00:04:06,552
就是说延迟时间内

95
00:04:06,552 --> 00:04:08,893
只搬运了16个byte的数据

96
00:04:08,893 --> 00:04:12,044
这个时候内存的利用率只有0.14%

97
00:04:12,044 --> 00:04:13,238
非常非常的小

98
00:04:13,238 --> 00:04:16,566
内存的搬运就占了99.86%的时间了

99
00:04:16,566 --> 00:04:20,449
现在看一下一个整个的内存的利用率

100
00:04:20,449 --> 00:04:22,753
不管是AMD Intel还是NVIDIA

101
00:04:22,753 --> 00:04:26,031
整体来说对于AS+Y这么刚才的一段程序

102
00:04:26,081 --> 00:04:29,830
内存的利用率是非常的非常的低

103
00:04:29,830 --> 00:04:34,084
可以看到基本上都是不到0.1的范围内

104
00:04:34,084 --> 00:04:36,716
刚才的程序确实写得非常的不好

105
00:04:36,766 --> 00:04:38,544
没有充分利用并发和信心度

106
00:04:38,544 --> 00:04:41,368
下面看一下另外一个程序

107
00:04:41,368 --> 00:04:44,372
把刚才的那个程序进行了一次展开

108
00:04:44,372 --> 00:04:47,252
每一次执行从0到7的数据

109
00:04:47,252 --> 00:04:48,916
然后迭代8次

110
00:04:48,916 --> 00:04:51,966
这种就是把AS+Y的这种demo

111
00:04:51,966 --> 00:04:56,105
或者这种计算通过并发进行循环展开

112
00:04:56,105 --> 00:04:58,990
整个总线处于一个忙碌的状态当中

113
00:04:58,990 --> 00:05:00,471
从计算来看一下

114
00:05:00,471 --> 00:05:04,748
就是11659次除以16就等于729

115
00:05:04,748 --> 00:05:08,750
循环展开之后在执行729次请求

116
00:05:08,750 --> 00:05:09,839
都是没有问题的

117
00:05:09,839 --> 00:05:11,887
这个时候叫做通过并发

118
00:05:11,887 --> 00:05:14,440
使得总线处于忙碌的状态当中

119
00:05:14,440 --> 00:05:16,096
下面可以看到

120
00:05:16,096 --> 00:05:17,918
在真正的应用场景

121
00:05:17,918 --> 00:05:21,011
实际上编译器很少会对整个循环

122
00:05:21,011 --> 00:05:24,023
进行超过100次以上的一个展开

123
00:05:24,023 --> 00:05:26,161
第2个问题就是一个线程

124
00:05:26,161 --> 00:05:29,549
每一次执行的指令数量是有限的

125
00:05:29,549 --> 00:05:32,542
它不可能执行非常非常多并发的数量

126
00:05:32,542 --> 00:05:33,807
第3个问题就是一个线程

127
00:05:33,807 --> 00:05:36,414
一个线程其实很难直接去处理

128
00:05:36,414 --> 00:05:39,114
700多个计算的负荷

129
00:05:39,114 --> 00:05:40,779
于是就引入了

130
00:05:40,779 --> 00:05:42,687
硬件架构的一个问题了

131
00:05:42,687 --> 00:05:43,795
虽然并发的操作

132
00:05:43,795 --> 00:05:46,491
让一次能够执行更多的指令

133
00:05:46,491 --> 00:05:48,499
能够执行流水的操作

134
00:05:48,499 --> 00:05:49,832
但是同样架构

135
00:05:49,832 --> 00:05:52,000
也会受到所限制所约束

136
00:05:52,902 --> 00:05:55,918
看一下同样的例子

137
00:05:55,918 --> 00:05:57,198
Z=AX+Y

138
00:05:57,198 --> 00:06:00,529
这个demo通过并行的方式进行循环展开

139
00:06:00,529 --> 00:06:01,852
刚才是通过并发

140
00:06:01,852 --> 00:06:03,081
现在是通过并行

141
00:06:03,081 --> 00:06:04,081
并行

142
00:06:04,244 --> 00:06:05,564
就是通过并行处理器

143
00:06:05,564 --> 00:06:06,740
或者多个线程

144
00:06:06,740 --> 00:06:09,407
去执行AX+Y这个操作

145
00:06:09,407 --> 00:06:11,391
同样使得总线

146
00:06:11,391 --> 00:06:13,370
处于忙碌的状态当中

147
00:06:13,370 --> 00:06:15,747
每一次可以执行729个迭代

148
00:06:15,747 --> 00:06:16,963
不过有点不一样的

149
00:06:16,963 --> 00:06:19,362
就是现在每个线程

150
00:06:19,362 --> 00:06:21,834
独立的去负责相关的运算

151
00:06:21,834 --> 00:06:22,689
也就是每个线程

152
00:06:22,689 --> 00:06:22,834
去计算一次as加y这么一个操作

153
00:06:22,834 --> 00:06:26,067
去计算一次AX+Y这么一个操作

154
00:06:26,208 --> 00:06:28,811
现在要执行729次计算

155
00:06:28,811 --> 00:06:31,564
一共就需要729个线程

156
00:06:31,564 --> 00:06:34,852
也就是parallel一共有729次

157
00:06:34,852 --> 00:06:37,815
这个时候遇到的瓶颈或者约束

158
00:06:37,815 --> 00:06:39,369
就会受到线程数量

159
00:06:39,369 --> 00:06:41,756
还有内存请求的一个约束了

160
00:06:42,837 --> 00:06:45,194
于是就引入了第二个内容

161
00:06:45,194 --> 00:06:46,339
或者第二个话题

162
00:06:46,339 --> 00:06:48,830
并行跟并发之间的关系

163
00:06:49,143 --> 00:06:52,471
并行主要是指能够同时处理多个任务

164
00:06:52,752 --> 00:06:55,719
并发是指能够处理多个任务的功能

165
00:06:55,719 --> 00:06:57,370
但不一定是同时

166
00:06:57,370 --> 00:06:58,434
所以叫做并发

167
00:06:58,434 --> 00:06:59,919
可以它大量的并发

168
00:06:59,919 --> 00:07:02,917
但并行是同时去执行相同的任务

169
00:07:03,257 --> 00:07:05,503
在实际的硬件的工作过程当中

170
00:07:05,503 --> 00:07:08,275
更多的倾向于利用多线程

171
00:07:08,275 --> 00:07:09,625
对循环展开

172
00:07:09,625 --> 00:07:11,731
来提高整体硬件的利用率

173
00:07:11,731 --> 00:07:14,310
这就是GPU的最主要的原理

174
00:07:14,310 --> 00:07:17,072
现在来看一下在硬件限制的情况下

175
00:07:17,072 --> 00:07:19,476
一般能够执行多少个线程

176
00:07:20,181 --> 00:07:22,740
同样的以三款芯片作为例子

177
00:07:22,740 --> 00:07:23,404
一个是AMD

178
00:07:23,404 --> 00:07:23,935
一个是英特尔

179
00:07:23,935 --> 00:07:26,136
另外一个是英伟达的A100

180
00:07:26,384 --> 00:07:27,182
针对这个表

181
00:07:27,182 --> 00:07:29,652
其实刚才只看了内存的利用率

182
00:07:29,652 --> 00:07:31,572
现在增加三列

183
00:07:31,572 --> 00:07:32,244
线程的请求

184
00:07:32,244 --> 00:07:33,136
线程的可用数

185
00:07:33,136 --> 00:07:34,536
还有线程的比例

186
00:07:34,621 --> 00:07:37,029
去看一下到底需要多少线程

187
00:07:37,029 --> 00:07:40,651
才能够解决内存时延的问题

188
00:07:41,111 --> 00:07:41,710
从这个表

189
00:07:41,710 --> 00:07:43,583
可以看到几个关键的数据

190
00:07:43,583 --> 00:07:47,905
GPU的时延会比CPU要高出好几个倍数的等级

191
00:07:48,073 --> 00:07:49,460
第二个比较重要的数据

192
00:07:49,460 --> 00:07:51,431
就是GPU的线程数

193
00:07:51,577 --> 00:07:54,291
是CPU的接近二三十倍

194
00:07:54,291 --> 00:07:56,217
也是非常夸张的一个数据

195
00:07:56,397 --> 00:07:57,787
另外一个比较重要的数据

196
00:07:57,787 --> 00:08:00,245
就是线程的数量

197
00:08:00,371 --> 00:08:02,280
GPU的可用线程数

198
00:08:02,280 --> 00:08:03,798
是CPU的一百多倍

199
00:08:03,798 --> 00:08:05,459
这个时候可以算出来

200
00:08:05,459 --> 00:08:06,459
线程的比例

201
00:08:06,459 --> 00:08:07,916
GPU是5.6倍

202
00:08:07,916 --> 00:08:09,429
而相对于CPU呢

203
00:08:09,429 --> 00:08:11,123
基本上是一点多倍

204
00:08:11,628 --> 00:08:13,701
这就是GPU最重要的一个设计点

205
00:08:13,701 --> 00:08:16,170
它拥有非常多的线程

206
00:08:16,170 --> 00:08:19,701
为大量大规模任务并行而去设计的

207
00:08:19,701 --> 00:08:21,363
因此会说GPU

208
00:08:21,363 --> 00:08:22,513
英伟达这个A100

209
00:08:22,638 --> 00:08:24,302
它是一个大型的吞吐器

210
00:08:24,302 --> 00:08:25,670
有一部分的线程

211
00:08:25,670 --> 00:08:26,674
它在等待着数据

212
00:08:26,674 --> 00:08:27,527
有一部分线程

213
00:08:27,527 --> 00:08:29,288
它在等待被激活去计算

214
00:08:29,288 --> 00:08:30,437
有一部分线程

215
00:08:30,437 --> 00:08:32,421
它已经正在计算的过程当中

216
00:08:32,910 --> 00:08:35,945
GPU的硬件设计师将所有的资源

217
00:08:35,945 --> 00:08:37,137
所有的硬件资源

218
00:08:37,137 --> 00:08:39,303
都投入到增加更多的线程当中

219
00:08:39,303 --> 00:08:41,214
而不是想办法去减少

220
00:08:41,214 --> 00:08:42,729
数据搬运的延迟

221
00:08:42,729 --> 00:08:45,000
指令执行的延迟

222
00:08:45,426 --> 00:08:48,172
相对应的，可以把CPU

223
00:08:48,172 --> 00:08:50,006
比喻成一台延迟机

224
00:08:50,006 --> 00:08:51,334
它的一个最大的工作

225
00:08:51,334 --> 00:08:52,915
是希望一个线程里面

226
00:08:52,915 --> 00:08:54,716
完成所有的工作

227
00:08:54,716 --> 00:08:56,628
为什么线程比只有一点多呢

228
00:08:56,628 --> 00:08:57,762
是因为希望

229
00:08:57,762 --> 00:08:59,134
能够用足够的线程

230
00:08:59,134 --> 00:09:00,665
去解决延迟的问题

231
00:09:00,665 --> 00:09:01,611
所以这个时候

232
00:09:01,611 --> 00:09:03,093
CPU的硬件设计者

233
00:09:03,093 --> 00:09:04,731
或者硬件设计架构师

234
00:09:04,731 --> 00:09:06,842
就会把所有的资源和重心

235
00:09:06,842 --> 00:09:09,487
都投入到减少延迟上面

236
00:09:09,487 --> 00:09:11,718
这也是SIMD跟SIMT的

237
00:09:11,718 --> 00:09:13,626
一个架构最大的区别

238
00:09:13,836 --> 00:09:15,514
GPU不是通过增加线程

239
00:09:15,514 --> 00:09:16,468
来去解决问题

240
00:09:16,468 --> 00:09:18,353
而是使用相反的方式

241
00:09:18,353 --> 00:09:20,624
去优化线程的执行的

242
00:09:20,624 --> 00:09:21,624
速率和效率

243
00:09:21,990 --> 00:09:23,841
这就是CPU跟GPU之间

244
00:09:23,841 --> 00:09:25,275
最大的区别

245
00:09:25,275 --> 00:09:27,458
也是它们的本质区别

246
00:09:28,016 --> 00:09:29,508
因此在这里面

247
00:09:29,508 --> 00:09:31,684
引出一个非常重要的概念

248
00:09:31,762 --> 00:09:32,762
线程

249
00:09:32,762 --> 00:09:34,762
会进入到GPU的

250
00:09:34,889 --> 00:09:36,000
线程

251
00:09:36,635 --> 00:09:38,819
下面来到第三个内容

252
00:09:38,819 --> 00:09:39,843
GPU的cache

253
00:09:39,843 --> 00:09:41,725
缓存机制

254
00:09:41,865 --> 00:09:43,113
GPU的一级流水

255
00:09:43,113 --> 00:09:43,599
二级流水

256
00:09:43,599 --> 00:09:44,585
三级流水

257
00:09:44,957 --> 00:09:46,040
现在看一下

258
00:09:46,040 --> 00:09:47,389
GPU的缓存机制

259
00:09:47,891 --> 00:09:49,382
尽可能的希望去减少

260
00:09:49,382 --> 00:09:50,224
内存的时延

261
00:09:50,224 --> 00:09:50,857
内存的搬运

262
00:09:50,857 --> 00:09:51,959
还有内存的带宽

263
00:09:51,959 --> 00:09:52,736
一些一系列

264
00:09:52,736 --> 00:09:54,057
关于内存的问题

265
00:09:54,497 --> 00:09:55,261
而这里面

266
00:09:55,261 --> 00:09:56,497
缓存对内存来说

267
00:09:56,497 --> 00:09:57,974
就变得非常的重要

268
00:09:58,067 --> 00:09:59,229
HBM Memory

269
00:09:59,229 --> 00:09:59,948
有80G

270
00:09:59,948 --> 00:10:01,277
在英伟达的

271
00:10:01,277 --> 00:10:02,391
A100的架构里面

272
00:10:02,391 --> 00:10:03,364
这80G

273
00:10:03,364 --> 00:10:04,944
就是经常谈到的

274
00:10:05,053 --> 00:10:05,826
显存

275
00:10:06,209 --> 00:10:07,164
在GPU里面

276
00:10:07,164 --> 00:10:08,530
独立的内存

277
00:10:08,530 --> 00:10:10,560
把一些寄存器文件

278
00:10:10,560 --> 00:10:11,620
we just file

279
00:10:11,620 --> 00:10:13,234
也当做缓存

280
00:10:13,334 --> 00:10:14,830
寄存器离SM

281
00:10:14,830 --> 00:10:16,139
真正的执行单元

282
00:10:16,139 --> 00:10:17,277
是非常的近

283
00:10:17,277 --> 00:10:18,459
因为更SM

284
00:10:18,459 --> 00:10:19,764
实际的计算单元

285
00:10:19,764 --> 00:10:21,139
希望尽可能快速的

286
00:10:21,139 --> 00:10:22,494
去获取数据

287
00:10:22,494 --> 00:10:24,122
于是就会从寄存器里面

288
00:10:24,239 --> 00:10:26,435
去读取Cache里面的一些数据

289
00:10:26,656 --> 00:10:28,443
另外一方面，希望Cache

290
00:10:28,443 --> 00:10:29,378
缓存

291
00:10:29,378 --> 00:10:31,667
离内存，或者显存更近

292
00:10:31,667 --> 00:10:33,624
因为GPU希望把大量的数据

293
00:10:33,624 --> 00:10:35,202
直接搬运到cache里面

294
00:10:35,202 --> 00:10:36,703
这个时候有两个矛盾

295
00:10:36,703 --> 00:10:39,203
于是，GPU就设计了多级的缓存

296
00:10:39,311 --> 00:10:40,975
首先往右边去看一下

297
00:10:41,000 --> 00:10:42,782
对应的80G的显存

298
00:10:42,782 --> 00:10:44,737
是一个高带宽的内存

299
00:10:44,737 --> 00:10:46,312
或者叫做显存

300
00:10:46,312 --> 00:10:46,854
第2个

301
00:10:46,854 --> 00:10:48,202
就是缓存

302
00:10:48,202 --> 00:10:50,148
真正到片内的缓存

303
00:10:50,229 --> 00:10:50,952
片内的缓存

304
00:10:50,952 --> 00:10:52,501
可能分为多级

305
00:10:52,835 --> 00:10:53,401
第1个

306
00:10:53,401 --> 00:10:54,563
就是是L2的Cache

307
00:10:54,563 --> 00:10:56,776
离显存最近的

308
00:10:56,776 --> 00:10:57,198
第2个

309
00:10:57,198 --> 00:10:58,650
就是L1的Cache

310
00:10:58,650 --> 00:11:00,314
它里面的存储空间

311
00:11:00,314 --> 00:11:00,966
会更少

312
00:11:00,966 --> 00:11:02,736
只有192个KB

313
00:11:02,841 --> 00:11:05,275
都有SM都有自己独立的Cache

314
00:11:05,389 --> 00:11:06,839
而真正的Register

315
00:11:06,839 --> 00:11:08,465
也是作为Cache里面的

316
00:11:08,465 --> 00:11:10,068
里面有256个KB

317
00:11:10,068 --> 00:11:12,223
一共有27MB的寄存器

318
00:11:12,223 --> 00:11:13,868
在整个A100里面

319
00:11:13,868 --> 00:11:15,411
它有108个SM

320
00:11:15,411 --> 00:11:16,462
那SM是什么呢

321
00:11:16,462 --> 00:11:17,341
后面

322
00:11:17,341 --> 00:11:19,173
会从介绍GPU的一些

323
00:11:19,173 --> 00:11:20,118
基本的概念里面

324
00:11:20,118 --> 00:11:21,460
去给大家汇报的

325
00:11:21,555 --> 00:11:23,015
现在大家去理解SM

326
00:11:23,015 --> 00:11:24,279
就是执行单元

327
00:11:24,279 --> 00:11:25,017
就可以了

328
00:11:25,017 --> 00:11:26,471
简单理解为执行单元

329
00:11:26,849 --> 00:11:28,023
现在来看看

330
00:11:28,023 --> 00:11:30,560
带宽和时延的一个问题

331
00:11:30,737 --> 00:11:31,822
在GPU里面呢

332
00:11:31,822 --> 00:11:33,079
主内存是具有一些

333
00:11:33,079 --> 00:11:35,199
高带宽的HBM的内存

334
00:11:35,435 --> 00:11:39,065
现在把主内存作为内存带宽的基本单位

335
00:11:39,065 --> 00:11:39,875
来去看一下

336
00:11:39,875 --> 00:11:41,845
其他的传输数据有多少

337
00:11:42,198 --> 00:11:43,497
L2缓存的带宽呢

338
00:11:43,497 --> 00:11:44,684
是它的三倍

339
00:11:44,684 --> 00:11:45,950
而L1缓存的带宽

340
00:11:45,950 --> 00:11:47,213
是它的13倍

341
00:11:47,458 --> 00:11:48,700
在真正计算的时候

342
00:11:48,700 --> 00:11:49,738
希望缓存

343
00:11:49,738 --> 00:11:51,389
能够尽快的去用完

344
00:11:51,389 --> 00:11:53,585
然后换下一批数据上来

345
00:11:53,696 --> 00:11:54,590
那这个时候

346
00:11:54,590 --> 00:11:56,368
就会遇到时延的问题

347
00:11:56,368 --> 00:11:58,635
从上往下去看一下

348
00:11:58,635 --> 00:11:59,091
首先

349
00:11:59,091 --> 00:12:01,431
离SM最近的是

350
00:12:01,431 --> 00:12:02,495
L1的缓存

351
00:12:02,495 --> 00:12:03,132
如果延迟

352
00:12:03,132 --> 00:12:04,139
作为基本单位

353
00:12:04,139 --> 00:12:05,522
L2的Cache的延迟

354
00:12:05,522 --> 00:12:06,771
就是5倍

355
00:12:06,771 --> 00:12:08,591
而对应的HBM的延迟

356
00:12:08,591 --> 00:12:09,449
就会更高

357
00:12:09,715 --> 00:12:12,075
这个时候，就会很清楚的理解到

358
00:12:12,075 --> 00:12:14,355
为什么GPU里面

359
00:12:14,355 --> 00:12:16,110
有单独的显存

360
00:12:16,110 --> 00:12:17,582
因为延迟

361
00:12:17,582 --> 00:12:18,615
实在是太高了

362
00:12:18,615 --> 00:12:18,640
假设我把CPU里面的DRAM的数据

363
00:12:18,640 --> 00:12:21,218
假设我把CPU里面的DRAM的数据

364
00:12:21,243 --> 00:12:21,964
传过来

365
00:12:21,964 --> 00:12:23,283
给GPU进行计算

366
00:12:23,404 --> 00:12:24,310
那时延

367
00:12:24,310 --> 00:12:25,596
会非常非常的高

368
00:12:25,651 --> 00:12:26,452
完全跟不上

369
00:12:26,452 --> 00:12:27,719
计算的速度

370
00:12:27,799 --> 00:12:28,347
还有跟不上

371
00:12:28,347 --> 00:12:30,287
带宽的传输的速度

372
00:12:30,491 --> 00:12:31,214
那这个时候

373
00:12:31,214 --> 00:12:32,607
就要求GPU里面

374
00:12:32,607 --> 00:12:33,819
有自己的一个

375
00:12:33,966 --> 00:12:36,146
高带宽的内存

376
00:12:36,146 --> 00:12:38,563
high bandwidth memory

377
00:12:38,563 --> 00:12:40,201
所以叫做HBM

378
00:12:40,547 --> 00:12:42,644
最后呢，就通过PCIe

379
00:12:42,644 --> 00:12:45,423
来去对数据进行传输

380
00:12:45,423 --> 00:12:47,115
把CPU里面的数据

381
00:12:47,115 --> 00:12:48,246
DRAM里面的数据

382
00:12:48,246 --> 00:12:51,547
传输到GPU里面的HBM

383
00:12:52,120 --> 00:12:53,371
HBM计算强度

384
00:12:53,371 --> 00:12:54,298
假设为100

385
00:12:54,408 --> 00:12:56,275
那L2的缓存的计算强度

386
00:12:56,275 --> 00:12:57,107
就会好很多

387
00:12:57,107 --> 00:12:58,337
只为39

388
00:12:58,337 --> 00:12:59,371
那39就意味着

389
00:12:59,371 --> 00:13:00,727
每个数据

390
00:13:00,794 --> 00:13:02,202
只需要执行39个操作

391
00:13:02,770 --> 00:13:04,659
而L1的缓存更少

392
00:13:04,659 --> 00:13:06,027
它的计算强度更少

393
00:13:06,027 --> 00:13:07,432
只需要8个操作

394
00:13:07,432 --> 00:13:08,078
8个操作

395
00:13:08,078 --> 00:13:08,739
这个时候

396
00:13:08,739 --> 00:13:10,007
对于硬件来说

397
00:13:10,007 --> 00:13:11,857
是非常容易实现的

398
00:13:12,035 --> 00:13:13,064
这样就解释了

399
00:13:13,064 --> 00:13:15,918
为什么L1缓存、L2缓存和寄存器

400
00:13:15,918 --> 00:13:18,001
对GPU来说这么的重要

401
00:13:18,001 --> 00:13:19,208
可以把数据

402
00:13:19,208 --> 00:13:20,788
放在L1缓存里面

403
00:13:20,788 --> 00:13:22,920
然后对数据进行8个操作

404
00:13:22,920 --> 00:13:24,648
使得计算

405
00:13:24,809 --> 00:13:26,551
达到了一个饱和的状态

406
00:13:26,551 --> 00:13:27,527
使得GPU里面

407
00:13:27,527 --> 00:13:30,503
SM具体的算力利用率更高

408
00:13:31,209 --> 00:13:32,492
而往下看看

409
00:13:32,567 --> 00:13:35,169
PCIe的带宽就变得非常的糟糕

410
00:13:35,169 --> 00:13:36,400
它的整体的时延

411
00:13:36,400 --> 00:13:37,866
延迟也会非常的高

412
00:13:37,866 --> 00:13:39,944
整体的算力的利用率

413
00:13:39,944 --> 00:13:41,224
也会很低

414
00:13:41,224 --> 00:13:42,428
算力的强度

415
00:13:42,428 --> 00:13:44,517
计算的强度太高了

416
00:13:44,637 --> 00:13:46,117
在带宽增加的同时

417
00:13:46,117 --> 00:13:48,210
线程的数量

418
00:13:48,210 --> 00:13:49,305
或者线程的请求数

419
00:13:49,305 --> 00:13:50,881
也需要相对应的增加

420
00:13:50,881 --> 00:13:51,965
这个时候才能够处理

421
00:13:51,965 --> 00:13:53,650
刚才所说到的

422
00:13:53,650 --> 00:13:55,309
并行的操作

423
00:13:55,309 --> 00:13:57,649
每个线程执行一个对应的数据

424
00:13:57,649 --> 00:14:00,360
才能够把算力利用率提升上去

425
00:14:00,620 --> 00:14:02,131
只有线程数足够多

426
00:14:02,131 --> 00:14:04,690
才能够让整个系统的内存

427
00:14:04,690 --> 00:14:06,119
处于忙碌的状态

428
00:14:06,119 --> 00:14:09,252
让计算也处于忙碌的状态

429
00:14:09,252 --> 00:14:12,302
因此看到GPU里面的线程数

430
00:14:12,302 --> 00:14:14,627
是非常非常的多

431
00:14:14,975 --> 00:14:16,063
既然聊到线程

432
00:14:16,063 --> 00:14:17,151
接下来看看

433
00:14:17,151 --> 00:14:18,207
GPU的线程

434
00:14:18,207 --> 00:14:19,269
它的整体原理

435
00:14:19,477 --> 00:14:20,550
那下面这个就是

436
00:14:20,550 --> 00:14:23,124
GPU的一个线程的机制

437
00:14:23,124 --> 00:14:24,662
或者GPU的整体的架构

438
00:14:24,662 --> 00:14:26,594
左边就是GPU大的架构

439
00:14:26,663 --> 00:14:29,262
右边打开其中一个SM

440
00:14:29,262 --> 00:14:31,147
看一下里面有哪些内容

441
00:14:31,147 --> 00:14:32,355
刚才讲到了

442
00:14:32,355 --> 00:14:34,679
GPU其实里面有大量的SM

443
00:14:34,679 --> 00:14:35,831
SM可以看做

444
00:14:35,831 --> 00:14:38,485
一个基本的运算的单元

445
00:14:38,485 --> 00:14:39,339
在GPU里面

446
00:14:39,339 --> 00:14:41,118
在一个时钟周期内

447
00:14:41,118 --> 00:14:42,676
可以执行多个warp

448
00:14:42,820 --> 00:14:43,592
那warp这个概念

449
00:14:43,592 --> 00:14:45,498
后面会单独的去展开

450
00:14:45,498 --> 00:14:47,931
在一个SM里面有64个warp

451
00:14:47,931 --> 00:14:48,919
其中每四个warp

452
00:14:48,919 --> 00:14:50,628
它可以进行一个并发的执行

453
00:14:50,976 --> 00:14:52,238
GPU的工程师

454
00:14:52,238 --> 00:14:53,307
主要是增加线程

455
00:14:53,307 --> 00:14:54,829
增加warp来解决

456
00:14:54,829 --> 00:14:57,233
或者掩盖延迟的问题

457
00:14:57,233 --> 00:14:58,513
而不是去减少

458
00:14:58,513 --> 00:15:00,910
延迟的时间

459
00:15:00,910 --> 00:15:02,983
因此可以有更多的线程

460
00:15:02,983 --> 00:15:04,453
去解决问题了

461
00:15:04,453 --> 00:15:06,007
下面来看一下

462
00:15:06,007 --> 00:15:07,180
在每一个SM里面

463
00:15:07,180 --> 00:15:10,691
一共有2048个线程

464
00:15:10,691 --> 00:15:13,628
整个A100有20多万个线程

465
00:15:13,628 --> 00:15:15,573
可以提供非常多的线程给

466
00:15:15,573 --> 00:15:16,546
其实很多时候

467
00:15:16,546 --> 00:15:17,415
程序

468
00:15:17,415 --> 00:15:18,939
是用不完线程的

469
00:15:18,939 --> 00:15:20,689
这个是刚才讲到的

470
00:15:20,689 --> 00:15:23,537
有一些线程，它处于计算的过程当中

471
00:15:23,537 --> 00:15:25,725
有一些线程，它在搬运数据

472
00:15:25,725 --> 00:15:27,088
另外还有一些线程

473
00:15:27,088 --> 00:15:29,526
它在同步的等待下一次被计算

474
00:15:29,526 --> 00:15:31,464
因此很多时候会看到

475
00:15:31,464 --> 00:15:34,869
GPU它的算力利用率并不是非常的高

476
00:15:34,869 --> 00:15:37,346
但是完全不觉得它慢

477
00:15:37,346 --> 00:15:39,660
是因为线程是超配的

478
00:15:39,660 --> 00:15:40,697
远远超出

479
00:15:40,697 --> 00:15:43,131
大部分应用程序的使用范围

480
00:15:43,566 --> 00:15:45,187
线程可以在不同的warp上面

481
00:15:45,187 --> 00:15:46,374
进行一个调度

482
00:15:46,788 --> 00:15:48,519
在GPU的工作本质里面

483
00:15:48,519 --> 00:15:50,523
来到了最后一个内容

484
00:15:50,523 --> 00:15:52,427
或者最后一个总结了

485
00:15:52,427 --> 00:15:54,731
CPU跟GPU的本质的区别

486
00:15:54,731 --> 00:15:56,262
主要是并行的问题

487
00:15:56,262 --> 00:15:57,606
而不是并发的问题

488
00:15:57,606 --> 00:16:00,798
GPU通过大量的线程提供并行的能力

489
00:16:01,543 --> 00:16:03,471
那今天的内容就到这里为止

490
00:16:03,471 --> 00:16:04,711
简单的总结一下

491
00:16:04,711 --> 00:16:05,787
GPU的工作原理

492
00:16:05,787 --> 00:16:08,360
首先以AX+Y这个例子

493
00:16:08,360 --> 00:16:10,965
去了解一下并发和并行的区别

494
00:16:10,965 --> 00:16:12,273
还有串行的区别

495
00:16:12,273 --> 00:16:15,620
也就是CPU跟GPU最大的一个不一样

496
00:16:15,620 --> 00:16:18,180
GPU提供并行的机制

497
00:16:18,180 --> 00:16:20,228
下面就了解到了

498
00:16:20,228 --> 00:16:22,760
GPU的整体的缓存的机制

499
00:16:22,760 --> 00:16:23,780
通过多级的缓存

500
00:16:23,780 --> 00:16:24,952
多级的流水

501
00:16:24,952 --> 00:16:26,061
多级的Cache

502
00:16:26,061 --> 00:16:27,994
把整个GPU的内存

503
00:16:27,994 --> 00:16:29,284
把GPU的数据

504
00:16:29,284 --> 00:16:30,958
充分的利用起来

505
00:16:30,958 --> 00:16:31,750
有了这一点

506
00:16:31,750 --> 00:16:32,558
怎么去执行

507
00:16:32,558 --> 00:16:33,715
那么大量的数据

508
00:16:33,715 --> 00:16:34,803
于是就引起了

509
00:16:34,803 --> 00:16:36,918
GPU的线程的原理

510
00:16:36,918 --> 00:16:39,526
GPU里面提供了大量的线程

511
00:16:39,526 --> 00:16:40,603
超配的线程

512
00:16:40,603 --> 00:16:41,359
去完成

513
00:16:41,359 --> 00:16:45,152
对不同层级的数据的搬运和计算

514
00:16:45,449 --> 00:16:47,391
今天的内容就到这里为止

515
00:16:47,469 --> 00:16:48,469
谢谢各位

516
00:16:48,469 --> 00:16:49,000
卷的不行了

517
00:16:49,000 --> 00:16:50,310
卷的不行了

518
00:16:50,310 --> 00:16:51,925
记得一键三连加关注哦

519
00:16:51,925 --> 00:16:53,069
所有的内容都会开源

520
00:16:53,069 --> 00:16:55,000
在下面这条链接里面

521
00:16:55,299 --> 00:16:56,299
拜了个拜

