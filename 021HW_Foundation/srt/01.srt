1
00:00:02,707 --> 00:00:04,707
字幕生成：慎独     字母校对：lim

2
00:00:05,165 --> 00:00:06,690
Hello 大家好

3
00:00:06,690 --> 00:00:08,538
工资劫持了我的身体

4
00:00:08,538 --> 00:00:11,673
床铺埋葬了我的灵魂的ZOMI

5
00:00:12,222 --> 00:00:14,782
现在呢又来到了午夜更新

6
00:00:14,782 --> 00:00:16,270
不是午夜凶灵

7
00:00:16,270 --> 00:00:18,585
这一次来到一个全新的内容

8
00:00:18,585 --> 00:00:19,865
就是AI芯片

9
00:00:19,865 --> 00:00:22,846
这个内容可能很多人不会太关心

10
00:00:22,846 --> 00:00:24,719
但是在整个AI系统里面

11
00:00:24,719 --> 00:00:27,966
AI的芯片是所有的基础

12
00:00:28,246 --> 00:00:31,425
在正式进入到AI芯片的内容之前

13
00:00:31,425 --> 00:00:32,760
来回顾一下

14
00:00:32,760 --> 00:00:34,582
ZOMI在之前的很多系列里面

15
00:00:34,582 --> 00:00:37,289
去给大家分享和汇报过的内容

16
00:00:38,550 --> 00:00:40,200
主要分开三大块

17
00:00:40,200 --> 00:00:42,208
第一块就是AI框架

18
00:00:42,208 --> 00:00:43,925
整体AI框架的核心技术

19
00:00:43,925 --> 00:00:48,342
因为AI框架要正式地跑在芯片上面

20
00:00:48,342 --> 00:00:50,838
于是就离不开编译器

21
00:00:50,838 --> 00:00:53,150
在第二大的内容里面

22
00:00:53,150 --> 00:00:55,830
去给大家分享了整个AI编译器

23
00:00:55,830 --> 00:00:58,553
从传统编译器到AI编译器里面的一些区别

24
00:00:58,553 --> 00:01:01,310
还有AI编译器的前端优化和后端优化

25
00:01:01,310 --> 00:01:04,495
最后以Pytorch2.0作为一个结尾

26
00:01:04,495 --> 00:01:07,123
接着在第三大块的内容里面

27
00:01:07,123 --> 00:01:09,167
去介绍了推理引擎

28
00:01:09,167 --> 00:01:11,934
推理引擎其实也是AI框架的其中一部分

29
00:01:11,934 --> 00:01:13,524
但是它比较独立

30
00:01:13,524 --> 00:01:14,676
里面会做一些

31
00:01:14,676 --> 00:01:16,775
跟网络模型相关、跟算法相关的

32
00:01:16,775 --> 00:01:18,881
模型小型化、模型压缩

33
00:01:18,881 --> 00:01:20,630
最后真正来到了推理引擎里面的

34
00:01:20,630 --> 00:01:21,705
一些架构的模块

35
00:01:21,705 --> 00:01:23,000
离线的转换、图优化

36
00:01:23,000 --> 00:01:24,833
还有Kernels的优化

37
00:01:24,833 --> 00:01:26,177
谈到Kernels的优化

38
00:01:26,177 --> 00:01:28,310
就离不开AI芯片

39
00:01:28,310 --> 00:01:30,409
所以今天来到一个正式的

40
00:01:30,409 --> 00:01:32,201
或者比较重要的一个内容了

41
00:01:32,201 --> 00:01:34,430
就是所有一切的根基

42
00:01:34,430 --> 00:01:35,710
AI芯片

43
00:01:35,710 --> 00:01:36,862
那在AI芯片里面

44
00:01:36,862 --> 00:01:39,166
主要分开两大块内容

45
00:01:39,166 --> 00:01:43,134
第一块就是AI的整个计算体系

46
00:01:43,134 --> 00:01:44,350
那所谓的计算体系

47
00:01:44,350 --> 00:01:48,503
就是AI深度学习、人工智能的计算的模式

48
00:01:48,503 --> 00:01:49,719
到底有哪一些

49
00:01:49,719 --> 00:01:51,110
然后根据计算模式

50
00:01:51,110 --> 00:01:52,403
去了解一下

51
00:01:52,403 --> 00:01:54,707
AI对于硬件的整体的计算体系

52
00:01:54,707 --> 00:01:57,395
还有它最重要的一个计算的方式

53
00:01:57,395 --> 00:01:59,368
就是矩阵运算

54
00:01:59,368 --> 00:02:01,455
接着在第二大模块

55
00:02:01,455 --> 00:02:03,400
和第二个大块的内容里面

56
00:02:03,400 --> 00:02:04,719
去看一下

57
00:02:04,719 --> 00:02:07,125
整个AI芯片的基础

58
00:02:07,125 --> 00:02:08,431
那这个AI芯片的基础

59
00:02:08,431 --> 00:02:09,775
就非常有意思

60
00:02:09,775 --> 00:02:11,695
也不会讲得太深入

61
00:02:11,695 --> 00:02:14,100
而是希望能够粗略的带过

62
00:02:14,100 --> 00:02:16,893
然后以我浅薄的知识

63
00:02:16,893 --> 00:02:19,965
去给大家做一个简单的分享就好了

64
00:02:19,965 --> 00:02:22,205
如果你已经对AI芯片

65
00:02:22,205 --> 00:02:25,034
或者已经比较熟悉整个硬件的体系

66
00:02:25,034 --> 00:02:26,418
完全可以跳过

67
00:02:26,418 --> 00:02:27,432
不要吐槽

68
00:02:27,432 --> 00:02:28,072
确实这里面

69
00:02:28,072 --> 00:02:30,152
后面可能讲得比较粗俗

70
00:02:31,944 --> 00:02:33,480
这整个AI芯片体系

71
00:02:33,480 --> 00:02:35,976
分开4大块内容

72
00:02:35,976 --> 00:02:39,620
那第一块就是通用的处理器CPU

73
00:02:39,620 --> 00:02:43,485
接着会从数据来去看CPU的计算

74
00:02:43,485 --> 00:02:45,789
因为数据量越来越大

75
00:02:45,789 --> 00:02:47,325
不管在图形图像处理

76
00:02:47,325 --> 00:02:48,285
在AI里面

77
00:02:48,285 --> 00:02:50,350
数据量确实越来越大

78
00:02:50,350 --> 00:02:51,485
模型也越来越大

79
00:02:51,485 --> 00:02:52,850
于是就需要用到

80
00:02:52,850 --> 00:02:55,965
通用的图形处理器GPU

81
00:02:55,965 --> 00:02:57,949
因为随着时代的发展

82
00:02:57,949 --> 00:03:00,637
后来又出现了很多专用的处理器

83
00:03:00,637 --> 00:03:02,109
包括NPU还有TPU

84
00:03:02,109 --> 00:03:05,443
华为就推出了自己的达芬奇架构

85
00:03:05,443 --> 00:03:07,170
然后推出了自己的昇腾

86
00:03:07,170 --> 00:03:08,952
产品现在有自己的NPU

87
00:03:08,952 --> 00:03:10,307
接着去看看

88
00:03:10,307 --> 00:03:13,080
整个计算架构体系的黄金10年

89
00:03:13,080 --> 00:03:14,403
也就是未来的

90
00:03:14,403 --> 00:03:16,131
或者现在正在发生

91
00:03:16,131 --> 00:03:18,107
已经迈进的10年

92
00:03:18,107 --> 00:03:19,963
这10年有哪些不一样

93
00:03:19,963 --> 00:03:21,888
有哪些新的知识

94
00:03:21,888 --> 00:03:24,700
但是不要觉得这么简单

95
00:03:24,700 --> 00:03:27,520
其实在讲图形图像处理的时候

96
00:03:27,520 --> 00:03:28,440
在讲GPU

97
00:03:28,440 --> 00:03:30,592
会深入的去探讨一下

98
00:03:30,592 --> 00:03:32,768
GPU的整体的工作原理

99
00:03:32,768 --> 00:03:34,496
还有它的编程的本质

100
00:03:34,496 --> 00:03:36,608
就是它的硬件整体的基础

101
00:03:36,608 --> 00:03:38,208
接着会去看看

102
00:03:38,208 --> 00:03:40,050
以英伟达为例子的

103
00:03:40,050 --> 00:03:41,200
去了解一下

104
00:03:41,200 --> 00:03:42,802
英伟达的GPU的架构

105
00:03:42,802 --> 00:03:44,650
从Fermi到Hopper的架构

106
00:03:44,650 --> 00:03:45,675
里面的演进

107
00:03:45,675 --> 00:03:47,851
包括里面最核心的tensor core

108
00:03:47,851 --> 00:03:49,690
还有里面的NV link

109
00:03:49,690 --> 00:03:51,482
去详解详细的打开

110
00:03:51,482 --> 00:03:53,338
里面到底有什么不一样

111
00:03:53,338 --> 00:03:57,754
接着回到最初的GPU的初衷

112
00:03:57,754 --> 00:04:01,274
它的一个图形的处理流水线

113
00:04:01,274 --> 00:04:02,554
图形的Pipeline

114
00:04:02,554 --> 00:04:04,666
到底是怎么一步一步地

115
00:04:04,666 --> 00:04:07,354
演进到现在AI能够去运算

116
00:04:07,354 --> 00:04:10,269
或者AI用的最多的内容里面

117
00:04:10,269 --> 00:04:12,509
于是在GPU的图形流水线里面

118
00:04:12,509 --> 00:04:14,749
去看看图形流水线的基础

119
00:04:14,749 --> 00:04:16,605
GPU的逻辑模块划分

120
00:04:16,605 --> 00:04:18,461
最后到图形处理的算法

121
00:04:18,461 --> 00:04:19,933
到硬件

122
00:04:19,933 --> 00:04:22,835
到底是什么样的一个关系

123
00:04:22,835 --> 00:04:24,436
了解完GPU之后

124
00:04:24,436 --> 00:04:25,821
肯定离不开

125
00:04:25,821 --> 00:04:28,701
AI专用处理器NPU或者TPU

126
00:04:28,701 --> 00:04:30,405
里面的内容

127
00:04:30,405 --> 00:04:31,637
核心内容

128
00:04:31,637 --> 00:04:33,780
于是就会深入的去看看

129
00:04:33,780 --> 00:04:36,404
华为生腾达芬奇架构NPU

130
00:04:36,404 --> 00:04:38,493
里面到底有什么不一样

131
00:04:38,493 --> 00:04:39,965
先从架构讲起

132
00:04:39,965 --> 00:04:42,420
然后再看看它的整体的处理器

133
00:04:42,420 --> 00:04:44,532
当然了还会去分析一下

134
00:04:44,532 --> 00:04:45,812
友商的产品

135
00:04:45,812 --> 00:04:48,710
谷歌的TPU的最核心脉动阵列

136
00:04:48,710 --> 00:04:49,716
是怎么去实现的

137
00:04:49,716 --> 00:04:50,455
说实话

138
00:04:50,455 --> 00:04:52,852
这个脉动阵列还是有一定的历史的

139
00:04:52,852 --> 00:04:54,217
然后去看看

140
00:04:54,217 --> 00:04:55,497
TPU的整体的架构

141
00:04:55,497 --> 00:04:58,121
从TPU的V1 V2 V3

142
00:04:58,121 --> 00:05:00,153
逐步的演进

143
00:05:00,153 --> 00:05:02,585
最近应该是上一年

144
00:05:02,585 --> 00:05:03,993
21年22年的时候

145
00:05:03,993 --> 00:05:07,110
特斯拉也推出了自己的NPU

146
00:05:07,110 --> 00:05:07,833
DUJO

147
00:05:07,833 --> 00:05:10,649
这个DUJO确实非常的有意思

148
00:05:10,649 --> 00:05:13,768
它的带宽大得非常的惊人

149
00:05:14,100 --> 00:05:15,112
最后一个内容

150
00:05:15,112 --> 00:05:16,788
就去看看国内外

151
00:05:16,788 --> 00:05:17,940
其他AI芯片

152
00:05:17,940 --> 00:05:18,775
然后对它

153
00:05:18,775 --> 00:05:20,488
对整个AI芯片

154
00:05:20,488 --> 00:05:22,828
进行一个全面的思考

155
00:05:22,828 --> 00:05:25,260
这个也仅限于我ZOMI个人的思考

156
00:05:25,260 --> 00:05:28,012
不代表不具有官方的意义

157
00:05:28,012 --> 00:05:30,704
也希望引起大家的共鸣

158
00:05:30,704 --> 00:05:32,560
让大家更多的参与思考

159
00:05:37,825 --> 00:05:39,041
最后一个模块

160
00:05:39,041 --> 00:05:42,241
就是计算体系架构的黄金10年

161
00:05:42,241 --> 00:05:44,993
为什么称它为黄金10年

162
00:05:44,993 --> 00:05:48,255
是因为随着一开始的单核CPU

163
00:05:48,255 --> 00:05:50,825
到多核CPU或者多核的GPU

164
00:05:50,825 --> 00:05:53,089
到现在的CPU跟GPU

165
00:05:53,089 --> 00:05:55,629
或者NPU的异构并行的架构

166
00:05:55,629 --> 00:05:56,717
到后面

167
00:05:56,717 --> 00:05:59,021
或者现在正在发生的

168
00:05:59,021 --> 00:06:01,645
已经是超异构并行的架构上面

169
00:06:01,645 --> 00:06:04,525
需要融合非常多不同的产品

170
00:06:04,525 --> 00:06:06,189
在一个AI计算中心里面

171
00:06:06,189 --> 00:06:07,661
可能就会有大量的CPU

172
00:06:07,661 --> 00:06:09,112
大量的GPU

173
00:06:09,112 --> 00:06:10,328
大量的NPU和DPU

174
00:06:10,328 --> 00:06:12,696
组成的一个超大规模的集群

175
00:06:12,696 --> 00:06:15,485
这个集群已经不仅是AI集群

176
00:06:15,485 --> 00:06:17,666
而是一个超异构的集群

177
00:06:17,666 --> 00:06:20,560
面对摩尔定律已经失效的今天

178
00:06:20,560 --> 00:06:22,989
制程还不断地去演进

179
00:06:22,989 --> 00:06:24,356
于是现在出现了

180
00:06:24,356 --> 00:06:26,340
越来越多的专用的处理器

181
00:06:26,340 --> 00:06:27,525
不同的专用的处理器

182
00:06:27,525 --> 00:06:28,964
怎么跟通用处理器

183
00:06:28,964 --> 00:06:29,950
融合在一起

184
00:06:29,950 --> 00:06:32,766
怎么跟整个超异构并行的架构里面

185
00:06:32,766 --> 00:06:35,162
更好的软硬件的适配

186
00:06:35,162 --> 00:06:38,560
这个时候就引起了最后的思考

187
00:06:38,560 --> 00:06:41,626
计算体架构的黄金10年

188
00:06:41,626 --> 00:06:43,943
那当然今天这个视频

189
00:06:43,943 --> 00:06:46,455
没有太多的核心本质的内容

190
00:06:46,455 --> 00:06:47,875
算是比较随意

191
00:06:47,875 --> 00:06:50,563
在最后我非常推荐大家

192
00:06:50,563 --> 00:06:52,633
去看一看David里面的

193
00:06:52,633 --> 00:06:54,839
关于计算机架构的

194
00:06:54,839 --> 00:06:57,335
黄金10年的一个总结和回顾

195
00:06:57,335 --> 00:06:59,432
这里面我就抽出了

196
00:06:59,432 --> 00:07:01,224
最后的一个PPT

197
00:07:01,224 --> 00:07:03,985
里面的最后的三个总结

198
00:07:03,985 --> 00:07:05,230
第一个就是

199
00:07:05,230 --> 00:07:06,330
软件的发展

200
00:07:06,330 --> 00:07:09,553
能够去激发硬件架构的创新和革命

201
00:07:09,553 --> 00:07:10,720
第二点就是

202
00:07:10,720 --> 00:07:12,315
不管是CISC、RISC

203
00:07:12,315 --> 00:07:15,375
不同的ISA指令的架构级

204
00:07:15,375 --> 00:07:16,975
实际上市场

205
00:07:16,975 --> 00:07:19,023
最终会决定芯片

206
00:07:19,023 --> 00:07:19,791
决定架构

207
00:07:19,791 --> 00:07:22,525
往哪个方向去牵引的

208
00:07:22,525 --> 00:07:24,413
很多时候不用去争论太多

209
00:07:24,413 --> 00:07:26,653
让市场告诉答案

210
00:07:27,045 --> 00:07:27,995
第三点就是

211
00:07:27,995 --> 00:07:30,624
提高更多的软件跟硬件的接口

212
00:07:30,624 --> 00:07:33,696
可以更好地去引发硬件架构的

213
00:07:33,696 --> 00:07:34,976
创新的机会点

214
00:07:34,976 --> 00:07:37,000
这个时候就回到

215
00:07:37,000 --> 00:07:38,198
黄金10年里面的

216
00:07:38,198 --> 00:07:39,280
最后的一个分享

217
00:07:39,280 --> 00:07:41,800
或者最后的一个给大家的汇报

218
00:07:41,800 --> 00:07:44,104
面向异构计算和超异构计算

219
00:07:44,104 --> 00:07:46,152
软硬件应该怎么去协同

