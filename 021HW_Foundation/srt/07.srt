1
00:00:02,725 --> 00:00:04,725
字幕生成：慎独     字母校对：lim

2
00:00:05,425 --> 00:00:07,025
哈喽大家好 我是ZOMI

3
00:00:07,025 --> 00:00:09,720
末期到12点多才来录这个课

4
00:00:09,720 --> 00:00:11,617
每次都是特别的晚

5
00:00:11,617 --> 00:00:14,391
那今天呢来给AI芯片里面的

6
00:00:14,391 --> 00:00:15,936
AI的计算体系

7
00:00:15,936 --> 00:00:18,081
做一个整体的总结

8
00:00:18,081 --> 00:00:19,637
什么叫做计算体系

9
00:00:19,637 --> 00:00:21,659
其实呢在这个内容啊

10
00:00:21,659 --> 00:00:25,115
别说你 我也觉得讲的确实有点分散

11
00:00:25,115 --> 00:00:26,561
而且不聚焦

12
00:00:26,561 --> 00:00:27,393
那讲到后面呢

13
00:00:27,393 --> 00:00:28,913
可能你都不知道自己听的

14
00:00:28,913 --> 00:00:30,913
到底是一个什么样的事情

15
00:00:30,961 --> 00:00:32,127
或者我给你汇报了

16
00:00:32,127 --> 00:00:34,127
到底是一个怎么样的连贯的内容

17
00:00:34,161 --> 00:00:37,583
那现在呢今天对它进行一个串讲

18
00:00:37,583 --> 00:00:40,961
简单的几分钟过一过之前所分享的内容

19
00:00:40,961 --> 00:00:43,134
那第一个呢之前所分享的是

20
00:00:43,134 --> 00:00:45,201
深度学习的计算模式

21
00:00:45,201 --> 00:00:47,477
去看看深度学习有哪些不一样的

22
00:00:47,477 --> 00:00:49,790
计算的范式和计算的模式 

23
00:00:49,790 --> 00:00:51,790
还有它的计算的内容

24
00:00:51,841 --> 00:00:54,881
接着呢去看看AI的计算体系

25
00:00:54,881 --> 00:00:58,241
计算体系里面的最重要的计算就是矩阵运算

26
00:00:58,241 --> 00:01:01,415
所以会从深度学习开始入手

27
00:01:01,415 --> 00:01:05,041
然后再到具体的计算的这个过程

28
00:01:06,450 --> 00:01:09,306
那现在打开深度学习的计算模式

29
00:01:09,306 --> 00:01:10,721
这个内容里面呢

30
00:01:10,721 --> 00:01:13,034
发现其实在一开始的时候

31
00:01:13,034 --> 00:01:15,645
会讲讲AI的发展和它的方式

32
00:01:15,645 --> 00:01:17,198
接着呢去看看

33
00:01:17,198 --> 00:01:20,481
AI的非常经典的网络模型结构

34
00:01:20,481 --> 00:01:22,014
了解完这个之后呢看看

35
00:01:22,014 --> 00:01:25,281
一些模型的量化和剪枝的技术

36
00:01:25,281 --> 00:01:28,241
这些所有东西呢都是围绕着AI去发展的

37
00:01:29,325 --> 00:01:30,900
AI有三大范式

38
00:01:30,900 --> 00:01:31,839
一个就是监督学习

39
00:01:31,839 --> 00:01:32,756
无监督学习

40
00:01:32,756 --> 00:01:34,231
还有强化学习

41
00:01:34,810 --> 00:01:38,081
而最热门的属于监督学习

42
00:01:38,081 --> 00:01:39,472
监督学习里面呢就有

43
00:01:39,472 --> 00:01:42,241
AI它发展的非常多的网络模型

44
00:01:42,241 --> 00:01:44,736
而且网络模型呢变得越来越大

45
00:01:44,736 --> 00:01:46,661
随着箭头所指

46
00:01:47,186 --> 00:01:48,801
在AI的经典模型里面呢

47
00:01:48,801 --> 00:01:52,161
除了CNN网络模型还有LSTM, Transformer

48
00:01:52,161 --> 00:01:56,161
还有RNN这种经典的网络模型结构

49
00:01:56,161 --> 00:01:59,761
接着呢去看看模型的压缩和量化

50
00:01:59,761 --> 00:02:03,441
通过不同的手段呢对矩阵对计算

51
00:02:03,441 --> 00:02:05,521
其实是有非常大的影响

52
00:02:05,521 --> 00:02:08,337
针对网络模型结构还有

53
00:02:08,337 --> 00:02:09,477
模型量化与压缩

54
00:02:09,477 --> 00:02:12,961
让对AI的计算模式提出了一些思考

55
00:02:12,961 --> 00:02:15,441
这些思考就是AI的计算模式

56
00:02:15,441 --> 00:02:17,145
对硬件有什么依赖

57
00:02:17,145 --> 00:02:19,851
对硬件提出什么新的诉求

58
00:02:21,046 --> 00:02:21,782
接着呢

59
00:02:21,782 --> 00:02:23,681
在第三个内容里面呢

60
00:02:23,681 --> 00:02:26,796
去看看深度学习的计算模式里面的

61
00:02:26,796 --> 00:02:28,001
轻量化的模型

62
00:02:28,001 --> 00:02:30,321
还有一些大模型、分布式并行

63
00:02:30,321 --> 00:02:33,441
对计算模式的一些改进和思考

64
00:02:33,441 --> 00:02:35,295
那这里面呢去分享了

65
00:02:35,295 --> 00:02:37,121
或者回顾了一些CNN系列

66
00:02:37,121 --> 00:02:40,481
还有Transformer系列的非常多的网络模型

67
00:02:40,481 --> 00:02:41,361
特别是SOTA

68
00:02:41,361 --> 00:02:44,241
然后呢看看Megatron-LM大语言模型

69
00:02:44,241 --> 00:02:47,377
叫做 LLM : Language Large Model

70
00:02:47,377 --> 00:02:48,721
或者Large Language Model

71
00:02:48,721 --> 00:02:51,441
这种做了很多不同的张量并行

72
00:02:51,441 --> 00:02:53,361
Pipeline并行还有Sequence并行

73
00:02:53,361 --> 00:02:55,801
这种很多的并行的模式

74
00:02:56,212 --> 00:02:57,921
了解完轻量化的网络模型

75
00:02:57,921 --> 00:02:59,601
还有一些并行的模式之后呢

76
00:02:59,601 --> 00:03:04,001
对AI的计算模式也进行了一个回顾和思考

77
00:03:04,635 --> 00:03:05,521
到这里为止呢

78
00:03:05,521 --> 00:03:09,761
已经了解完了整个深度学习的计算模式

79
00:03:09,761 --> 00:03:14,241
深度学习AI它有哪些不一样的计算的特点

80
00:03:14,241 --> 00:03:16,161
那基于这些计算的特点呢

81
00:03:16,161 --> 00:03:19,281
引申出了下一个内容

82
00:03:19,281 --> 00:03:22,081
计算体系还有矩阵运算

83
00:03:22,081 --> 00:03:25,521
这里面值得注意的就是一个呢是计算的模式

84
00:03:25,521 --> 00:03:27,441
一个是计算的体系

85
00:03:28,146 --> 00:03:32,561
现在简单地过一过计算体系里面有哪些内容

86
00:03:33,921 --> 00:03:36,481
在AI的计算体系里面呢

87
00:03:36,481 --> 00:03:39,761
去看看AI芯片的关键的设计指标

88
00:03:39,761 --> 00:03:42,129
就是之前已经讲过了

89
00:03:42,129 --> 00:03:44,961
很多深度学习的计算的模式

90
00:03:45,836 --> 00:03:46,796
这些模式呢

91
00:03:46,796 --> 00:03:48,081
对关键指标

92
00:03:48,081 --> 00:03:49,277
对设计的指标

93
00:03:49,277 --> 00:03:50,902
是有非常大的牵引作用的

94
00:03:50,902 --> 00:03:53,201
然后呢去看看矩阵的运算

95
00:03:53,201 --> 00:03:55,382
就是整个AI计算体系里面

96
00:03:55,382 --> 00:03:57,041
最核心最关键的计算

97
00:03:57,041 --> 00:03:58,321
有了这些计算之后呢

98
00:03:58,321 --> 00:04:00,481
可以看看比特的位数

99
00:04:00,481 --> 00:04:02,081
针对不同的应用场景呢

100
00:04:02,081 --> 00:04:04,561
它可能会使用不同的比特位数

101
00:04:04,641 --> 00:04:08,401
针对不同的运算也会使用不同的比特位数

102
00:04:09,306 --> 00:04:10,961
接着呢进入第一个内容

103
00:04:10,961 --> 00:04:12,641
就是AI的关键指标

104
00:04:12,641 --> 00:04:16,241
那关键指标里面呢有两个非常非常的核心

105
00:04:16,241 --> 00:04:18,481
一个就是带宽bandwidth

106
00:04:18,481 --> 00:04:21,521
一个就是PE执行引擎

107
00:04:21,521 --> 00:04:25,841
PE跟执行引擎之间会决定峰值算力

108
00:04:25,841 --> 00:04:27,661
不同的PE不同的带宽之间

109
00:04:27,661 --> 00:04:31,281
需要找到一个很好的平衡配合点

110
00:04:31,281 --> 00:04:33,281
有了这个基础的了解之后呢

111
00:04:33,281 --> 00:04:36,801
就会对整个AI体系的关键的设计指标

112
00:04:36,801 --> 00:04:39,493
有精度、吞吐率、时延

113
00:04:39,493 --> 00:04:41,041
还有一些额外的指标

114
00:04:41,041 --> 00:04:44,001
就是能耗、系统的价格还有易用性

115
00:04:45,114 --> 00:04:47,601
可能前四个呢跟硬件非常相关

116
00:04:47,601 --> 00:04:50,161
那系统价格易用性这个两个事情呢

117
00:04:50,161 --> 00:04:51,761
就比较玄学了

118
00:04:51,761 --> 00:04:54,161
或者比较有大的浮动性

119
00:04:54,161 --> 00:04:56,561
然后了解完关键的设计指标之后呢

120
00:04:56,561 --> 00:04:58,161
看看矩阵的运算

121
00:04:58,161 --> 00:05:01,441
矩阵运算是整个AI计算体系里面

122
00:05:01,521 --> 00:05:04,401
最核心的运算的方式

123
00:05:05,281 --> 00:05:06,987
不管是CNN、Transformer

124
00:05:06,987 --> 00:05:08,278
还有Linear、MatMul

125
00:05:08,278 --> 00:05:10,001
这种计算模式全连接的

126
00:05:10,001 --> 00:05:14,481
都会把它转换成为具体的矩阵乘

127
00:05:14,481 --> 00:05:18,161
通过矩阵乘的方式去代替传统的卷积

128
00:05:18,161 --> 00:05:20,215
因此会说矩阵乘

129
00:05:20,215 --> 00:05:23,281
是AI体系里面最核心的计算

130
00:05:23,281 --> 00:05:25,681
于是呢基于这个最核心的计算

131
00:05:25,681 --> 00:05:27,911
会去思考关于软件上面

132
00:05:27,911 --> 00:05:30,081
应该怎么去设计硬件

133
00:05:30,081 --> 00:05:34,401
关于硬件上面呢怎么去符合关键设计指标

134
00:05:35,315 --> 00:05:38,323
接着呢去看看最后一个内容就是

135
00:05:38,323 --> 00:05:40,323
比特的位宽

136
00:05:40,899 --> 00:05:42,819
知道矩阵的运算呢

137
00:05:42,819 --> 00:05:46,001
是基于最基本的数据单元去运算的

138
00:05:46,001 --> 00:05:48,859
而数据单元最基本的存储单位呢

139
00:05:48,859 --> 00:05:50,067
就是bit

140
00:05:50,067 --> 00:05:51,441
位数

141
00:05:51,441 --> 00:05:53,281
所以呢针对不同的数据呢

142
00:05:53,281 --> 00:05:55,041
是有不同的位宽

143
00:05:55,041 --> 00:05:56,321
不同的存储格式

144
00:05:57,021 --> 00:05:59,921
而在具体的芯片设计场景里面

145
00:05:59,921 --> 00:06:04,641
到底拥有多少FP32 多少BF16 多少FP16呢

146
00:06:04,641 --> 00:06:07,921
是跟芯片跟应用场景相关的

147
00:06:07,921 --> 00:06:11,361
如果我的芯片呢主要是针对训练的场景

148
00:06:11,361 --> 00:06:16,241
可能会提供更多的FP32还有FP16

149
00:06:16,881 --> 00:06:20,241
但是如果我芯片更多的可能是针对推理场景

150
00:06:20,241 --> 00:06:23,338
那这个时候呢int8跟FP16

151
00:06:23,338 --> 00:06:26,241
可能是更好的一种选择

152
00:06:26,241 --> 00:06:28,961
最后呢对整个AI芯片的设计

153
00:06:29,041 --> 00:06:32,241
特别是位宽呢做了一个整体的回顾

154
00:06:33,402 --> 00:06:35,386
接着最后了

155
00:06:35,386 --> 00:06:37,121
来到一个最后的内容

156
00:06:37,121 --> 00:06:39,553
来一个summary大串讲

157
00:06:39,553 --> 00:06:43,521
把刚才讲的知识呢再重新的回顾一把

158
00:06:43,521 --> 00:06:47,521
那首先去了解了整个深度学习的计算模式

159
00:06:47,521 --> 00:06:50,001
包括经典的网络模型结构、轻量化

160
00:06:50,001 --> 00:06:51,281
模型的量化压缩

161
00:06:51,281 --> 00:06:52,753
再到大模型

162
00:06:52,753 --> 00:06:56,145
去理解什么是计算

163
00:06:56,400 --> 00:06:59,681
计算对硬件需求是什么

164
00:06:59,681 --> 00:07:02,161
需要什么来去更好的计算

165
00:07:02,161 --> 00:07:05,681
接着呢通过AI的芯片的关键指标

166
00:07:05,681 --> 00:07:09,761
去了解一款芯片如何更好的支持计算

167
00:07:09,761 --> 00:07:12,001
需要关注哪些重点的工作

168
00:07:12,001 --> 00:07:14,801
这种就是关键的设计指标

169
00:07:14,801 --> 00:07:19,361
从而引出峰值算力、PE和带宽之间的关系

170
00:07:19,361 --> 00:07:23,601
最后就去了解一下深度学习的计算核心

171
00:07:23,601 --> 00:07:26,161
矩阵乘这个内容

172
00:07:26,161 --> 00:07:29,201
来看看对实际的计算有哪些需求

173
00:07:29,201 --> 00:07:31,041
那为了提高计算性能

174
00:07:31,041 --> 00:07:35,521
降低功耗还有满足训练不同场景的精度和要求

175
00:07:35,521 --> 00:07:39,361
对计算呢会引入很多复杂的

176
00:07:39,361 --> 00:07:41,681
非常多样化的比特的位宽

177
00:07:42,321 --> 00:07:44,081
下面的这两个呢

178
00:07:44,081 --> 00:07:47,601
是跟AI计算体系相关

179
00:07:47,601 --> 00:07:52,161
上面这个呢是跟AI计算模式相关

180
00:07:52,161 --> 00:07:55,761
从算法倒推到软硬件

181
00:07:55,841 --> 00:07:57,761
应该怎么去设计

182
00:07:57,761 --> 00:07:59,521
应该怎么去做牵引

183
00:07:59,521 --> 00:08:02,764
好了 今天的内容到这里为止

184
00:08:02,764 --> 00:08:03,589
谢谢各位

185
00:08:03,589 --> 00:08:05,089
白白喵

