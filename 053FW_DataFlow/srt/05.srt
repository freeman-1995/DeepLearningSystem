1
00:00:05,131 --> 00:00:07,131
哈喽大家好,我是ZOMI

2
00:00:07,131 --> 00:00:09,131
昨天录的太晚

3
00:00:09,131 --> 00:00:11,131
所以今天上班的时候

4
00:00:11,131 --> 00:00:13,131
经常在摸鱼

5
00:00:14,881 --> 00:00:15,881
废话不多说了

6
00:00:16,131 --> 00:00:18,131
来看看今天一个很重要的内容

7
00:00:18,131 --> 00:00:20,131
也是我觉得计算图里面

8
00:00:20,131 --> 00:00:22,131
除了自动微分之外

9
00:00:22,131 --> 00:00:24,131
第二个最重要的内容了

10
00:00:24,131 --> 00:00:26,131
就是控制流

11
00:00:27,131 --> 00:00:28,131
那控制流里面

12
00:00:28,131 --> 00:00:30,131
今天主要是讲几个概念

13
00:00:30,131 --> 00:00:32,131
第一个去看看什么是控制流

14
00:00:32,506 --> 00:00:34,506
控制流跟计算图是怎么表示的

15
00:00:34,506 --> 00:00:36,506
还有它们之间的关系

16
00:00:36,506 --> 00:00:38,506
接着去讲讲动态图

17
00:00:38,506 --> 00:00:40,506
引起的控制流的问题

18
00:00:40,506 --> 00:00:42,506
还有静态图跟控制流的关系

19
00:00:42,506 --> 00:00:44,506
最后看看

20
00:00:44,506 --> 00:00:46,506
现在经常去讲

21
00:00:46,506 --> 00:00:48,506
TensorFlow也好,Pytorch也好

22
00:00:48,506 --> 00:00:51,929
都会做一些动静统一的结合和技术

23
00:00:51,929 --> 00:00:53,929
它到底是个什么样子的

24
00:00:58,206 --> 00:01:01,206
其实深度学习它是一个可编程的系统

25
00:01:01,206 --> 00:01:03,206
或者叫做可编程的框架

26
00:01:03,206 --> 00:01:05,206
这个框架在设计的时候

27
00:01:05,206 --> 00:01:09,206
首先第一个就是希望能够让前端用户

28
00:01:09,206 --> 00:01:12,206
能够独立于后面的芯片使能

29
00:01:12,206 --> 00:01:14,206
让前端的用户不用感知

30
00:01:14,206 --> 00:01:16,206
底层的硬件的实现的细节

31
00:01:16,206 --> 00:01:20,206
然后用更贴近于神经网络的方式

32
00:01:20,206 --> 00:01:22,206
去实现他们想要的算法和任务

33
00:01:23,606 --> 00:01:25,606
为了解决这个问题

34
00:01:25,606 --> 00:01:28,606
AI框架这里面就提出了一个统一的表示

35
00:01:28,606 --> 00:01:30,606
叫做计算图

36
00:01:30,606 --> 00:01:32,606
通过这个统一的描述

37
00:01:32,606 --> 00:01:34,606
可以帮助前端的用户

38
00:01:34,606 --> 00:01:38,606
在编程的时候更加灵活的去编写它的算法

39
00:01:38,606 --> 00:01:42,606
这个计算图也影响了后面的优化的方式

40
00:01:42,606 --> 00:01:44,606
还有整个系统如何进行扩展

41
00:01:44,606 --> 00:01:47,606
都是将神经网络的计算抽象成为一个

42
00:01:47,606 --> 00:01:50,606
由基本原语构成的有向无环图

43
00:01:50,606 --> 00:01:52,856
也就是叫做DAG图

44
00:01:53,381 --> 00:01:56,381
不过呢,随着深度学习网络的研究的发展

45
00:01:56,381 --> 00:01:59,381
特别是这几年呈现井喷式的发展

46
00:01:59,381 --> 00:02:02,381
迎来了RNN, LSTM的结构之后

47
00:02:02,381 --> 00:02:04,381
又迎来了Transformer

48
00:02:04,381 --> 00:02:08,381
甚至最近的还有GAN, Diffusion这种网络模型

49
00:02:08,381 --> 00:02:10,381
出现这些网络模型

50
00:02:10,381 --> 00:02:13,381
就对AI框架引起了更大的挑战

51
00:02:13,381 --> 00:02:17,381
下面这段代码就是我从Hungerface里面去摘取的

52
00:02:17,381 --> 00:02:20,275
一个Decision Transformer里面的

53
00:02:20,275 --> 00:02:22,381
其中关于Transformer的一个结构

54
00:02:22,381 --> 00:02:25,381
可以看到Transformer里面的一个结构

55
00:02:25,381 --> 00:02:28,381
在Forward的阶段它有一个if else

56
00:02:28,381 --> 00:02:30,381
然后还有一个if

57
00:02:30,381 --> 00:02:34,381
这一些if else, while都是动态的一个控制流

58
00:02:34,381 --> 00:02:38,381
另外的话,在对Transformer进行堆叠的时候

59
00:02:38,381 --> 00:02:40,381
又引入了大量的for循环

60
00:02:40,381 --> 00:02:44,381
这个时候就对系统提出了非常大的挑战

61
00:02:44,381 --> 00:02:47,381
怎么样去更好地支持

62
00:02:47,381 --> 00:02:50,381
这个时候对AI框架和AI系统

63
00:02:50,381 --> 00:02:52,381
就提出了比较大的一个挑战

64
00:02:52,381 --> 00:02:56,381
怎么样去支持这些动态的控制流语句

65
00:02:58,381 --> 00:03:01,381
AI框架为了更好地支持这些

66
00:03:01,381 --> 00:03:04,381
天生就含有控制流语句的神经网络模型

67
00:03:04,381 --> 00:03:08,381
于是就会不约而同的去对动态控制流

68
00:03:08,381 --> 00:03:11,381
引入了新的语言结构的支持

69
00:03:11,381 --> 00:03:14,381
现在在控制流的解决方案里面

70
00:03:14,381 --> 00:03:17,381
好几个框架其实都有自己的一套解决方案

71
00:03:17,381 --> 00:03:20,381
来看看现在主流的三种解决方案

72
00:03:20,381 --> 00:03:22,381
虽然现在的AI框架很多

73
00:03:22,381 --> 00:03:24,381
但是主要是集中这三种

74
00:03:24,381 --> 00:03:30,381
首先第一种就是后端对控制流语句进行原生的支持

75
00:03:30,381 --> 00:03:33,381
也就是支持控制流原生的算子和原语

76
00:03:33,381 --> 00:03:36,381
然后允许在计算图里面

77
00:03:36,381 --> 00:03:39,381
去有一些控制流或者数据流进行混合

78
00:03:39,381 --> 00:03:43,381
这种方式最典型的代表就是TensorFlow

79
00:03:43,381 --> 00:03:46,381
第二种就是复用前端语言的控制流语句

80
00:03:46,381 --> 00:03:50,381
也就是我直接附用Python的控制流语句

81
00:03:50,381 --> 00:03:54,381
然后通过Python的语言去驱动后端的数据流图的执行

82
00:03:54,381 --> 00:03:57,381
这种最典型的方式就是PyTorch

83
00:03:57,381 --> 00:04:00,381
另外第三种就是MindSpore

84
00:04:00,381 --> 00:04:05,381
第三种就是后端对控制流的语言结构进行解析

85
00:04:05,381 --> 00:04:07,381
变成一个子图

86
00:04:07,381 --> 00:04:11,381
也就是通过原码表示的方式变成一个计算图

87
00:04:11,381 --> 00:04:14,381
这个最典型的代表就是MindSpore

88
00:04:14,381 --> 00:04:19,381
然后PyTorch和TensorFlow最新的版本也开始慢慢的引入

89
00:04:25,381 --> 00:04:27,381
下面来打开看看第一种方式

90
00:04:27,381 --> 00:04:29,381
也就是典型的TensorFlow的方式

91
00:04:29,381 --> 00:04:34,381
它主要是向数据流图中添加一个控制流原语

92
00:04:34,381 --> 00:04:37,381
控制流原语主要是在这一层

93
00:04:37,381 --> 00:04:41,381
然后里面去提供一些底层的控制流原语

94
00:04:41,381 --> 00:04:47,381
Enter, Switch, Exist, Merge, Next, Iterator一共是五个

95
00:04:47,381 --> 00:04:50,381
这种方式来看看它的特点

96
00:04:50,381 --> 00:04:52,381
先看完特点再解析那个图

97
00:04:52,381 --> 00:04:58,381
这种方式主要是采用声明式的编程去获得一个计算图

98
00:04:58,381 --> 00:05:02,381
在编译阶段对整个计算图进行全局的优化

99
00:05:02,381 --> 00:05:06,381
第二种它执行的时候就不需要在前端语言就是Python

100
00:05:06,381 --> 00:05:10,381
还有后端的OneTime的时候反复的切换

101
00:05:10,381 --> 00:05:13,381
这个时候就可以有更高的执行效率

102
00:05:13,381 --> 00:05:16,381
把整个图都央到OneTime去执行

103
00:05:16,381 --> 00:05:20,381
这种方式就是控制流原语提供一个控制流原语

104
00:05:20,381 --> 00:05:25,381
把控制流原语作为语言的第一特性然后去执行的

105
00:05:25,381 --> 00:05:28,381
现在来看看下面的这个图

106
00:05:28,381 --> 00:05:30,381
首先我从上往下看

107
00:05:30,381 --> 00:05:33,381
上面就是计算图的API

108
00:05:33,381 --> 00:05:35,381
也就是TensorFlow的一些API

109
00:05:35,381 --> 00:05:39,381
TensorFlow最基础的提供了tf.while_loop

110
00:05:39,381 --> 00:05:41,381
还有tf.condition或cond

111
00:05:41,381 --> 00:05:44,381
这两个操作while_loop就是for循环

112
00:05:44,381 --> 00:05:46,381
Condition就是if else这种方式

113
00:05:46,381 --> 00:05:51,381
TensorFlow发现这种方式可能用的不太好用

114
00:05:51,381 --> 00:05:54,381
于是它又提供了高层次的API

115
00:05:54,381 --> 00:05:57,381
tf.map_fn, tf.case

116
00:05:57,381 --> 00:05:58,381
这两种方式

117
00:05:58,381 --> 00:06:02,381
但是TF出了名就是难用就是不好用

118
00:06:02,381 --> 00:06:04,381
谷歌为了解决这个问题

119
00:06:04,381 --> 00:06:08,381
然后又推出了另外一个更高级的API

120
00:06:08,381 --> 00:06:11,381
这个API就是叫做autograph

121
00:06:11,381 --> 00:06:16,381
通过Python控制流原码转换为一个最基本的控制流API

122
00:06:16,381 --> 00:06:19,381
也就是通过刚才说的第三种方式

123
00:06:19,381 --> 00:06:21,381
原码转换的方式

124
00:06:21,381 --> 00:06:24,381
把它变成tf.while_loop和tf.cond

125
00:06:24,381 --> 00:06:27,381
就是在里面自己写了些模板

126
00:06:27,381 --> 00:06:29,381
然后把这些模板套上来

127
00:06:29,381 --> 00:06:31,381
就是这么简单的一个工作

128
00:06:31,381 --> 00:06:33,381
它其实只是做了一个转换

129
00:06:33,381 --> 00:06:35,381
再往下层看一看

130
00:06:35,381 --> 00:06:37,381
刚才讲了

131
00:06:37,381 --> 00:06:41,381
计算图原语在TensorFlow里面就提供了几种原语

132
00:06:41,381 --> 00:06:45,381
这几种原语就是去组成tf.while_loop和tf.cond的

133
00:06:45,381 --> 00:06:48,381
就是把这几个简单的组合

134
00:06:48,381 --> 00:06:51,381
再往下就是图并优化层了

135
00:06:51,381 --> 00:06:55,381
对上面使用底层控制流语句构建好的图进行一些编译优化

136
00:06:55,381 --> 00:07:00,381
那图优化能看到的其实更多的是底层的一个控制流语句

137
00:07:00,381 --> 00:07:01,381
因为在做转换的时候

138
00:07:01,381 --> 00:07:04,381
它已经一步步的变成这个图了

139
00:07:07,381 --> 00:07:09,381
下面就是举一个简单的例子

140
00:07:09,381 --> 00:07:12,381
看一下TensorFlow里面具体是怎么实现的

141
00:07:12,381 --> 00:07:14,381
首先有一个例子

142
00:07:14,381 --> 00:07:18,381
就是两个嵌套循环的for,for=0

143
00:07:18,381 --> 00:07:19,381
然后叠代到10

144
00:07:19,381 --> 00:07:20,381
然后不断的去叠加

145
00:07:20,381 --> 00:07:23,381
那中间的某个计算就不展示出来了

146
00:07:23,381 --> 00:07:25,381
在TensorFlow 2.0里面

147
00:07:25,381 --> 00:07:28,381
它的使用方式其实是比较头痛的

148
00:07:28,381 --> 00:07:31,381
最后调用while_loop就两个for

149
00:07:31,381 --> 00:07:35,381
把ABCY存起来就两个for嵌套循环

150
00:07:36,381 --> 00:07:38,381
上层的表达就是这样的

151
00:07:38,381 --> 00:07:42,381
但是底层怎么去记录怎么去实现呢

152
00:07:42,381 --> 00:07:46,381
首先在TensorFlow里面有 一个叫做执行增

153
00:07:46,381 --> 00:07:47,381
Execution Firm

154
00:07:47,381 --> 00:07:52,381
这个执行增具有全局唯一的名字作为标识符

155
00:07:52,381 --> 00:07:56,381
可以把它作为一个域或者Scope一个方式

156
00:07:56,381 --> 00:07:59,381
然后下面就有很多key和value

157
00:07:59,381 --> 00:08:01,381
就有一些字典的方式

158
00:08:01,381 --> 00:08:05,381
字典存的就是算子还有算子对应的上下文

159
00:08:05,381 --> 00:08:07,381
包括它的输入数据的地址

160
00:08:07,381 --> 00:08:09,381
输出数据的地址

161
00:08:09,381 --> 00:08:10,381
算子的属性

162
00:08:10,381 --> 00:08:13,381
然后下面嵌套for的时候怎么办呢

163
00:08:13,381 --> 00:08:15,381
再嵌套一个执行增

164
00:08:15,381 --> 00:08:18,381
为的就是并发的时候可以利用这些记录的工作

165
00:08:18,381 --> 00:08:20,381
或者执行增的这个Scope

166
00:08:20,381 --> 00:08:22,381
然后进行一些并发的计算

167
00:08:22,381 --> 00:08:26,381
那这个就是TensorFlow在底层去执行的一个方式

168
00:08:26,381 --> 00:08:30,381
现在来看一下TensorFlow比较特别的

169
00:08:30,381 --> 00:08:33,381
它其实在一个condition语句里面

170
00:08:33,381 --> 00:08:37,381
就是if else里面用的是两个原语进行组合的

171
00:08:37,381 --> 00:08:39,381
那第一个原语就是switch

172
00:08:39,381 --> 00:08:41,381
第二个原语就是merge

173
00:08:41,381 --> 00:08:44,381
通过switch和merge不断的组合

174
00:08:44,381 --> 00:08:46,381
然后变成这么一条表达式

175
00:08:46,381 --> 00:08:48,381
那可能第一个就是判断

176
00:08:48,381 --> 00:08:50,381
然后第二个就是能不能打执行

177
00:08:50,381 --> 00:08:54,381
可以看到直接用TensorFlow的condition这个API

178
00:08:54,381 --> 00:08:56,381
其实是很难去理解

179
00:08:56,381 --> 00:08:59,381
或者非常不方便去写代码的

180
00:08:59,381 --> 00:09:00,381
不过没关系

181
00:09:00,381 --> 00:09:01,381
继续往下看一看

182
00:09:01,381 --> 00:09:04,381
更复杂的一个操作就是while_loop

183
00:09:04,381 --> 00:09:05,381
写一个for

184
00:09:05,381 --> 00:09:06,381
写一个for的时候

185
00:09:06,381 --> 00:09:08,381
计算图更加复杂了

186
00:09:08,381 --> 00:09:11,381
右边下面的这个是实际上TensorFlow

187
00:09:11,381 --> 00:09:14,381
这个AI框架去执行的计算图

188
00:09:14,381 --> 00:09:17,381
用户用的是while_loop这个API

189
00:09:17,381 --> 00:09:22,381
这时候TensorFlow就把五个控制流的原语

190
00:09:22,381 --> 00:09:24,381
进行一个组装拼合

191
00:09:24,381 --> 00:09:26,381
所以它用起来也是让我比较头痛的

192
00:09:26,381 --> 00:09:28,381
那现在来看看

193
00:09:28,381 --> 00:09:30,381
像TensorFlow这种方式

194
00:09:30,381 --> 00:09:31,381
就是提供控制流原语

195
00:09:31,381 --> 00:09:33,381
它有什么优缺点

196
00:09:38,881 --> 00:09:40,881
先来聊聊缺点

197
00:09:40,881 --> 00:09:42,881
因为缺点实在是太明显了

198
00:09:42,881 --> 00:09:44,881
就是它的控制流语句

199
00:09:44,881 --> 00:09:46,881
首先是服务它的运行时的

200
00:09:46,881 --> 00:09:48,881
就是为了在它的系统

201
00:09:48,881 --> 00:09:50,881
能够更好的去执行并发

202
00:09:50,881 --> 00:09:54,881
所以它设计了一套这种控制流原语

203
00:09:54,881 --> 00:09:55,881
有一个比较大的问题就是

204
00:09:55,881 --> 00:09:58,881
它跟深度学习的概念差异非常大

205
00:09:58,881 --> 00:10:00,881
我要重新的去学习一套

206
00:10:00,881 --> 00:10:02,881
它的API是怎么做的

207
00:10:02,881 --> 00:10:04,881
因为它的用户是用户

208
00:10:06,756 --> 00:10:08,756
第二个问题就是

209
00:10:08,756 --> 00:10:10,756
它对控制流原语进行再次封装

210
00:10:10,756 --> 00:10:12,756
那控制流的API的方式

211
00:10:12,756 --> 00:10:14,756
是提供给用户使用的

212
00:10:14,756 --> 00:10:16,756
导致我的计算图很复杂

213
00:10:16,756 --> 00:10:18,756
说白了就是用户看的是

214
00:10:18,756 --> 00:10:20,175
tf.while_loop, tf.cond

215
00:10:20,175 --> 00:10:22,756
实际上计算机执行的是

216
00:10:22,756 --> 00:10:24,756
这么复杂的一个计算图

217
00:10:24,756 --> 00:10:26,756
这个计算图你让我看真不好看

218
00:10:26,756 --> 00:10:30,956
假设它for里面再嵌套一个if else

219
00:10:31,556 --> 00:10:33,956
if else又嵌套一个for

220
00:10:33,956 --> 00:10:37,956
这个时候计算图真的没法看了

221
00:10:41,631 --> 00:10:43,631
那优点就是

222
00:10:43,631 --> 00:10:45,631
像计算图里面引入控制流原语

223
00:10:45,631 --> 00:10:47,631
非常方便编译期间

224
00:10:47,631 --> 00:10:49,631
挖掘运行时的效率

225
00:10:49,631 --> 00:10:51,631
也就是j极致的性能

226
00:10:51,631 --> 00:10:53,631
第二个就是

227
00:10:53,631 --> 00:10:55,631
解耦数字语言和执行过程

228
00:10:55,631 --> 00:10:57,631
加速整个运行时

229
00:10:57,631 --> 00:10:59,631
第二点可能跟第一点不一样

230
00:10:59,631 --> 00:11:01,631
就是把前端语言表达

231
00:11:01,631 --> 00:11:03,631
跟后端执行

232
00:11:03,631 --> 00:11:05,631
隔离开来

233
00:11:05,631 --> 00:11:07,631
不用反复的去利用宿主的if else

234
00:11:07,631 --> 00:11:09,631
Pytorch使用的是动态图

235
00:11:09,631 --> 00:11:11,631
它主要是

236
00:11:11,631 --> 00:11:13,631
复用宿主语言的控制流

237
00:11:13,631 --> 00:11:15,631
所谓的宿主语言

238
00:11:15,631 --> 00:11:17,631
就是高级语言

239
00:11:17,631 --> 00:11:19,631
用户用到写API的语言

240
00:11:19,631 --> 00:11:21,631
这里面简单的一个计算图

241
00:11:21,631 --> 00:11:23,631
假设这个是神经网络的图

242
00:11:23,631 --> 00:11:25,631
AI框架在Pytorch里面

243
00:11:25,631 --> 00:11:27,631
就不再维护一个计算图

244
00:11:27,631 --> 00:11:29,631
计算图只是其中一个

245
00:11:29,631 --> 00:11:31,631
方便用户理解的概念

246
00:11:31,631 --> 00:11:33,631
接着使用Pytorch

247
00:11:33,631 --> 00:11:35,631
就好像使用Python代码一样

248
00:11:35,631 --> 00:11:37,631
模型即代码

249
00:11:37,631 --> 00:11:39,631
写一个网络模型出来

250
00:11:39,631 --> 00:11:41,631
就表示神经网络

251
00:11:41,631 --> 00:11:43,631
接着后端就直接以库的形式

252
00:11:43,631 --> 00:11:45,631
去执行WinDNA

253
00:11:45,631 --> 00:11:47,631
CUDA,OpenCL

254
00:11:47,631 --> 00:11:49,631
还有CAN,像这种

255
00:11:49,631 --> 00:11:51,631
就直接执行里面的语句

256
00:11:51,631 --> 00:11:53,631
但是一旦设计到控制流的时候

257
00:11:53,631 --> 00:11:55,631
就在CPU或者在上层

258
00:11:55,631 --> 00:11:57,631
宿主语言,就是Python里面

259
00:11:57,631 --> 00:11:59,631
去执行

260
00:11:59,631 --> 00:12:01,631
这样附用宿主语言控制流的动态图方式

261
00:12:01,631 --> 00:12:03,631
有两个最大的好处

262
00:12:03,631 --> 00:12:05,631
第一个就是用户

263
00:12:05,631 --> 00:12:07,631
能够灵活的使用

264
00:12:07,631 --> 00:12:09,631
前端宿主语言进行表达控制流

265
00:12:09,631 --> 00:12:11,631
就直接使用Python的

266
00:12:11,631 --> 00:12:13,631
If else while for这些

267
00:12:13,631 --> 00:12:15,631
去表达控制流

268
00:12:15,631 --> 00:12:17,631
马上就输出张量的计算求解结果

269
00:12:17,631 --> 00:12:19,631
也就是我写完这个代码之后

270
00:12:19,631 --> 00:12:21,631
我一执行S等于X加Y

271
00:12:21,631 --> 00:12:23,631
马上就输出结果

272
00:12:23,631 --> 00:12:25,631
另外一个好处就是

273
00:12:25,631 --> 00:12:27,631
大家都说PyTorch非常好用

274
00:12:27,631 --> 00:12:29,631
所以它定义神经网络

275
00:12:29,631 --> 00:12:31,631
就像编写真正的程序一样

276
00:12:31,631 --> 00:12:33,631
让开发者更加容易接受

277
00:12:33,631 --> 00:12:35,631
但是问题也很严重

278
00:12:35,631 --> 00:12:37,631
用户很容易

279
00:12:37,631 --> 00:12:39,631
滥用前端的语言特性

280
00:12:39,631 --> 00:12:41,631
带来非常复杂的性能问题

281
00:12:41,631 --> 00:12:43,631
也就是你要做PyTorch的性能优化

282
00:12:43,631 --> 00:12:45,631
其实是有很多问题的

283
00:12:45,631 --> 00:12:47,631
第二个就是执行流

284
00:12:47,631 --> 00:12:49,631
第二个就是执行流会在语言的边界来跳转

285
00:12:49,631 --> 00:12:51,631
带来严重的

286
00:12:51,631 --> 00:12:53,631
one time的开销

287
00:12:53,631 --> 00:12:55,631
这个就是代表

288
00:12:55,631 --> 00:12:57,631
我可能语句在Python

289
00:12:57,631 --> 00:12:59,631
在CPU里面去执行

290
00:12:59,631 --> 00:13:01,631
我的后面张量的计算

291
00:13:01,631 --> 00:13:03,631
我在我的NPU、GPU上面去执行

292
00:13:03,631 --> 00:13:05,631
一个在NPU执行

293
00:13:05,631 --> 00:13:07,631
一个在CPU执行

294
00:13:07,631 --> 00:13:09,631
中间就涉及到GPU跟CPU之间的通讯

295
00:13:09,631 --> 00:13:11,631
第三个就是控制流

296
00:13:11,631 --> 00:13:13,631
和数据流隔离在前端

297
00:13:13,631 --> 00:13:15,631
控制流我在前端

298
00:13:15,631 --> 00:13:17,631
控制流大部分都是用Python代码

299
00:13:17,631 --> 00:13:19,631
数据流可能执行的是机器码

300
00:13:19,631 --> 00:13:21,631
这个时候

301
00:13:21,631 --> 00:13:23,631
跨语言的优化是很痛苦的

302
00:13:32,481 --> 00:13:34,481
第三种方式

303
00:13:34,481 --> 00:13:36,481
就是MindSpore的一种方式

304
00:13:36,481 --> 00:13:38,481
对Python的原码进行解析

305
00:13:38,481 --> 00:13:40,481
然后变成一个计算图

306
00:13:40,481 --> 00:13:42,481
这个计算图是已经展开的计算图

307
00:13:42,481 --> 00:13:44,481
或者已经展开了

308
00:13:44,481 --> 00:13:46,481
或者已经展开作为子图的

309
00:13:46,481 --> 00:13:48,481
那它里面有两种方式

310
00:13:48,481 --> 00:13:50,481
第一种就是

311
00:13:50,481 --> 00:13:52,481
计算图能够直接表达的

312
00:13:52,481 --> 00:13:54,481
那就直接把它表达出来了

313
00:13:54,481 --> 00:13:56,481
例如for循环里面

314
00:13:56,481 --> 00:13:58,481
它直接把它变成一个串型的计算图

315
00:13:58,481 --> 00:14:00,481
例如我for两次

316
00:14:00,481 --> 00:14:02,481
那我可能把for两次里面的计算子

317
00:14:02,481 --> 00:14:04,481
直接列出来

318
00:14:04,481 --> 00:14:06,481
然后去变成计算图

319
00:14:06,481 --> 00:14:08,481
那第二个

320
00:14:08,481 --> 00:14:10,481
像if else这种

321
00:14:10,481 --> 00:14:12,481
它可能就会把它变成两个子图

322
00:14:12,481 --> 00:14:14,481
if里面的一个子图

323
00:14:14,481 --> 00:14:16,481
else里面的又另外一个子图

324
00:14:16,481 --> 00:14:18,481
然后运行的时候

325
00:14:18,481 --> 00:14:20,481
动态的去选择两个子图

326
00:14:20,481 --> 00:14:22,481
进行运算

327
00:14:22,481 --> 00:14:24,481
那优点就是用户

328
00:14:24,481 --> 00:14:26,481
能够得到一定程度自由的

329
00:14:26,481 --> 00:14:28,481
去使用前端数字语言的控制流

330
00:14:28,481 --> 00:14:30,481
也就是用户

331
00:14:30,481 --> 00:14:32,481
可以使用简单的

332
00:14:32,481 --> 00:14:34,481
Python的代码

333
00:14:34,481 --> 00:14:36,481
去写一些控制流

334
00:14:36,481 --> 00:14:38,481
另外一个优点就是

335
00:14:38,481 --> 00:14:40,481
接有了数字语言和执行过程

336
00:14:40,481 --> 00:14:42,481
可以得到一定的效率的提升

337
00:14:42,481 --> 00:14:44,481
第三个就是

338
00:14:44,481 --> 00:14:46,481
我会有一个统一的计算图

339
00:14:46,481 --> 00:14:48,481
能够去做一些性能的优化

340
00:14:48,481 --> 00:14:50,481
看上去一切都很美好

341
00:14:50,481 --> 00:14:52,481
但是

342
00:14:52,481 --> 00:14:54,481
如果硬件不支持我的

343
00:14:54,481 --> 00:14:56,481
这种算子的选择

344
00:14:56,481 --> 00:14:58,481
程序依然会在语言的

345
00:14:58,481 --> 00:15:00,481
边界进行跳转

346
00:15:00,481 --> 00:15:02,481
仍然会有one time的开销

347
00:15:02,481 --> 00:15:04,481
部分Python的控制流的

348
00:15:04,481 --> 00:15:06,481
代码不能够表示有一定的

349
00:15:06,481 --> 00:15:08,481
约束性

350
00:15:08,481 --> 00:15:10,481
谈到它会有一定程度自由的使用

351
00:15:10,481 --> 00:15:12,481
而不是完全自由的

352
00:15:12,481 --> 00:15:14,481
去使用

353
00:15:14,481 --> 00:15:16,481
卷的不行

354
00:15:16,481 --> 00:15:18,481
记得一键三连加关注

355
00:15:18,481 --> 00:15:20,481
所有的内容都会开源在下面这条链接里面

356
00:15:20,481 --> 00:15:22,481
拜了个拜

