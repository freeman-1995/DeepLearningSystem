1
00:00:00,000 --> 00:00:05,760
哈喽大家好

2
00:00:05,760 --> 00:00:09,400
在上一节里面新挖了一个坑叫做计算图

3
00:00:09,400 --> 00:00:11,800
计算图看着好像很简单

4
00:00:11,800 --> 00:00:15,040
其实里面还有很多内容等去一起去挖掘的

5
00:00:15,040 --> 00:00:19,080
计算图在某些场景里面又叫数据流图

6
00:00:19,080 --> 00:00:20,320
为了统一概念

7
00:00:20,320 --> 00:00:23,560
在这里面统一叫它叫做计算图就好了

8
00:00:23,560 --> 00:00:25,400
后面聊到数据流图啊

9
00:00:25,400 --> 00:00:26,160
DAG图啊

10
00:00:26,160 --> 00:00:29,200
其实都把它当做计算图去看待就好了

11
00:00:29,520 --> 00:00:32,760
那计算图的出现其实是为了解决AI系统

12
00:00:32,760 --> 00:00:35,160
化过程当中遇到的很多问题

13
00:00:35,560 --> 00:00:38,400
那下面来看看定义一个神经网络

14
00:00:38,400 --> 00:00:40,160
或者深度学习之前

15
00:00:40,160 --> 00:00:42,440
一般有那几种步骤

16
00:00:42,440 --> 00:00:46,320
之前在AI框架系统里面已经简单的讲过了

17
00:00:46,320 --> 00:00:48,200
首先就是定一个神经网络

18
00:00:48,200 --> 00:00:51,000
从输入马东梅到预测马什么梅

19
00:00:51,400 --> 00:00:52,600
马东梅

20
00:00:53,160 --> 00:00:54,080
什么东梅啊

21
00:00:55,120 --> 00:00:57,560
接着去定义优化目标

22
00:00:57,560 --> 00:00:58,960
就是优化目标

23
00:00:59,080 --> 00:01:01,760
接着呢自动的去更新梯度

24
00:01:02,040 --> 00:01:03,360
那这里面问题就来了

25
00:01:03,760 --> 00:01:05,840
怎么样去实现进入自动求导吗

26
00:01:05,840 --> 00:01:08,400
自动求导这个工作其实是很复杂的

27
00:01:08,680 --> 00:01:13,040
那第二个怎么在系统里面统一的表示神经网络了

28
00:01:13,040 --> 00:01:16,480
就是这个神经网络到底怎么去用程序去表达呢

29
00:01:17,320 --> 00:01:19,520
除了上层表示上的问题呢

30
00:01:19,520 --> 00:01:22,160
其实还会遇到更多的问题

31
00:01:22,160 --> 00:01:26,120
例如假设已经有了对程序的表达

32
00:01:26,200 --> 00:01:30,000
现在怎么对这个神经网络进行简化合并变化

33
00:01:30,000 --> 00:01:31,880
让它在硬件上面

34
00:01:31,880 --> 00:01:34,360
就是底层这些英伟达或者华为

35
00:01:34,360 --> 00:01:39,000
Atlas800这些训练服务器上面更高效的去执行呢

36
00:01:40,600 --> 00:01:42,920
假设我刚才只有一台服务器

37
00:01:42,920 --> 00:01:45,240
现在我有多台服务器的时候

38
00:01:45,240 --> 00:01:47,680
怎么对内存进行预分配和管理了

39
00:01:48,000 --> 00:01:49,640
如果我只是一堆程序

40
00:01:49,640 --> 00:01:51,640
我可能依赖于编译器是吧

41
00:01:51,640 --> 00:01:53,960
LVM等传统的编译器去执行

42
00:01:53,960 --> 00:01:55,480
但是深度学习

43
00:01:55,640 --> 00:01:57,080
他用什么编译器呢

44
00:01:57,920 --> 00:02:01,160
如果我用编译器编译成机器指令之后

45
00:02:01,160 --> 00:02:03,320
我怎么去适配到不同的后端

46
00:02:03,320 --> 00:02:05,200
不同的硬件去执行呢

47
00:02:06,240 --> 00:02:07,760
我太难了

48
00:02:07,760 --> 00:02:11,600
所以AI框架在系统化或者工程化当中呢

49
00:02:11,600 --> 00:02:13,880
会遇到非常非常多的问题

50
00:02:14,160 --> 00:02:16,800
如果其他同学看到有这么多问题

51
00:02:16,800 --> 00:02:19,040
或者如果你能想到更多的问题

52
00:02:19,040 --> 00:02:20,680
或者更核心的问题

53
00:02:20,680 --> 00:02:22,440
也非常欢迎给点弹幕

54
00:02:22,920 --> 00:02:25,720
为了解决刚才所说的很多问题

55
00:02:25,720 --> 00:02:26,600
所以呢

56
00:02:26,600 --> 00:02:27,600
在这里面

57
00:02:27,600 --> 00:02:31,800
在AI框架和这个就是AI框架的最原始的图里面

58
00:02:31,800 --> 00:02:34,600
就提出了一个统一表示

59
00:02:34,600 --> 00:02:37,720
去把各种各样的神经网络的模型

60
00:02:37,720 --> 00:02:40,800
然后通过一个计算图对它进行表达

61
00:02:40,800 --> 00:02:42,360
包括Transformer

62
00:02:42,360 --> 00:02:43,080
CNN

63
00:02:43,080 --> 00:02:44,360
LSTM RNN

64
00:02:44,360 --> 00:02:46,960
都可以通过这个计算图进行表达

65
00:02:46,960 --> 00:02:48,640
那对上呢就是前端

66
00:02:48,640 --> 00:02:50,520
对下呢就是一堆的层了

67
00:02:51,520 --> 00:02:54,880
计算图最基本的组成主要是由

68
00:02:54,880 --> 00:02:56,150
张量，Tensor 

69
00:02:56,150 --> 00:02:58,440
还有算子，Operator来组成的 

70
00:02:58,440 --> 00:03:01,080
Tensor呢就作为最基本的数据结构

71
00:03:01,080 --> 00:03:03,680
主要是对高维的数字进行表示

72
00:03:03,680 --> 00:03:06,920
它也是对标量向量矩阵的一种推广

73
00:03:06,920 --> 00:03:08,800
那可能一开始呢

74
00:03:08,800 --> 00:03:11,640
很多人没有接触计算机体系的时候呢

75
00:03:11,640 --> 00:03:14,000
一谈标量可能不知道是什么

76
00:03:14,000 --> 00:03:16,520
标量呢简单的理解就是一个数

77
00:03:16,520 --> 00:03:19,440
123567这些叫做数

78
00:03:19,480 --> 00:03:21,680
在高等数学的线性代数里面

79
00:03:21,680 --> 00:03:23,520
其实已经学到大量的

80
00:03:23,520 --> 00:03:25,760
向量和矩阵的运算了

81
00:03:25,760 --> 00:03:27,560
那高维的数组

82
00:03:27,560 --> 00:03:28,480
也就是张量

83
00:03:28,480 --> 00:03:29,880
它只是一个表示

84
00:03:29,880 --> 00:03:32,480
那通常呢会用张量来代表

85
00:03:32,480 --> 00:03:34,520
对更高维的数组

86
00:03:34,520 --> 00:03:36,640
例如4维3维5维

87
00:03:36,640 --> 00:03:38,560
甚至到6 7维

88
00:03:38,560 --> 00:03:40,320
例如在华为昇腾的

89
00:03:40,320 --> 00:03:43,760
Atlas服务器或者Atlas这个芯片里面呢

90
00:03:43,760 --> 00:03:45,680
可能一般对数据的

91
00:03:45,680 --> 00:03:48,120
会直接把它表示成6维的数据

92
00:03:48,160 --> 00:03:49,520
然后进行运算的

93
00:03:49,520 --> 00:03:51,480
不过大家不用深度的去理解

94
00:03:51,480 --> 00:03:54,080
现在去讲的张量呢

95
00:03:54,080 --> 00:03:55,600
主要是稠密的张量 

96
00:03:55,600 --> 00:03:56,520
稀疏的张量呢

97
00:03:56,520 --> 00:03:58,080
暂时不去谈

98
00:03:58,080 --> 00:03:59,360
那张量的形状呢

99
00:03:59,360 --> 00:04:02,120
像这个图可能这个张量的shape呢

100
00:04:02,120 --> 00:04:03,560
就是325

101
00:04:03,560 --> 00:04:06,000
那从后面往前看

102
00:04:06,000 --> 00:04:07,520
是从后面往前看

103
00:04:07,520 --> 00:04:08,080
第一个呢

104
00:04:08,080 --> 00:04:08,760
是5呢

105
00:04:08,760 --> 00:04:11,520
就是指我有5维的一个数组

106
00:04:11,520 --> 00:04:11,960
2呢

107
00:04:11,960 --> 00:04:13,880
就是这个数组有两排

108
00:04:13,880 --> 00:04:14,520
那3呢

109
00:04:14,520 --> 00:04:17,680
就是有三组这种2乘以5的数组

110
00:04:17,680 --> 00:04:22,120
这样呢就组成了一个3维shape为325的一个张量

111
00:04:22,120 --> 00:04:25,680
那张量它主要里面的元素的基本数据类型

112
00:04:25,680 --> 00:04:26,920
也会进行表示的

113
00:04:26,920 --> 00:04:29,000
就是Data Type等于Int Float

114
00:04:29,000 --> 00:04:31,040
还是其他数据类型

115
00:04:31,040 --> 00:04:33,320
就是代表里面每一个元素

116
00:04:33,320 --> 00:04:35,840
具体存的是哪一种数据类型

117
00:04:37,440 --> 00:04:40,280
为什么AI框架里面的计算图

118
00:04:40,280 --> 00:04:42,800
使用张量这个数据结构呢

119
00:04:42,800 --> 00:04:44,960
作为它最基础的数据结构呢

120
00:04:44,960 --> 00:04:46,200
其实可以看到啊

121
00:04:46,240 --> 00:04:47,960
它优点有两个

122
00:04:47,960 --> 00:04:49,640
这是我能够想得到的

123
00:04:49,640 --> 00:04:50,120
第一个呢

124
00:04:50,120 --> 00:04:52,880
就是在上层用户表示的时候

125
00:04:52,880 --> 00:04:56,160
其实可以把它表示成一个张量的数组

126
00:04:56,160 --> 00:04:58,400
那在底层做物理运算的时候

127
00:04:58,400 --> 00:04:59,640
或者计算的时候

128
00:04:59,640 --> 00:05:01,960
就有了一个统一的数据结构

129
00:05:01,960 --> 00:05:04,240
可以对物理的地址进行映射

130
00:05:04,240 --> 00:05:05,840
非常方便对物理啊

131
00:05:05,840 --> 00:05:07,520
或者对内存进行切片

132
00:05:07,520 --> 00:05:09,040
切分操作

133
00:05:09,040 --> 00:05:13,240
那第二个优点就是在作为最基本的运算的时候呢

134
00:05:13,240 --> 00:05:15,800
可以把数据变成一个整体

135
00:05:15,800 --> 00:05:17,400
做批操作处理

136
00:05:17,400 --> 00:05:19,520
特别适合与单指令多数据

137
00:05:19,520 --> 00:05:21,760
就是SIMD的这种并行加速

138
00:05:23,280 --> 00:05:26,240
作为计算的最基本的单元

139
00:05:26,240 --> 00:05:28,240
对计算肯定是有帮助的

140
00:05:28,240 --> 00:05:29,800
所以叫做张量呢

141
00:05:29,800 --> 00:05:33,360
是作为计算图的最基本的数据结构

142
00:05:33,360 --> 00:05:37,640
那下面来看一看张量的几个不同维度的数据

143
00:05:37,640 --> 00:05:38,240
首先呢

144
00:05:38,240 --> 00:05:39,360
是一维的张量

145
00:05:39,360 --> 00:05:39,960
一维的张量

146
00:05:39,960 --> 00:05:40,960
其实一般呢

147
00:05:40,960 --> 00:05:43,880
都把它叫做向量或者矩阵就完了

148
00:05:43,920 --> 00:05:44,390
二维呢

149
00:05:44,390 --> 00:05:44,440
可能就是一个矩阵

150
00:05:44,440 --> 00:05:46,190
可能就是一个矩阵

151
00:05:46,240 --> 00:05:47,040
那三维呢

152
00:05:47,040 --> 00:05:49,200
可能更多的日常呢

153
00:05:49,200 --> 00:05:51,640
会更多的代表一张图片

154
00:05:51,640 --> 00:05:52,760
因为一张图片呢

155
00:05:52,760 --> 00:05:53,960
就有长和宽

156
00:05:53,960 --> 00:05:55,240
当然它有一个channel

157
00:05:55,240 --> 00:05:58,120
就由三个不同的通道组成一张图片

158
00:05:58,120 --> 00:06:00,000
才能够变成一个彩色的图片

159
00:06:01,240 --> 00:06:02,960
那这个时候在图像里面呢

160
00:06:02,960 --> 00:06:04,320
刚才已经用了三维

161
00:06:04,320 --> 00:06:05,760
就是CHW了

162
00:06:05,760 --> 00:06:07,600
C就是channel

163
00:06:07,600 --> 00:06:09,080
实际上图像呢

164
00:06:09,080 --> 00:06:12,760
作为张量丢进去AI框架进行计算之前呢

165
00:06:12,760 --> 00:06:15,120
前面还会加一个维度

166
00:06:15,120 --> 00:06:16,760
叫做N就是Batch

167
00:06:16,760 --> 00:06:17,720
Batch Size

168
00:06:17,720 --> 00:06:20,760
就是把多张图片打包成一起

169
00:06:20,760 --> 00:06:24,560
然后丢给AI框架进行处理的

170
00:06:24,560 --> 00:06:26,840
这个时候图像张量化处理

171
00:06:26,840 --> 00:06:28,760
丢给AI系统之前

172
00:06:28,760 --> 00:06:31,800
就会把数据组成一个四维的张量

173
00:06:31,800 --> 00:06:33,560
当然了自然语言处理呢

174
00:06:33,560 --> 00:06:35,040
可能会比较特别

175
00:06:35,040 --> 00:06:36,240
因为自然语言处理

176
00:06:36,240 --> 00:06:38,360
首先第一个就是词向量

177
00:06:38,360 --> 00:06:39,600
就是我的Words

178
00:06:39,600 --> 00:06:40,840
有了单词之后

179
00:06:40,840 --> 00:06:42,680
我可能还会用sentenced

180
00:06:42,680 --> 00:06:44,520
就是把它拼成一个句子

181
00:06:44,520 --> 00:06:48,040
就是不同的单词组成句子

182
00:06:48,040 --> 00:06:48,560
然后呢

183
00:06:48,560 --> 00:06:51,320
我有很多个句子或者很多个段落

184
00:06:51,320 --> 00:06:53,600
那所以前面再加一个N

185
00:06:53,600 --> 00:06:56,160
这样就变成一个自然语言处理的张量了

186
00:06:57,520 --> 00:06:59,800
刚才谈到的图像啊

187
00:06:59,800 --> 00:07:02,400
自然语言处理是最基础的任务

188
00:07:02,400 --> 00:07:04,720
实际上还有一些稀疏张量

189
00:07:04,720 --> 00:07:06,040
特别是到后期

190
00:07:06,040 --> 00:07:08,080
或者现在大模型计算的时候

191
00:07:08,080 --> 00:07:10,400
会引起大量稀疏的问题

192
00:07:10,400 --> 00:07:12,080
那最新的一个研究热点

193
00:07:12,080 --> 00:07:13,000
就是图

194
00:07:13,000 --> 00:07:14,400
图和点这两个了

195
00:07:14,400 --> 00:07:15,800
也是稀疏张量

196
00:07:15,800 --> 00:07:17,120
可能在这里面呢

197
00:07:17,120 --> 00:07:19,800
就暂时不要去展开稀疏的关系

198
00:07:19,800 --> 00:07:22,800
在AI框架基础里面的历史环节

199
00:07:22,800 --> 00:07:25,080
或者历史那一小节里面呢

200
00:07:25,080 --> 00:07:28,480
已经讲过了最基础的计算图有什么概念

201
00:07:28,480 --> 00:07:29,040
这里面呢

202
00:07:29,040 --> 00:07:30,280
重复一下

203
00:07:30,280 --> 00:07:34,040
或者做一个更加详细一丢丢的一个理解

204
00:07:34,040 --> 00:07:34,920
那计算图呢

205
00:07:34,920 --> 00:07:36,560
它是一个有向无环图

206
00:07:36,560 --> 00:07:39,120
但是现在不要去理解那个图

207
00:07:39,120 --> 00:07:40,880
而是先去理解一下

208
00:07:40,920 --> 00:07:44,800
计算图里面有两种最重要的元素

209
00:07:44,800 --> 00:07:45,560
那第一种呢

210
00:07:45,560 --> 00:07:47,120
就是最基本的数据结构

211
00:07:47,120 --> 00:07:48,360
叫张量

212
00:07:48,760 --> 00:07:49,440
那第二个呢

213
00:07:49,440 --> 00:07:51,120
就是基本的运算单元

214
00:07:51,120 --> 00:07:52,360
叫做算子

215
00:07:52,360 --> 00:07:53,560
所以大家提到算子

216
00:07:53,560 --> 00:07:56,480
不要觉得算子只是一些加减乘除啊

217
00:07:56,480 --> 00:07:58,120
其实卷积、BatchNorm

218
00:07:58,120 --> 00:07:58,880
Sigmod

219
00:07:58,880 --> 00:08:01,200
还有很多后来提出的

220
00:08:01,200 --> 00:08:02,240
包括Transformer

221
00:08:02,240 --> 00:08:04,120
后来已经成为一个大的算子

222
00:08:04,120 --> 00:08:05,480
所以算子有大有小

223
00:08:05,480 --> 00:08:07,400
小的算子可能加减乘除

224
00:08:07,400 --> 00:08:09,400
求根号或cos、sin

225
00:08:09,400 --> 00:08:11,040
那复杂的神经网络的算子

226
00:08:11,040 --> 00:08:13,600
可能就是类似于CudaNN这种

227
00:08:13,600 --> 00:08:15,080
提供了很多卷积

228
00:08:15,080 --> 00:08:18,440
LSTM,RNN,Transformer这一类的大算子

229
00:08:19,960 --> 00:08:20,600
下面呢

230
00:08:20,600 --> 00:08:22,520
了解了两个基本的概念

231
00:08:22,520 --> 00:08:23,840
或者基本的元素之后呢

232
00:08:23,840 --> 00:08:26,440
现在就来看看数据流图了

233
00:08:26,440 --> 00:08:28,880
或者DAG图或者计算图

234
00:08:28,880 --> 00:08:31,360
那后面都叫做计算图就好了

235
00:08:31,360 --> 00:08:32,080
里面呢

236
00:08:32,080 --> 00:08:35,720
主要是表示神经网络的一个运算逻辑和状态

237
00:08:35,720 --> 00:08:36,120
这个呢

238
00:08:36,120 --> 00:08:38,480
就是最基础的正向的计算图

239
00:08:38,480 --> 00:08:39,280
比较好看

240
00:08:39,280 --> 00:08:40,640
比较容易理解

241
00:08:40,640 --> 00:08:41,280
节点呢

242
00:08:41,280 --> 00:08:45,400
就代表刚才所说的一些算子

243
00:08:45,400 --> 00:08:47,000
包括卷积、ReLU

244
00:08:48,080 --> 00:08:48,720
那边呢

245
00:08:48,720 --> 00:08:49,640
就代表张量

246
00:08:49,640 --> 00:08:51,080
就是数据流

247
00:08:51,080 --> 00:08:54,320
所以有时候叫做数据流图或者计算图

248
00:08:54,320 --> 00:08:55,120
那计算图呢

249
00:08:55,120 --> 00:08:57,440
更聚焦于中间的这个计算

250
00:08:57,440 --> 00:08:58,520
计算很重要

251
00:08:58,520 --> 00:08:59,360
数据流图呢

252
00:08:59,360 --> 00:09:00,800
就代表这个数据呢

253
00:09:00,800 --> 00:09:02,680
是通过不断的去流动的

254
00:09:02,680 --> 00:09:05,120
然后其实他们都是代表DAG图

255
00:09:05,120 --> 00:09:06,600
都是同一个概念

256
00:09:06,600 --> 00:09:07,080
然后呢

257
00:09:07,120 --> 00:09:09,480
张量就从这里面不断的流进去

258
00:09:09,480 --> 00:09:10,800
计算的算子

259
00:09:10,800 --> 00:09:11,600
然后流出来

260
00:09:11,600 --> 00:09:12,720
作为输出

261
00:09:12,720 --> 00:09:13,640
然后输出呢

262
00:09:13,640 --> 00:09:15,480
作为下一个算子的输入

263
00:09:15,480 --> 00:09:19,280
这么一个简单的表示神经网络的计算逻辑

264
00:09:19,280 --> 00:09:23,080
for、while这种控制流相关的一些语句

265
00:09:23,080 --> 00:09:23,880
那这个时候呢

266
00:09:23,880 --> 00:09:24,920
计算图呢

267
00:09:24,920 --> 00:09:26,720
可能就会变得更加复杂

268
00:09:26,720 --> 00:09:29,320
或者循环的时候就嵌套一套套的

269
00:09:29,320 --> 00:09:32,240
嵌套很多个往下的计算图

270
00:09:32,240 --> 00:09:33,560
在后面的章节里面呢

271
00:09:33,560 --> 00:09:35,360
就会详细的去展开

272
00:09:35,360 --> 00:09:38,880
当数据流图遇到这些控制流的时候怎么办

273
00:09:40,800 --> 00:09:43,280
那下面来回顾一下

274
00:09:43,280 --> 00:09:48,720
刚才了解了AI实际上在系统化工程化当中呢

275
00:09:48,720 --> 00:09:50,800
会遇到非常多的问题

276
00:09:50,800 --> 00:09:53,120
怎么去表示我的神经网络

277
00:09:53,120 --> 00:09:54,840
表示网友的神经网络呢

278
00:09:54,840 --> 00:09:57,200
怎么去适配到不同的硬件上面

279
00:09:57,200 --> 00:09:58,800
这都有大量的问题

280
00:09:58,800 --> 00:10:00,400
那为了解决这些问题呢

281
00:10:00,400 --> 00:10:02,440
所以就提出了计算图

282
00:10:02,440 --> 00:10:04,200
能够对AI系统

283
00:10:04,200 --> 00:10:04,880
对下呢

284
00:10:04,880 --> 00:10:09,320
对AI的硬件执行或者计算进行了一个统一的表示

285
00:10:09,320 --> 00:10:10,080
对上呢

286
00:10:10,080 --> 00:10:12,320
承接各种各样的AI的算法

287
00:10:12,320 --> 00:10:14,400
或者AI的程序的表达

288
00:10:14,400 --> 00:10:15,080
那另外呢

289
00:10:15,080 --> 00:10:17,040
还了解了计算图呢

290
00:10:17,040 --> 00:10:19,400
主要是由张量和基本的算子

291
00:10:19,400 --> 00:10:23,000
两个最基础的元素所组成的

292
00:10:23,000 --> 00:10:25,080
好了今天的课程比较简单

293
00:10:25,080 --> 00:10:25,880
谢谢各位

294
00:10:25,880 --> 00:10:26,760
白了个白

295
00:10:27,680 --> 00:10:28,480
卷的不行了

296
00:10:28,480 --> 00:10:29,360
卷的不行了

297
00:10:29,360 --> 00:10:31,160
记得一键三连加关注哦

298
00:10:31,160 --> 00:10:34,160
所有的内容都会开源在下面这条链接里面

299
00:10:34,160 --> 00:10:35,520
拜了个拜

