1
00:00:04,850 --> 00:00:06,850
哈喽大家好,我是ZOMI

2
00:00:06,850 --> 00:00:08,850
昨天录的太晚

3
00:00:08,850 --> 00:00:10,850
所以今天上班的时候

4
00:00:10,850 --> 00:00:12,850
经常在摸鱼

5
00:00:14,850 --> 00:00:15,850
废话不多说了

6
00:00:15,850 --> 00:00:17,850
来看看今天一个很重要的内容

7
00:00:17,850 --> 00:00:19,850
也是我觉得计算图里面

8
00:00:19,850 --> 00:00:21,850
除了自动微分之外

9
00:00:21,850 --> 00:00:23,850
第二个最重要的内容了

10
00:00:23,850 --> 00:00:25,850
就是控制流

11
00:00:26,850 --> 00:00:27,850
那控制流里面

12
00:00:27,850 --> 00:00:29,850
今天主要是讲几个概念

13
00:00:29,850 --> 00:00:32,950
第一个去看看什么是控制流

14
00:00:32,950 --> 00:00:35,475
控制流跟计算图是怎么表示的

15
00:00:35,575 --> 00:00:37,575
还有它们之间的关系

16
00:00:37,575 --> 00:00:39,575
接着去讲讲动态图

17
00:00:39,575 --> 00:00:41,575
引起的控制流的问题

18
00:00:41,575 --> 00:00:43,575
还有静态图跟控制流的关系

19
00:00:43,575 --> 00:00:45,575
最后看看

20
00:00:45,575 --> 00:00:47,575
现在经常去讲

21
00:00:47,575 --> 00:00:49,575
TensorFlow也好,Pytorch也好

22
00:00:49,575 --> 00:00:51,575
都会做一些动静统一的结合和技术

23
00:00:51,575 --> 00:00:53,575
它到底是个什么样子的

24
00:00:59,575 --> 00:01:04,575
最后来看看动态图转换成为静态图

25
00:01:04,575 --> 00:01:06,575
这也是MindSpore这个AI框架

26
00:01:06,575 --> 00:01:10,575
首次提出动静态图统一的概念

27
00:01:10,575 --> 00:01:13,575
后来有了TensorFlow推出了AutoGrade

28
00:01:13,575 --> 00:01:15,575
Pytorch推出了JIT

29
00:01:15,575 --> 00:01:17,575
都是使用这种方式

30
00:01:17,575 --> 00:01:19,575
也是希望能够把动态图转换成为静态图

31
00:01:19,575 --> 00:01:23,575
这个概念是MindSpore头包第一次提出的

32
00:01:24,575 --> 00:01:27,575
下面来看看动态图转静态图

33
00:01:27,575 --> 00:01:28,575
主要有两种方式

34
00:01:28,575 --> 00:01:30,575
第一种就是基于追踪

35
00:01:30,575 --> 00:01:31,575
就是Trace的方式

36
00:01:31,575 --> 00:01:34,575
第二种就是基于原码转换AST

37
00:01:34,575 --> 00:01:36,575
抽象语法树的方式

38
00:01:36,575 --> 00:01:38,575
不要着急

39
00:01:38,575 --> 00:01:40,575
下面来逐个算法去展开

40
00:01:40,575 --> 00:01:42,575
具体是怎么实现的

41
00:01:42,575 --> 00:01:45,575
首先第一个就是基于追踪的方式

42
00:01:45,575 --> 00:01:47,575
基于追踪的方式比较直接

43
00:01:47,575 --> 00:01:49,575
就是直接执行用户的代码

44
00:01:49,575 --> 00:01:50,575
直接执行Python代码

45
00:01:50,575 --> 00:01:52,575
记录下算子的调用的序列

46
00:01:52,575 --> 00:01:55,575
把这些序列的保存成为一个静态图

47
00:01:56,575 --> 00:01:59,575
然后在问探的时候去执行静态图就好了

48
00:01:59,575 --> 00:02:03,575
优点就是非常广泛的去支持数字语言的各种控制流

49
00:02:03,575 --> 00:02:06,575
这个其实更像PyTorch的方式

50
00:02:06,575 --> 00:02:08,575
就PyTorch原生的方式

51
00:02:08,575 --> 00:02:11,575
但是问题就是场景非常受限

52
00:02:11,575 --> 00:02:15,575
只能保存有限次执行的轨迹并且线性化

53
00:02:15,575 --> 00:02:19,575
静态图就失去了原程序的完整的控制流

54
00:02:19,575 --> 00:02:23,575
就是可以这么简单的理解

55
00:02:23,575 --> 00:02:26,575
我基于用户的代码进行一个追踪

56
00:02:26,575 --> 00:02:31,575
但是我不可能把用户的所有的程序都执行一遍

57
00:02:31,575 --> 00:02:32,575
既然不能执行一遍

58
00:02:32,575 --> 00:02:34,575
那我可能只能执行一两遍

59
00:02:34,575 --> 00:02:37,575
去做一个检测代码或者做一个遍历

60
00:02:37,575 --> 00:02:39,575
知道它的代码结构

61
00:02:39,575 --> 00:02:41,575
然后变成一个静态图

62
00:02:41,575 --> 00:02:45,175
所以这种方式其实在实际的AI框架

63
00:02:45,175 --> 00:02:47,575
或者AI系统里面用的比较少

64
00:02:47,575 --> 00:02:49,575
用的更多的这里面

65
00:02:49,575 --> 00:02:52,575
这里面以Pytorch的JIT为例子

66
00:02:52,575 --> 00:02:54,575
就Just in time

67
00:02:54,575 --> 00:02:57,575
那天我在群里面跟一些同事去聊

68
00:02:57,575 --> 00:03:00,575
他们说你一听到JIT

69
00:03:00,575 --> 00:03:04,575
十个用户有九个用户都不知道JIT到底是什么

70
00:03:04,575 --> 00:03:07,575
另外一个同事又跳出来补充了一句

71
00:03:07,575 --> 00:03:12,575
十个用户有9.999个用户不知道JIT是什么

72
00:03:12,575 --> 00:03:14,575
JIT就是Jaxed in time

73
00:03:14,575 --> 00:03:17,575
也就是在运行时动态编译

74
00:03:17,575 --> 00:03:19,575
计算机实际运行的是机器码

75
00:03:19,575 --> 00:03:23,575
通过把前端的这些高级语言变成汇编语言

76
00:03:23,575 --> 00:03:28,575
然后每一条汇编都对应一条对应一串机器码

77
00:03:28,575 --> 00:03:34,575
而JIT Just in time就是在内存里面生成和运行一段代码

78
00:03:34,575 --> 00:03:37,575
就是边执行边运行这么理解就好了

79
00:03:37,575 --> 00:03:40,575
下面来看看基于原码解析的方式

80
00:03:40,575 --> 00:03:44,575
基于原码解析的方式就是把数字语言

81
00:03:44,575 --> 00:03:48,375
就是把Python的语言通过抽象语法树

82
00:03:48,375 --> 00:03:50,575
把它变成一个内部的语法树

83
00:03:50,575 --> 00:03:52,575
也就是这种内部的语法树

84
00:03:52,575 --> 00:03:54,575
Internal AST数

85
00:03:54,575 --> 00:03:58,575
然后经过SSA等各种编译优化之后

86
00:03:58,575 --> 00:04:01,575
再做一些类型的推导等不同的pass

87
00:04:01,575 --> 00:04:04,575
然后最终转换成为一个计算图

88
00:04:04,575 --> 00:04:07,575
这种方式就是基于原码的方式

89
00:04:07,575 --> 00:04:11,575
下面这个左边就是Pytorch的一个JIT script

90
00:04:11,575 --> 00:04:13,575
右边就是它的一个编译过程

91
00:04:13,575 --> 00:04:15,575
首先输入的是一个Python的代码

92
00:04:15,575 --> 00:04:17,225
然后通过一些解析器

93
00:04:17,225 --> 00:04:20,575
把它变成一个Python的AST抽象语法数

94
00:04:20,575 --> 00:04:24,575
然后再对一些latest进行解析语法进行解析

95
00:04:24,575 --> 00:04:26,575
然后转换成为内部的语法数

96
00:04:26,575 --> 00:04:30,575
然后再对它进行一个IR的转换、IR的优化

97
00:04:30,575 --> 00:04:33,575
最后就变成一个可执行的IR

98
00:04:33,575 --> 00:04:35,575
然后给sqlter进行执行

99
00:04:35,575 --> 00:04:41,575
这个就是动态图转换成为静态图的一个最典型的方式

100
00:04:41,575 --> 00:04:43,575
那看看它有什么优缺点

101
00:04:43,575 --> 00:04:46,575
因为每一个解决方案它背后都有优缺点

102
00:04:46,575 --> 00:04:49,575
其实就在于怎么去选择

103
00:04:49,575 --> 00:04:51,575
小孩子才判断对错

104
00:04:51,575 --> 00:04:53,575
大人只权衡利弊

105
00:04:53,575 --> 00:04:56,575
那在AI框架或者AI系统的方案选择

106
00:04:56,575 --> 00:04:58,575
也只看利弊

107
00:05:03,575 --> 00:05:06,675
那第一个优点就是非常能够广泛的去支持

108
00:05:06,675 --> 00:05:08,575
宿主语言的各种动态控制流

109
00:05:09,575 --> 00:05:11,575
就各种if else while大部分是支持的

110
00:05:11,575 --> 00:05:15,575
缺点可能跟MindSpore的缺点其实差不多

111
00:05:15,575 --> 00:05:18,200
就是后端的实现的硬件和软件

112
00:05:18,200 --> 00:05:20,575
对静态图还是有一定的约束的

113
00:05:20,575 --> 00:05:22,575
就是它不能灵活的去表达

114
00:05:22,575 --> 00:05:26,225
那第二个就是数字语言的控制流

115
00:05:26,225 --> 00:05:29,575
并不是完全一定能够映射过来的

116
00:05:29,575 --> 00:05:33,575
那第三个就是遇到过度灵活的动态控制流

117
00:05:33,575 --> 00:05:37,575
运行的时候就会回退到由前端语言和后端的调用

118
00:05:37,575 --> 00:05:39,575
去不断的去轮回执行

119
00:05:39,575 --> 00:05:42,575
这个就类似于MindSpore的方式

120
00:05:42,575 --> 00:05:45,575
执行流跟控制流还会不断的跳转

121
00:05:45,575 --> 00:05:47,575
带来运行时的开销

122
00:05:47,575 --> 00:05:50,575
动态图转换成为静态图这种方式

123
00:05:50,575 --> 00:05:53,675
真的是为了兼顾灵活性应用性

124
00:05:53,675 --> 00:05:56,575
还有性能所提出的一种新的方案

125
00:05:56,575 --> 00:05:59,575
也被各个主流的AI框架所采用

126
00:05:59,575 --> 00:06:02,575
也被各个主流的AI框架所采用

127
00:06:03,575 --> 00:06:06,275
这一节课讲了控制流

128
00:06:06,275 --> 00:06:10,575
在计算图里面的表达和控制流跟计算图的关系

129
00:06:10,575 --> 00:06:14,575
这个是计算图里面非常非常核心的一个概念

130
00:06:14,575 --> 00:06:18,575
控制流采用不同的事迹就决定了AI框架

131
00:06:18,575 --> 00:06:21,325
分为了声明式编程的静态图

132
00:06:21,325 --> 00:06:23,575
或者是命令式编程的动态图

133
00:06:23,575 --> 00:06:26,575
静态图就统一了深度学习的一个表示

134
00:06:26,575 --> 00:06:29,575
非常利于编译优化和执行加速

135
00:06:29,575 --> 00:06:32,575
但是应用性实在非常难堪

136
00:06:32,575 --> 00:06:35,575
动态图非常灵活的应用数字语言

137
00:06:35,575 --> 00:06:38,575
但是优化起来也是很痛苦

138
00:06:38,575 --> 00:06:42,575
所以现在TensorFlow很难部署或者部署起来了

139
00:06:42,575 --> 00:06:45,575
又要转成Onlyt或者Mobile或者Caffe

140
00:06:45,575 --> 00:06:48,575
就它在部署的时候还是很大问题

141
00:06:48,575 --> 00:06:53,575
最后就提出了基于追踪的Traced或者基于源码的方式

142
00:06:53,575 --> 00:06:57,575
把动静态图统一起来兼顾应用性和性能

143
00:06:57,575 --> 00:06:59,575
好了,谢谢各位

144
00:06:59,575 --> 00:07:01,575
卷的不行了,卷的不行了

145
00:07:01,575 --> 00:07:03,575
记得一键三连加关注哦

146
00:07:03,575 --> 00:07:06,575
所有的内容都会开源在下面这条链接里面

147
00:07:06,575 --> 00:07:08,575
拜了个拜

